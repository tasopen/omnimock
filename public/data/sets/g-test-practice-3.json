{
  "metadata": {
    "title": "G検定 模擬試験 3",
    "description": "シラバス2024対応・実践編 (生成AI、法規制強化、最新トレンド重点)",
    "timeLimit": 100,
    "passLine": 70,
    "totalQuestions": 160
  },
  "questions": [
    {
      "id": 1,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の定義",
      "question": "人工知能（AI）の定義に関する説明として、最も適切なものを選べ。",
      "options": [
        "専門家の間でも明確な統一された定義は存在しない",
        "人間の脳の神経回路を模倣したシステムのみを指す",
        "自律的に意思決定を行い、感情を持つコンピュータプログラムである",
        "特定のタスクのみを処理する「特化型AI」のことだけを指す"
      ],
      "answer": 0,
      "explanation": "人工知能（AI）には、研究者や専門家の間でも統一された明確な定義は存在しません。時代や研究者によって捉え方が異なります。"
    },
    {
      "id": 2,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の分類",
      "question": "AIの分類において、「強いAI」と「弱いAI」という概念を提唱した哲学者は誰か。",
      "options": [
        "ジョン・サール",
        "アラン・チューリング",
        "マービン・ミンスキー",
        "レイ・カーツワイル"
      ],
      "answer": 0,
      "explanation": "ジョン・サール (John Searle) は、「中国語の部屋」の思考実験とともに、人間のように心を持つ「強いAI」と、単に知的な処理を模倣する「弱いAI」を定義しました。"
    },
    {
      "id": 3,
      "majorCategory": "人工知能とは",
      "subCategory": "AIの効果",
      "question": "「AI効果」と呼ばれる現象の説明として、最も適切なものを選べ。",
      "options": [
        "AIの原理が解明され実用化されると、それは単なる自動化とみなされ「知能」とは呼ばれなくなる現象",
        "AIが進化することで人間の仕事が奪われる現象",
        "AI等の技術導入により、一時的に生産性が低下する現象",
        "AIが学習データに含まれるバイアスを増幅してしまう現象"
      ],
      "answer": 0,
      "explanation": "AI効果とは、かつてはAIと呼ばれていた技術が、仕組みが分かり実用化されると「それは単なる計算/自動化だ」とみなされ、AIの定義から外れてしまう心理的な現象を指します。"
    },
    {
      "id": 4,
      "majorCategory": "人工知能とは",
      "subCategory": "第1次AIブーム",
      "question": "1956年に開催され、「人工知能（Artificial Intelligence）」という言葉が初めて公式に使われた会議は何か。",
      "options": [
        "ダートマス会議",
        "ダボス会議",
        "アシロマ会議",
        "国際人工知能会議"
      ],
      "answer": 0,
      "explanation": "1956年のダートマス会議 (Dartmouth Conference) で、ジョン・マッカーシー (John McCarthy) らにより「人工知能」という用語が提唱されました。"
    },
    {
      "id": 5,
      "majorCategory": "人工知能とは",
      "subCategory": "探索・推論",
      "question": "探索木において、現在いるノードから目的のノードまでの推定コスト（ヒューリスティック関数）を用いて探索を行う手法はどれか。",
      "options": [
        "A*アルゴリズム",
        "幅優先探索",
        "深さ優先探索",
        "モンテカルロ木探索"
      ],
      "answer": 0,
      "explanation": "A*アルゴリズム (A-Star Algorithm) は、スタート地点からの実コストとゴールまでの推定コストの和を用いて、最も有望な経路を探索する手法です。"
    },
    {
      "id": 6,
      "majorCategory": "人工知能とは",
      "subCategory": "第2次AIブーム",
      "question": "第2次AIブームの中心となった、専門家の知識をコンピュータに移植して推論を行うシステムを何と呼ぶか。",
      "options": [
        "エキスパートシステム",
        "ニューラルネットワーク",
        "サポートベクターマシン",
        "ジェネレーティブモデル"
      ],
      "answer": 0,
      "explanation": "1980年代の第2次AIブームでは、特定領域の専門知識をルールベースで記述した「エキスパートシステム (Expert System)」が流行しました（例：MYCIN）。"
    },
    {
      "id": 7,
      "majorCategory": "人工知能とは",
      "subCategory": "難問",
      "question": "「あるタスクを実行する際、関係のない事柄が無数にあることを考慮しきれず、計算量が爆発してしまう」という、第2次AIブームの際の大きな壁となった問題は何か。",
      "options": [
        "フレーム問題",
        "シンボルグラウンディング問題",
        "ノーフリーランチ定理",
        "勾配消失問題"
      ],
      "answer": 0,
      "explanation": "フレーム問題 (Frame Problem) は、現実世界の問題を解く際に「関係あること」と「関係ないこと」の区別を定義することが困難であるという問題です。"
    },
    {
      "id": 8,
      "majorCategory": "人工知能とは",
      "subCategory": "難問",
      "question": "記号（シンボル）とその意味（対象物）がAI内部で結びついていないという問題を何と呼ぶか。",
      "options": [
        "シンボルグラウンディング問題",
        "フレーム問題",
        "過学習",
        "次元の呪い"
      ],
      "answer": 0,
      "explanation": "シンボルグラウンディング問題 (Symbol Grounding Problem) は、コンピュータが扱う記号が実世界の意味と結びついていない（接地していない）という議論です。"
    },
    {
      "id": 9,
      "majorCategory": "人工知能とは",
      "subCategory": "第3次AIブーム",
      "question": "2012年の画像認識コンペティション「ILSVRC」で圧勝し、ディープラーニングブームの火付け役となったモデルは何か。",
      "options": [
        "AlexNet",
        "ResNet",
        "VGG",
        "GoogLeNet"
      ],
      "answer": 0,
      "explanation": "ジェフリー・ヒントン (Geoffrey Hinton) らのチームによる AlexNet は、従来の機械学習手法を大きく引き離して優勝し、ディープラーニングの有効性を知らしめました。"
    },
    {
      "id": 10,
      "majorCategory": "人工知能とは",
      "subCategory": "未来予測",
      "question": "「AIが自らより賢いAIを作り出すようになり、技術的成長が無限に加速する時点」を指す言葉として、レイ・カーツワイル (Ray Kurzweil) が提唱したものは何か。",
      "options": [
        "シンギュラリティ",
        "スーパーインテリジェンス",
        "シンボリズム",
        "トランスヒューマニズム"
      ],
      "answer": 0,
      "explanation": "シンギュラリティ (Singularity、技術的特異点) は、AIが人間の知能を超え、予測不可能な速度で進化する転換点を指します。"
    },
    {
      "id": 11,
      "majorCategory": "機械学習の概要",
      "subCategory": "基礎数学",
      "question": "機械学習の最適化計算において、関数の傾きを利用して最小値を探索するために用いられる数学的概念はどれか。",
      "options": [
        "偏微分",
        "積分",
        "集合論",
        "三角比"
      ],
      "answer": 0,
      "explanation": "多くのパラメータを持つ関数の最小値を求める際、特定の変数について微分する「偏微分」を用いて勾配（傾き）を計算し、パラメータを更新します（勾配降下法）。"
    },
    {
      "id": 12,
      "majorCategory": "機械学習の概要",
      "subCategory": "確率・統計",
      "question": "データのばらつき具合を表す指標であり、「偏差の二乗の平均値」で定義されるものは何か。",
      "options": [
        "分散",
        "標準偏差",
        "共分散",
        "中央値"
      ],
      "answer": 0,
      "explanation": "分散 (Variance) は、各データと平均値との差（偏差）を二乗して平均した値で、データの散らばり具合を表します。"
    },
    {
      "id": 13,
      "majorCategory": "機械学習の概要",
      "subCategory": "確率・統計",
      "question": "2つの変数間の線形な関係の強さを表す指標で、-1から1の値をとるものは何か。",
      "options": [
        "相関係数",
        "決定係数",
        "偏回帰係数",
        "オッズ比"
      ],
      "answer": 0,
      "explanation": "相関係数 (Correlation Coefficient) は、2つの変数の相関の強さを表し、1に近いほど正の相関、-1に近いほど負の相関こと示します。"
    },
    {
      "id": 14,
      "majorCategory": "機械学習の概要",
      "subCategory": "数理・統計の基礎",
      "question": "ある事象が生じた際に得られる情報量の期待値であり、データの不確実性や乱雑さを表す指標は何か。",
      "options": [
        "エントロピー",
        "尤度",
        "バイアス",
        "分散"
      ],
      "answer": 0,
      "explanation": "シャノンエントロピー (Entropy) は、情報源の不確実性の尺度であり、値が大きいほど事象の予測が難しく（ランダム性が高く）なります。"
    },
    {
      "id": 15,
      "majorCategory": "機械学習の概要",
      "subCategory": "数理・統計の基礎",
      "question": "結果（データ）が観測された後に、その原因となる事象の確率を更新する際に用いられる定理はどれか。",
      "options": [
        "ベイズの定理",
        "中心極限定理",
        "大数の法則",
        "ピタゴラスの定理"
      ],
      "answer": 0,
      "explanation": "ベイズの定理 (Bayes' Theorem) は、事後確率（結果から原因を推測する確率）を事前確率と尤度から計算するための基本定理です。"
    },
    {
      "id": 16,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法の種類",
      "question": "入力データと正解ラベルのセットを与えてモデルを学習させる手法を何と呼ぶか。",
      "options": [
        "教師あり学習",
        "教師なし学習",
        "強化学習",
        "半教師あり学習"
      ],
      "answer": 0,
      "explanation": "教師あり学習 (Supervised Learning) は、正解データ（教師データ）をもとに、入力と出力の関係を学習する手法です。"
    },
    {
      "id": 17,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法の種類",
      "question": "正解ラベルを与えず、データそのものの構造や特徴（クラスタなど）を学習させる手法はどれか。",
      "options": [
        "教師なし学習",
        "教師あり学習",
        "強化学習",
        "転移学習"
      ],
      "answer": 0,
      "explanation": "教師なし学習 (Unsupervised Learning) は、正解ラベルを用いずに、データの分布や構造（クラスタリングや次元削減など）を学習します。"
    },
    {
      "id": 18,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "エージェントが環境と相互作用し、得られる「報酬」を最大化するように行動方針を学習する手法はどれか。",
      "options": [
        "強化学習",
        "アンサンブル学習",
        "自己教師あり学習",
        "深層学習"
      ],
      "answer": 0,
      "explanation": "強化学習 (Reinforcement Learning) は、試行錯誤を通じて将来得られる報酬の総和が最大になるような行動方策を獲得する手法です。"
    },
    {
      "id": 19,
      "majorCategory": "機械学習の概要",
      "subCategory": "検証手法",
      "question": "学習データに対しては高い精度を示すが、未知のデータに対して精度が著しく低下する状態を何と呼ぶか。",
      "options": [
        "過学習",
        "学習不足",
        "正則化",
        "勾配消失"
      ],
      "answer": 0,
      "explanation": "過学習 (Overfitting) は、モデルが訓練データの特徴（ノイズ含む）に過剰に適合してしまい、汎化性能が失われた状態を指します。"
    },
    {
      "id": 20,
      "majorCategory": "機械学習の概要",
      "subCategory": "検証手法",
      "question": "データをk個のグループに分割し、そのうち1つをテスト用、残りを学習用として、これをk回入れ替えて検証する手法はどれか。",
      "options": [
        "k分割交差検証",
        "ホールドアウト法",
        "ブートストラップ法",
        "グリッドサーチ"
      ],
      "answer": 0,
      "explanation": "k分割交差検証 (k-fold Cross Validation) は、データを無駄なく使ってモデルの汎化性能を評価するための手法です。"
    },
    {
      "id": 21,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "真陽性 (TP) を「真陽性 (TP) + 偽陰性 (FN)」で割った値であり、実際に正であるもののうち正しく正と予測できた割合を表す指標は何か。",
      "options": [
        "再現率",
        "適合率",
        "正解率",
        "F値"
      ],
      "answer": 0,
      "explanation": "再現率 (Recall) は、見逃しをどれだけ防げたかを表す指標です。「感度 (Sensitivity)」とも呼ばれます。"
    },
    {
      "id": 23,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "適合率 (Precision) と再現率 (Recall) の調和平均で計算される指標は何か。",
      "options": [
        "F値",
        "正解率",
        "AUC",
        "特異度"
      ],
      "answer": 0,
      "explanation": "F値 (F-measure/F1-score) は、トレードオフの関係にある適合率と再現率のバランスを評価するための総合的な指標です。"
    },
    {
      "id": 24,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "分類モデルの評価において、縦軸に真陽性率(TPR)、横軸に偽陽性率(FPR)をとって描画される曲線を何と呼ぶか。",
      "options": [
        "ROC曲線",
        "PR曲線",
        "学習曲線",
        "シグモイド曲線"
      ],
      "answer": 0,
      "explanation": "ROC曲線は、閾値を変化させたときの分類モデルの性能を可視化するもので、この曲線の下側の面積がAUCとなります。"
    },
    {
      "id": 25,
      "majorCategory": "機械学習の概要",
      "subCategory": "回帰",
      "question": "回帰分析において、予測値と実測値の差の二乗和にペナルティ項（L2ノルム）を加えることで過学習を抑制する手法はどれか。",
      "options": [
        "リッジ回帰",
        "ラッソ回帰",
        "ロジスティック回帰",
        "サポートベクター回帰"
      ],
      "answer": 0,
      "explanation": "リッジ回帰 (Ridge Regression) は、L2正則化項を用いて重みの大きさを抑制し、過学習を防ぐ線形回帰の手法です。"
    },
    {
      "id": 26,
      "majorCategory": "機械学習の概要",
      "subCategory": "回帰",
      "question": "回帰分析において、L1ノルムをペナルティ項として加え、一部の係数を完全に0にする（特徴量選択の効果がある）手法はどれか。",
      "options": [
        "ラッソ回帰",
        "リッジ回帰",
        "エラスティックネット",
        "主成分分析"
      ],
      "answer": 0,
      "explanation": "ラッソ回帰 (Lasso Regression) は、L1正則化により不要なパラメータを0にすることで、スパースな解を得られる（特徴量選択ができる）特徴があります。"
    },
    {
      "id": 27,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル",
      "question": "「マージン」すなわちクラス間の境界との距離を最大化するように境界線を引く分類手法はどれか。",
      "options": [
        "サポートベクターマシン",
        "k近傍法",
        "決定木",
        "ナイーブベイズ"
      ],
      "answer": 0,
      "explanation": "サポートベクターマシン (SVM) は、マージン最大化によって識別境界を決定する手法で、高い汎化性能を持ちます。"
    },
    {
      "id": 28,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル",
      "question": "複数の弱い学習器（弱学習器）を組み合わせて、より精度の高い強い学習器を作る手法の総称は何か。",
      "options": [
        "アンサンブル学習",
        "転移学習",
        "強化学習",
        "表現学習"
      ],
      "answer": 0,
      "explanation": "アンサンブル学習 (Ensemble Learning) には、バギング（ランダムフォレストなど）やブースティング（勾配ブースティングなど）といった手法が含まれます。"
    },
    {
      "id": 29,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル",
      "question": "k平均法 (k-means) に関する説明として正しいものはどれか。",
      "options": [
        "データをk個のクラスタに分ける教師なし学習手法である",
        "k個の近傍データの多数決でクラス分類を行う教師あり学習手法である",
        "決定木をk個作成して平均をとる手法である",
        "k層のニューラルネットワークを用いる手法である"
      ],
      "answer": 0,
      "explanation": "k平均法 (k-means) は、代表点（重心）を更新しながらデータをk個のグループにクラスタリングする代表的な教師なし学習アルゴリズムです。"
    },
    {
      "id": 30,
      "majorCategory": "機械学習の概要",
      "subCategory": "前処理",
      "question": "カテゴリ変数（例：赤、青、緑）を、「赤=[1,0,0]」「青=[0,1,0]」のように0と1のベクトルで表現する手法を何と呼ぶか。",
      "options": [
        "One-hotエンコーディング",
        "分散表現",
        "主成分分析",
        "正規化"
      ],
      "answer": 0,
      "explanation": "One-hotエンコーディング（ワンホット表現）は、カテゴリデータを機械学習モデルで扱える数値ベクトルに変換する一般的な手法です。"
    },
    {
      "id": 31,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "生成AIの手法",
      "question": "1958年にローゼンブラット (Frank Rosenblatt) が提唱した、人間のニューロンの働きを模した単純な線形識別器は何か。",
      "options": [
        "単純パーセプトロン",
        "ボルツマンマシン",
        "オートエンコーダ",
        "トランスフォーマー"
      ],
      "answer": 0,
      "explanation": "単純パーセプトロンは、複数の入力に重みを掛けて足し合わせ、閾値を超えた場合に発火するモデルですが、線形分離不可能な問題（XORなど）を解けないという限界がありました。"
    },
    {
      "id": 32,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "基礎概念",
      "question": "単純パーセプトロンが線形分離不可能な問題（XOR問題）を解けないことを指摘し、第1次AIブームの終焉の一因を作った人物は誰か。",
      "options": [
        "マービン・ミンスキー",
        "ジェフリー・ヒントン",
        "ヤン・ルカン",
        "ヨシュア・ベンジオ"
      ],
      "answer": 0,
      "explanation": "マービン・ミンスキーとシーモア・パパートは著書『パーセプトロン』でその限界を数学的に証明し、ニューラルネット研究の冬の時代を招来しました。"
    },
    {
      "id": 33,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "多層パーセプトロンの学習において、出力層の誤差を入力層側に向かって順に伝播させ、各層の重みを更新するアルゴリズムは何か。",
      "options": [
        "誤差逆伝播法",
        "最尤推定法",
        "遺伝的アルゴリズム",
        "メトロポリス法"
      ],
      "answer": 0,
      "explanation": "誤差逆伝播法（バックプロパゲーション）は、連鎖律（Chain Rule）を利用してネットワーク全体の勾配を効率的に計算する手法で、現代のディープラーニングの基礎です。"
    },
    {
      "id": 34,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "NNの構成要素",
      "question": "勾配消失問題を緩和するために提案され、入力が0以下なら0、0より大きければ入力をそのまま出力する活性化関数は何か。",
      "options": [
        "ReLU",
        "Sigmoid関数",
        "Tanh関数",
        "Softmax関数"
      ],
      "answer": 0,
      "explanation": "ReLU（ランプ関数）は、正の領域で勾配が常に1であるため、層が深くなっても勾配消失が起きにくく、計算も高速です。"
    },
    {
      "id": 35,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "事前学習",
      "question": "2006年にジェフリー・ヒントンらが提唱した、層ごと（レイヤーワイズ）に教師なし学習を行い、重みの初期値を決定する手法で用いられるモデルはどれか。",
      "options": [
        "オートエンコーダ",
        "リカレントニューラルネットワーク",
        "畳み込みニューラルネットワーク",
        "敵対的生成ネットワーク"
      ],
      "answer": 0,
      "explanation": "オートエンコーダ（特に積層オートエンコーダ）を用いた事前学習により、深いネットワークの学習が可能になり、第3次AIブームのきっかけとなりました。"
    },
    {
      "id": 36,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "テクニック",
      "question": "学習時の各層の出力を確率的（ランダム）に0にすることで、ニューロンの共適応を防ぎ過学習を抑制する手法は何か。",
      "options": [
        "ドロップアウト",
        "バッチ正規化",
        "データ拡張",
        "早期終了"
      ],
      "answer": 0,
      "explanation": "ドロップアウト (Dropout) は、学習のたびに異なる数の一部のニューロンを無効化することで、擬似的にアンサンブル学習のような効果を得て過学習を防ぎます。"
    },
    {
      "id": 37,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AIの応用分野",
      "question": "画像認識において、局所的な特徴抽出を行う「畳み込み層」と、位置ズレを吸収する「プーリング層」を持つネットワーク構造は何か。",
      "options": [
        "CNN",
        "RNN",
        "LSTM",
        "Transformer"
      ],
      "answer": 0,
      "explanation": "CNN（畳み込みニューラルネットワーク）は、画像データの空間的な構造（近接ピクセル間の関係）を効率的に学習できるため、画像認識分野で標準的に使用されます。"
    },
    {
      "id": 38,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AIの応用分野",
      "question": "過去の情報を記憶し、時系列データの処理に適した構造を持つが、長期的な依存関係の学習が苦手なニューラルネットワークはどれか。",
      "options": [
        "RNN",
        "CNN",
        "GAN",
        "SVM"
      ],
      "answer": 0,
      "explanation": "RNN（回帰結合型ニューラルネットワーク）は、隠れ層の状態を次の時刻に引き継ぐことで文脈を扱えますが、勾配消失問題により長期記憶が困難でした（LSTM等が解決策）。"
    },
    {
      "id": 39,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "最適化",
      "question": "学習が進むにつれて学習率を徐々に小さくしたり、過去の勾配の情報を利用したりして収束を早める手法（オプティマイザ）として、適切でないものはどれか。",
      "options": [
        "k-means",
        "Adam",
        "RMSProp",
        "SGD"
      ],
      "answer": 0,
      "explanation": "k-meansはクラスタリングの手法であり、ニューラルネットワークのパラメータ最適化手法（オプティマイザ）ではありません。他は全て最適化手法です。"
    },
    {
      "id": 40,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "定義",
      "question": "2010年代後半から急速に発展した、大量のデータから学習し、新しい文章・画像・音声などを創造できるAIを総称して何と呼ぶか。",
      "options": [
        "生成AI",
        "識別AI",
        "記号AI",
        "ルールベースAI"
      ],
      "answer": 0,
      "explanation": "生成AI (Generative AI) は、学習データの分布を学習し、それに似た新しいデータを生成することができるAIの総称です。LLMや画像生成モデルが含まれます。"
    },
    {
      "id": 41,
      "majorCategory": "機械学習の概要",
      "subCategory": "回帰",
      "question": "ロジスティック回帰分析において、線形結合の結果を0から1の確率値に変換するために用いられる関数はどれか。",
      "options": [
        "シグモイド関数",
        "ステップ関数",
        "ReLU関数",
        "恒等関数"
      ],
      "answer": 0,
      "explanation": "ロジスティック回帰では、シグモイド関数を用いて出力を0から1の範囲に収め、あるクラスに属する確率として解釈します。"
    },
    {
      "id": 42,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "決定木の分岐基準として用いられる、データ集合の不純度（混ざり具合）を表す指標はどれか。",
      "options": [
        "ジニ不純度",
        "相関係数",
        "分散",
        "F値"
      ],
      "answer": 0,
      "explanation": "決定木では、ジニ不純度やエントロピーを用いて、分割後のデータの混ざり具合が最も少なくな​​る（純度が高くなる）ように分岐を決定します。"
    },
    {
      "id": 43,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "ランダムフォレスト (Random Forest) の特徴として、最も適切なものはどれか。",
      "options": [
        "バギングと特徴量のランダム選択を組み合わせることで、多様な決定木を作成する",
        "前のモデルの誤りを修正するように、逐次的にモデルを学習させる",
        "データを高次元空間に写像し、線形分離可能な超平面を見つける",
        "ニューラルネットワークの層を深くして学習能力を高める"
      ],
      "answer": 0,
      "explanation": "ランダムフォレストは、ブートストラップサンプリング（バギング）と分岐時の特徴量ランダム選択により、相関の低い多数の決定木を作成し、その多数決をとる手法です。"
    },
    {
      "id": 44,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "勾配ブースティング決定木 (GBDT) に関する説明として正しいものはどれか。",
      "options": [
        "前の決定木が予測しきれなかった誤差を予測する決定木を順次追加して精度を高める",
        "独立して学習させた複数の決定木の多数決をとる手法である",
        "全データを用いた単一の決定木を作成し、枝刈りを行って汎化性能を高める",
        "データの特徴量を主成分分析で削減してから決定木を作成する"
      ],
      "answer": 0,
      "explanation": "GBDT (Gradient Boosting Decision Tree) は、ブースティングの一種で、前のモデルの残差（誤差）を次のモデルが学習することで、段階的に予測精度を向上させます。"
    },
    {
      "id": 45,
      "majorCategory": "機械学習の概要",
      "subCategory": "SVM",
      "question": "サポートベクターマシン (SVM) において、非線形なデータを線形分離可能にするために、高次元空間への写像を計算コストを抑えて行う手法を何と呼ぶか。",
      "options": [
        "カーネルトリック",
        "バギング",
        "正則化",
        "次元圧縮"
      ],
      "answer": 0,
      "explanation": "カーネルトリック (Kernel Trick) を用いることで、実際に高次元空間へデータを変換する計算を行わずに、高次元での内積を計算でき、非線形分類が可能になります。"
    },
    {
      "id": 46,
      "majorCategory": "機械学習の概要",
      "subCategory": "アルゴリズム",
      "question": "k近傍法 (k-NN) の特徴として適切なものはどれか。",
      "options": [
        "事前の学習フェーズが不要で、予測時に未知データと全学習データとの距離を計算する",
        "データをk個のクラスタに分割する教師なし学習である",
        "確率的勾配降下法を用いてパラメータを更新する",
        "決定木のアンサンブル学習を行う"
      ],
      "answer": 0,
      "explanation": "k近傍法 (k-Nearest Neighbor) は、学習データをただ保持し、予測時に近傍データを探すため「怠惰学習 (Lazy Learning)」と呼ばれます。"
    },
    {
      "id": 47,
      "majorCategory": "機械学習の概要",
      "subCategory": "アルゴリズム",
      "question": "「特徴量同士が互いに独立である」という強い仮定を置くことで計算を単純化した、確率的分類手法はどれか。",
      "options": [
        "ナイーブベイズ",
        "ロジスティック回帰",
        "ランダムフォレスト",
        "サポートベクターマシン"
      ],
      "answer": 0,
      "explanation": "ナイーブベイズ分類器 (Naive Bayes Classifier) は、特徴量間の独立性を仮定（ナイーブな仮定）することで、ベイズの定理を用いた確率計算を高速に行います。スパムフィルタ等で利用されます。"
    },
    {
      "id": 48,
      "majorCategory": "機械学習の概要",
      "subCategory": "データ前処理・分析",
      "question": "データの分散が最大になる方向を第1主成分とし、順次直交する方向へ軸をとることで次元削減を行う手法は何か。",
      "options": [
        "主成分分析",
        "t-SNE",
        "LDA",
        "オートエンコーダ"
      ],
      "answer": 0,
      "explanation": "主成分分析 (Principal Component Analysis: PCA) は、データの情報をできるだけ損なわない（分散を保つ）軸を見つけ出し、低次元に圧縮する手法です。"
    },
    {
      "id": 49,
      "majorCategory": "機械学習の概要",
      "subCategory": "クラスタリング",
      "question": "k-means法の初期値依存の問題を改善するために、初期クラスタ中心を互いに離れた位置になる確率が高くなるように選ぶ手法はどれか。",
      "options": [
        "k-means++",
        "k-medoids",
        "DBSCAN",
        "x-means"
      ],
      "answer": 0,
      "explanation": "k-means++は、初期値を完全にランダムではなく、既存の中心から距離が遠い点ほど選ばれやすくすることで、解の質と収束速度を改善します。"
    },
    {
      "id": 50,
      "majorCategory": "機械学習の概要",
      "subCategory": "クラスタリング",
      "question": "個々のデータをクラスタとし、最も似ているクラスタ同士を順次併合していく手法であり、その過程をデンドログラム（樹形図）で可視化できるものはどれか。",
      "options": [
        "階層的クラスタリング",
        "非階層的クラスタリング",
        "k-means法",
        "混合ガウスモデル"
      ],
      "answer": 0,
      "explanation": "階層的クラスタリング (Hierarchical Clustering) は、凝集型（ボトムアップ）などの手法があり、クラスタの結合過程をデンドログラムで表現できるのが特徴です。"
    },
    {
      "id": 51,
      "majorCategory": "機械学習の概要",
      "subCategory": "次元削減・可視化",
      "question": "高次元データの局所的な構造を保ちつつ低次元（2次元や3次元）に圧縮することに優れ、データの可視化によく用いられる手法はどれか。",
      "options": [
        "t-SNE",
        "PCA",
        "SVD",
        "NMF"
      ],
      "answer": 0,
      "explanation": "t-SNEは、高次元空間での点同士の類似度を低次元空間でも再現するように配置する手法で、複雑なデータの可視化に非常に有効です。"
    },
    {
      "id": 52,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "混同行列において、実際は負(Negative)のデータを誤って正(Positive)と予測してしまった場合を何と呼ぶか。",
      "options": [
        "偽陽性",
        "偽陰性",
        "真陽性",
        "真陰性"
      ],
      "answer": 0,
      "explanation": "偽陽性 (False Positive) は、実際は「ない（負）」ものを「ある（正）」と誤検出することであり、「誤警報」とも呼ばれます。"
    },
    {
      "id": 53,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "分類モデルの評価指標の一つで、正解データの偏り（不均衡データ）がある場合でも適切に評価しやすい指標として、適合率と再現率の調和平均をとったものはどれか（再掲類似）。",
      "options": [
        "F1スコア",
        "正解率",
        "特異度",
        "対数尤度"
      ],
      "answer": 0,
      "explanation": "不均衡データでは、単に「多数派クラス」を予測し続けるだけで正解率が高くなってしまうため、F1スコアが重要視されます。"
    },
    {
      "id": 54,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "ROC曲線はTPRとFPRの関係を見るが、正例が極端に少ない不均衡データにおいて、より実用的な評価指標として用いられる曲線は何か。",
      "options": [
        "PR曲線",
        "ROC曲線",
        "ローレンツ曲線",
        "シグモイド曲線"
      ],
      "answer": 0,
      "explanation": "PR曲線は、縦軸に適合率(Precision)、横軸に再現率(Recall)をとり、不均衡データでのモデル性能（特に正例の検出能力）を評価するのに適しています。"
    },
    {
      "id": 55,
      "majorCategory": "機械学習の概要",
      "subCategory": "回帰評価",
      "question": "回帰モデルの評価指標において、二乗することで大きな誤差の影響を大きく評価するため、外れ値に敏感な指標はどれか。",
      "options": [
        "RMSE",
        "MAE",
        "R2スコア",
        "MAPE"
      ],
      "answer": 0,
      "explanation": "RMSE（二乗平均平方根誤差）は誤差を二乗してから平均をとるため、外れ値のような大きな誤差があると値が大きくなりやすい特徴があります。"
    },
    {
      "id": 56,
      "majorCategory": "機械学習の概要",
      "subCategory": "回帰評価",
      "question": "回帰モデルの当てはまりの良さを表す指標で、最大値が1になり、1に近いほどモデルがデータをよく説明できていることを示すものは何か。",
      "options": [
        "決定係数",
        "相関係数",
        "分散",
        "標準誤差"
      ],
      "answer": 0,
      "explanation": "決定係数 (R^2, Coefficient of Determination) は、モデルがデータの変動をどれだけ説明できているかを示す指標です。"
    },
    {
      "id": 57,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習のテクニック",
      "question": "過学習を防ぐために、モデルの重（係数）の絶対値の和を損失関数に加える正則化手法はどれか。",
      "options": [
        "L1正則化",
        "L2正則化",
        "ドロップアウト",
        "バッチ正規化"
      ],
      "answer": 0,
      "explanation": "L1正則化は重みの絶対値の和をペナルティ項とし、ラッソ回帰などで用いられます。不要な重みを0にする効果があります。"
    },
    {
      "id": 58,
      "majorCategory": "機械学習の概要",
      "subCategory": "前処理",
      "question": "データの特徴量のスケール（平均と分散）を揃える処理で、平均を0、標準偏差を1にする変換を何と呼ぶか。",
      "options": [
        "標準化",
        "正規化",
        "白色化",
        "ロジット変換"
      ],
      "answer": 0,
      "explanation": "標準化 (Standardization) は、データを平均0、分散1の標準正規分布に従うように変換することで、スケールの異なる特徴量を扱いやすくします。"
    },
    {
      "id": 59,
      "majorCategory": "機械学習の概要",
      "subCategory": "検証手法",
      "question": "交差検証において、元のデータセットに含まれる正解ラベルの比率（クラス分布）を維持したまま分割を行う手法はどれか。",
      "options": [
        "層化k分割交差検証",
        "時系列交差検証",
        "リーブワンアウト交差検証",
        "単留保法"
      ],
      "answer": 0,
      "explanation": "層化k分割交差検証 (Stratified k-fold) は、各分割データのクラス比率を全体と同じに保つため、不均衡データの検証で特に有効です。"
    },
    {
      "id": 60,
      "majorCategory": "機械学習の概要",
      "subCategory": "ハイパーパラメータ探索",
      "question": "ハイパーパラメータの探索手法で、ベイズ最適化を用いて過去の試行結果から次に見るべき有望なパラメータを推定し、効率的に探索を行うフレームワークとして有名なものはどれか。",
      "options": [
        "Optuna",
        "Grid Search",
        "Random Search",
        "Manual Tuning"
      ],
      "answer": 0,
      "explanation": "Optunaは、ベイズ最適化（TPEなど）を用いて効率的にハイパーパラメータ空間を探索し、自動化するための人気のあるPythonライブラリです。"
    },
    {
      "id": 61,
      "majorCategory": "機械学習の概要",
      "subCategory": "データの扱い",
      "question": "不均衡データの対策として、少数派クラスのデータを人工的に合成して増やすオーバーサンプリング手法はどれか。",
      "options": [
        "SMOTE",
        "アンダーサンプリング",
        "バギング",
        "主成分分析"
      ],
      "answer": 0,
      "explanation": "SMOTEは、少数派クラスのデータ点同士を結ぶ線分上に新たなデータを人工的に生成することで、過学習を抑えつつデータを増強する手法です。"
    },
    {
      "id": 62,
      "majorCategory": "機械学習の概要",
      "subCategory": "特徴量選択",
      "question": "特徴量選択の手法において、実際に学習モデルを作成し、その精度をもとに特徴量の良し悪しを評価する手法（計算コストは高い）を何と呼ぶか。",
      "options": [
        "ラッパー法",
        "フィルター法",
        "埋め込み法",
        "アンサンブル法"
      ],
      "answer": 0,
      "explanation": "ラッパー法 (Wrapper Method) は、再帰的特徴量削減 (RFE) のように、実際にモデルを学習させて評価を繰り返すため、精度は高いですが計算コストがかかります。"
    },
    {
      "id": 63,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "アンサンブル学習において、異なるモデルの予測結果を入力として、最終的な予測を行う「メタモデル」を学習させる手法はどれか。",
      "options": [
        "スタッキング",
        "バギング",
        "ブースティング",
        "投票法"
      ],
      "answer": 0,
      "explanation": "スタッキング (Stacking) は、1段目の複数のモデルの出力を特徴量として、2段目のモデル（メタモデル）が最終予測を行う手法です。"
    },
    {
      "id": 64,
      "majorCategory": "機械学習の概要",
      "subCategory": "AIの応用分野",
      "question": "異常検知において、データをランダムに分割していき、孤立しやすい（分割回数が少ない）データを異常と判定する手法はどれか。",
      "options": [
        "Isolation Forest",
        "One-class SVM",
        "k-NN",
        "Local Outlier Factor"
      ],
      "answer": 0,
      "explanation": "Isolation Forestは、決定木のようにデータをランダムに分割した際、異常値は正常値よりも早く孤立する（パス長が短い）性質を利用した手法です。"
    },
    {
      "id": 65,
      "majorCategory": "機械学習の概要",
      "subCategory": "関連分析",
      "question": "マーケットバスケット分析などで用いられる「アソシエーション分析」において、商品Aを買った人が商品Bも買う『信頼度 (Confidence)』の定義として正しいものはどれか。",
      "options": [
        "AとBを両方買う確率 / Aを買う確率",
        "AとBを両方買う確率 / 全体の確率",
        "AとBを両方買う確率 /",
        "Bを買う確率 / Aを買う確率"
      ],
      "answer": 0,
      "explanation": "信頼度 (Confidence) は、条件部（Aを買った）が起こったときに、結論部（Bを買った）が起こる条件付き確率 P(B|A) です。"
    },
    {
      "id": 66,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "基礎",
      "question": "強化学習において、現在の知識で最良の行動を選ぶことと、未知の行動を試して知識を増やすことのトレードオフを何と呼ぶか。",
      "options": [
        "活用と探索",
        "バイアスとバリアンス",
        "精度と再現率",
        "教師ありと教師なし"
      ],
      "answer": 0,
      "explanation": "「活用 (Exploitation)」は既知の最良手を選ぶこと、「探索 (Exploration)」は未知のより良い手を探すことで、このバランスが重要です。"
    },
    {
      "id": 67,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "方策",
      "question": "強化学習において、ある状態の価値や、ある状態である行動をとることの価値を推定する関数を何と呼ぶか。",
      "options": [
        "価値関数",
        "目的関数",
        "活性化関数",
        "損失関数"
      ],
      "answer": 0,
      "explanation": "価値関数 (Value Function) は、特定の状態（または状態と行動）から将来得られる報酬の期待値を表す関数です。"
    },
    {
      "id": 68,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "手法",
      "question": "行動価値関数（Q関数）を更新する際、実際にとった行動とは無関係に、次の状態でとりうる最大のQ値を利用して学習する（オフポリシー）手法はどれか。",
      "options": [
        "Q学習",
        "SARSA",
        "モンテカルロ法",
        "方策勾配法"
      ],
      "answer": 0,
      "explanation": "Q学習 (Q-Learning) は、次の状態での最大のQ値を使って現在のQ値を更新するため、探索的な行動をしていても最適な行動価値を学習できます。"
    },
    {
      "id": 69,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "モデルが単純すぎて本質を捉えられない「バイアス」と、モデルが複雑すぎてデータの影響を受けすぎる「バリアンス」のトレードオフにおいて、バリアンスが高い状態は何を意味するか。",
      "options": [
        "過学習している",
        "学習不足である",
        "最適に学習できている",
        "データ数が不足しているとは限らない"
      ],
      "answer": 0,
      "explanation": "バリアンス（分散）が高いとは、学習データが変わるとモデルの予測結果が大きく変わってしまう状態、つまり過学習（Overfitting）している状態を指します。"
    },
    {
      "id": 70,
      "majorCategory": "機械学習の概要",
      "subCategory": "課題",
      "question": "データの次元数（特徴量の数）が増えると、空間が疎になり、距離の概念が意味をなさなくなったり、学習に必要なデータ量が指数関数的に増えたりする問題を何と呼ぶか。",
      "options": [
        "次元の呪い",
        "ノーフリーランチ定理",
        "シンギュラリティ",
        "勾配消失問題"
      ],
      "answer": 0,
      "explanation": "次元の呪い (Curse of Dimensionality) は、高次元空間において機械学習のパフォーマンスが低下したり、効率が悪くなったりする現象を指します。"
    },
    {
      "id": 71,
      "majorCategory": "機械学習の概要",
      "subCategory": "課題",
      "question": "モデルの学習時に、本来予測時点では知り得ないはずの将来の情報（正解など）が特徴量に含まれてしまい、テスト時に異常に高い精度が出てしまう問題を何と呼ぶか。",
      "options": [
        "リーク / データリーケージ",
        "過学習",
        "バイアス",
        "交差検証"
      ],
      "answer": 0,
      "explanation": "データリーケージ (Data Leakage) は、実運用時には使えないはずの情報が訓練データに混入し、実力以上の評価が出てしまう重大なミスです。"
    },
    {
      "id": 72,
      "majorCategory": "機械学習の概要",
      "subCategory": "手法",
      "question": "「あなたと似た商品を好むユーザーは、この商品も好んでいます」というように、ユーザー間の行動履歴の類似度に基づいて推薦を行う手法はどれか。",
      "options": [
        "協調フィルタリング",
        "コンテンツベースフィルタリング",
        "ルールベース推薦",
        "人気ランキング推薦"
      ],
      "answer": 0,
      "explanation": "協調フィルタリング (Collaborative Filtering) は、ユーザー×アイテムの相互作用（購入履歴や評価）の行列を利用して推薦を行います。"
    },
    {
      "id": 73,
      "majorCategory": "機械学習の概要",
      "subCategory": "手法",
      "question": "「あなたが過去に見た映画と同じジャンルや監督の映画を推薦します」というように、アイテム自体の属性（特徴量）の類似性に基づく手法はどれか。",
      "options": [
        "コンテンツベースフィルタリング",
        "協調フィルタリング",
        "行列分解",
        "アソシエーション分析"
      ],
      "answer": 0,
      "explanation": "コンテンツベースフィルタリング (Content-based Filtering) は、アイテムの内容（テキスト、ジャンル、属性など）の類似度を利用して推薦を行います。"
    },
    {
      "id": 74,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "トピックモデル",
      "question": "文書集合から、その背後にある潜在的なトピック（話題）の分布を推定する確率的生成モデルであり、各文書が複数のトピックから構成されると仮定する手法はどれか。",
      "options": [
        "LDA",
        "LSI",
        "TF-IDF",
        "Word2Vec"
      ],
      "answer": 0,
      "explanation": "LDA (Latent Dirichlet Allocation: 潜在的ディリクレ配分法) は、代表的なトピックモデルの手法です。"
    },
    {
      "id": 75,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル",
      "question": "時系列データの解析において、自己回帰(AR)、和分(I)、移動平均(MA)の3つの要素を組み合わせたモデルはどれか。",
      "options": [
        "ARIMAモデル",
        "RNNモデル",
        "SARIMAモデル",
        "状態空間モデル"
      ],
      "answer": 0,
      "explanation": "ARIMAモデルは、非定常な時系列データに対しても差分をとることで適用可能にした、古典的かつ強力な時系列予測モデルです。"
    },
    {
      "id": 76,
      "majorCategory": "機械学習の概要",
      "subCategory": "前処理",
      "question": "欠損値の処理として、欠損を含む行を削除するのではなく、平均値や中央値、あるいは予測値などで穴埋めすることを何と呼ぶか。",
      "options": [
        "代入法 / 補完",
        "除去法",
        "正規化",
        "バギング"
      ],
      "answer": 0,
      "explanation": "代入法 (Imputation) は、貴重なデータを捨てずに活用するために、統計的または機械学習的な手法で欠損値を埋める処理です。"
    },
    {
      "id": 77,
      "majorCategory": "機械学習の概要",
      "subCategory": "前処理",
      "question": "データ分布において、四分位範囲 (IQR) を利用し、第一四分位数より1.5倍のIQR以下、または第三四分位数より1.5倍のIQR以上の値を検出する手法は主に何に使われるか。",
      "options": [
        "外れ値検出",
        "欠損値補完",
        "特徴量選択",
        "クラスタリング"
      ],
      "answer": 0,
      "explanation": "箱ひげ図などで用いられるこの基準（Tukeyの方法）は、統計的に外れ値（異常値）を検出するためのシンプルなルールです。"
    },
    {
      "id": 78,
      "majorCategory": "機械学習の概要",
      "subCategory": "評価",
      "question": "クラスタリングの結果において、クラスタ内の凝集度とクラスタ間の分離度を評価し、-1から1の値をとる指標は何か。",
      "options": [
        "シルエット係数",
        "エルボー法",
        "カッパ係数",
        "ジニ係数"
      ],
      "answer": 0,
      "explanation": "シルエット係数は、データが自身のクラスタにどれだけ近く、隣接するクラスタからどれだけ遠いかを評価する指標です。"
    },
    {
      "id": 79,
      "majorCategory": "機械学習の概要",
      "subCategory": "アンサンブル",
      "question": "アンサンブル学習が単一のモデルよりも精度が高くなる傾向がある理由として、「多種多様なモデルの平均をとることで、個々のモデルの〇〇が相殺される」の〇〇に入る語句はどれか。",
      "options": [
        "誤差",
        "計算コスト",
        "特徴量",
        "バイアス"
      ],
      "answer": 0,
      "explanation": "アンサンブル（特にバギング）は、個々のモデルの予測のばらつき（バリアンス）を平均化することで抑え、汎化性能を向上させる効果があります。"
    },
    {
      "id": 80,
      "majorCategory": "機械学習の概要",
      "subCategory": "定理",
      "question": "「あらゆる問題に対して平均的に高性能なアルゴリズムは存在しない（ある問題に特化したアルゴリズムは、他の問題では劣る可能性がある）」という定理を何と呼ぶか（再掲類似）。",
      "options": [
        "ノーフリーランチ定理",
        "中心極限定理",
        "大数の法則",
        "ムーアの法則"
      ],
      "answer": 0,
      "explanation": "ノーフリーランチ定理は、「万能な究極のアルゴリズム」は存在せず、対象とする問題の性質に合わせてアルゴリズムを選択・調整する必要があることを示唆しています。"
    },
    {
      "id": 81,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "深層学習のモデル",
      "question": "RNN（リカレントニューラルネットワーク）の長期依存性の学習が困難な問題を解決するために、「忘却ゲート」などの機構を導入したモデルはどれか。",
      "options": [
        "LSTM",
        "CNN",
        "GAN",
        "MLP"
      ],
      "answer": 0,
      "explanation": "LSTMは、入力ゲート、出力ゲート、忘却ゲートを持つことで、重要な情報を長期間保持し、不要な情報を忘れることを学習できます。"
    },
    {
      "id": 82,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "深層学習のモデル",
      "question": "LSTMを簡略化した構造を持ち、計算コストを抑えつつ同等の性能を発揮することが多いモデルはどれか。",
      "options": [
        "GRU",
        "ResNet",
        "VGG",
        "Transformer"
      ],
      "answer": 0,
      "explanation": "GRUは、LSTMのゲート機構をリセットゲートと更新ゲートの2つに簡略化したモデルで、学習パラメータが少なくて済みます。"
    },
    {
      "id": 83,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "深層学習のモデル",
      "question": "時系列データを過去から未来へだけでなく、未来から過去への方向にも学習させることで、文脈をより深く捉えるモデルはどれか。",
      "options": [
        "双方向RNN",
        "オートエンコーダ",
        "自己回帰モデル",
        "ホップフィールドネットワーク"
      ],
      "answer": 0,
      "explanation": "双方向RNN (Bi-RNN) は、前方向と後ろ方向の2つのRNNを組み合わせることで、過去と未来両方の情報を利用して出力を決定します。"
    },
    {
      "id": 84,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "深層学習のモデル",
      "question": "CNNにおいて、特徴マップのチャンネル数を圧縮（次元削減）したり、計算量を抑えつつ非線形性を増やしたりするために用いられる畳み込みはどれか。",
      "options": [
        "1x1畳み込み",
        "3x3畳み込み",
        "転置畳み込み",
        "膨張畳み込み"
      ],
      "answer": 0,
      "explanation": "1x1畳み込みは、空間的なサイズ（縦横）を変えずにチャンネル方向の線形結合を行うため、チャンネル数の削減（次元圧縮）によく用いられます（例：GoogLeNetのInceptionモジュール）。"
    },
    {
      "id": 85,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "深層学習のモデル",
      "question": "全結合層の代わりとして、各特徴マップの平均値をとって出力層に渡す手法であり、パラメータ数を大幅に削減できるものは何か。",
      "options": [
        "Global Average Pooling",
        "Max Pooling",
        "Stochastic Pooling",
        "Dropout"
      ],
      "answer": 0,
      "explanation": "GAP (Global Average Pooling) は、最後に特徴マップごとの平均値をとることでベクトル化するため、全結合層のような大量のパラメータを必要としません。CAM等の可視化にも役立ちます。"
    },
    {
      "id": 86,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "データ拡張",
      "question": "学習データの画像の一部をランダムに黒く塗りつぶす（矩形で隠す）ことで、隠れなかった部分から特徴を捉えるように学習させるデータ拡張手法はどれか。",
      "options": [
        "Cutout",
        "Mixup",
        "Random Crop",
        "Flip"
      ],
      "answer": 0,
      "explanation": "Cutoutは、画像の一部を除去（マスク）することで、特定の局所的な特徴だけに頼らないロバストなモデルを作成する手法です。"
    },
    {
      "id": 87,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "モデル評価",
      "question": "物体検出において、予測したバウンディングボックスと正解のボックスの重なり具合を表す指標は何か（「共通部分の面積÷和集合の面積」で計算）。",
      "options": [
        "IoU",
        "FPS",
        "mAP",
        "ROC AUC"
      ],
      "answer": 0,
      "explanation": "IoU（Jaccard係数）は、領域の重なり具合を0から1で表し、物体検出の正解判定の閾値として利用されます。"
    },
    {
      "id": 88,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "後処理",
      "question": "物体検出において、同じ物体に対して複数の候補枠（バウンディングボックス）が出た際に、確信度が最も高い枠を残して他を抑制（削除）する処理は何か。",
      "options": [
        "NMS",
        "ROI Pooling",
        "アンカーボックス",
        "Batch Normalization"
      ],
      "answer": 0,
      "explanation": "NMS（非極大抑制）は、重複する検出枠の中から最もスコアが高いものを採用し、それとIoUが高い（重なっている）他の枠を削除するアルゴリズムです。"
    },
    {
      "id": 89,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "モデル",
      "question": "画像をグリッドに分割し、各グリッドで物体である確率と座標を同時に予測する、高速な1段階（One-stage）物体検出モデルはどれか。",
      "options": [
        "YOLO",
        "Faster R-CNN",
        "Mask R-CNN",
        "U-Net"
      ],
      "answer": 0,
      "explanation": "YOLOは、領域提案と分類を1つのネットワークで同時に行うため非常に高速で、リアルタイム検出に適しています。"
    },
    {
      "id": 90,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "モデル",
      "question": "全結合層を持たず、畳み込み層とアンプーリング（逆畳み込み等）だけで構成され、ピクセル単位でのクラス分類（セマンティックセグメンテーション）を可能にしたモデルはどれか。",
      "options": [
        "FCN",
        "CNN",
        "GAN",
        "RNN"
      ],
      "answer": 0,
      "explanation": "FCN（全畳み込みネットワーク）は、位置情報を保持したまま画像を処理し、入力画像と同じサイズのセグメンテーションマップを出力します。"
    },
    {
      "id": 91,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "モデル",
      "question": "医療画像診断などで有名な「U-Net」の特徴である、エンコーダ側の特徴マップをデコーダ側の対応する層に結合して位置情報を補完する仕組みを何と呼ぶか。",
      "options": [
        "スキップ接続",
        "残差接続",
        "ドロップアウト",
        "自己注意"
      ],
      "answer": 0,
      "explanation": "スキップ接続（U-Netの場合はconcatenationを用いる）により、畳み込みで失われた詳細な位置情報をデコーダ側に伝えることで、精度の高いセグメンテーションを実現します。"
    },
    {
      "id": 92,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Attention",
      "question": "Seq2seqモデルにおいて、入力文のどの単語に注目すべきかを学習し、長い文章の翻訳精度を劇的に向上させた機構は何か。",
      "options": [
        "注意機構 / アテンション",
        "記憶セル",
        "ゲート機構",
        "畳み込み"
      ],
      "answer": 0,
      "explanation": "Attention機構は、デコーダが出力する各ステップにおいて、エンコーダの出力（ソース文）のどこを重視するかを動的に重み付けします。"
    },
    {
      "id": 93,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "2017年に論文「Attention Is All You Need」で発表され、RNNを使わずにAttentionのみで構成された、現在のLLMの基礎となるモデルは何か。",
      "options": [
        "Transformer",
        "BERT",
        "GPT-3",
        "LSTM"
      ],
      "answer": 0,
      "explanation": "Transformerは、並列計算が可能で学習効率が高く、長期的な依存関係も捉えられるため、NLPのデファクトスタンダードとなりました。"
    },
    {
      "id": 94,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "Transformerの核心となる「Self-Attention（自己注意）」において、入力された単語ベクトルから生成される3つのベクトルの組み合わせとして正しいものはどれか。",
      "options": [
        "Query, Key, Value",
        "Input, Hidden, Output",
        "Forget, Update, Reset",
        "Mean, Variance, Bias"
      ],
      "answer": 0,
      "explanation": "Self-Attentionは、Query（検索クエリ）とKey（検索対象）の内積で類似度（重み）を計算し、それに基づいてValue（値）を重み付け和することで文脈を計算します。"
    },
    {
      "id": 95,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "事前学習モデル",
      "question": "Transformerのエンコーダ部分を使用し、文章の一部を隠して（マスクして）予測する「マスク化言語モデル(MLM)」などのタスクで事前学習を行う、双方向性のモデルはどれか。",
      "options": [
        "BERT",
        "GPT",
        "T5",
        "Word2Vec"
      ],
      "answer": 0,
      "explanation": "BERTは文脈を前後双方向から読み取ることができ、分類や質問応答などのタスクで高い性能を発揮します。"
    },
    {
      "id": 96,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "事前学習モデル",
      "question": "Transformerのデコーダ部分を使用し、次の単語を予測するタスク（自己回帰）で事前学習を行う、文章生成が得意なモデルはどれか。",
      "options": [
        "GPT",
        "BERT",
        "RoBERTa",
        "ALBERT"
      ],
      "answer": 0,
      "explanation": "GPTシリーズは、左から右へ順に単語を生成するタスクで学習されており、流暢な文章生成能力を持ちます。"
    },
    {
      "id": 97,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "画像をパッチ（ごく小さな矩形領域）に分割して並べることで、画像データに対してもTransformerを適用可能にしたモデルはどれか。",
      "options": [
        "ViT",
        "ResNet",
        "EfficientNet",
        "MobileNet"
      ],
      "answer": 0,
      "explanation": "ViT (Vision Transformer) は、画像を単語の並びのように扱うことで、CNNを使わずに高い画像認識精度を達成しました。"
    },
    {
      "id": 98,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "GAN",
      "question": "偽物を作る「生成器(Generator)」と、本物か偽物かを見抜く「識別器(Discriminator)」を競わせて学習するモデルはどれか。",
      "options": [
        "GAN",
        "VAE",
        "Diffusion Model",
        "Flow Model"
      ],
      "answer": 0,
      "explanation": "GAN（敵対的生成ネットワーク）は、2つのネットワークのミニマックスゲーム（競合学習）により、非常にリアルな画像を生成できます。"
    },
    {
      "id": 99,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "データを潜在的な確率分布（平均と分散）に変換し、そこからサンプリングしてデータを復元することで生成を行うモデルはどれか。",
      "options": [
        "VAE",
        "GAN",
        "CNN",
        "Autoregression"
      ],
      "answer": 0,
      "explanation": "VAE（変分オートエンコーダ）は、潜在空間が連続的な分布になるように学習するため、画像間のモーフィングなどが可能です。"
    },
    {
      "id": 100,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "生成AIの手法",
      "question": "画像にノイズを徐々に加えて完全にランダムなノイズにする過程と、逆にノイズを除去して画像を復元する過程（デノイジング）を学習する生成モデルはどれか。",
      "options": [
        "拡散モデル",
        "GAN",
        "VAE",
        "Transformer"
      ],
      "answer": 0,
      "explanation": "Stable DiffusionやDALL-E 2などの最新の画像生成AIの多くは、この拡散モデル（Diffusion Model）をベースにしています。"
    },
    {
      "id": 101,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "生成AIの手法",
      "question": "画像とテキストのペアを大量に学習し、画像とテキストが対応しているかを判定する（対照学習を行う）OpenAIのモデルで、Zero-shot分類などに使われるものはどれか。",
      "options": [
        "CLIP",
        "DALL-E",
        "GPT-4",
        "BERT"
      ],
      "answer": 0,
      "explanation": "CLIPは、画像とテキストを同じ特徴空間に埋め込むことで、「この画像は『犬』だ」といった分類を、学習データになかったラベル（Zero-shot）で行うことができます。"
    },
    {
      "id": 102,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習設定",
      "question": "学習時には見たことのないクラス（ラベル）を、補助的な情報（属性や説明文など）を用いて分類・認識するタスク設定を何と呼ぶか。",
      "options": [
        "ゼロショット学習",
        "ワンショット学習",
        "フューショット学習",
        "転移学習"
      ],
      "answer": 0,
      "explanation": "ゼロショット学習は、事前知識（意味的な関連性など）を利用して、訓練例が0件の未知のクラスに対応する手法です。"
    },
    {
      "id": 103,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "大規模なデータセットで事前学習済みのモデルのパラメータ全体を、特定のタスクのデータで再学習して微調整する手法を何と呼ぶか。",
      "options": [
        "ファインチューニング",
        "特徴抽出",
        "蒸留",
        "プルーニング"
      ],
      "answer": 0,
      "explanation": "ファインチューニングは、事前学習で得た汎用的な特徴を前提に、目的のタスクに特化させるために全パラメータ（または一部）を更新する手法です。"
    },
    {
      "id": 104,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "ある領域（ソースドメイン）で学習したモデルの知識を、別の関連する領域（ターゲットドメイン）の学習に利用することで、少ないデータでも高性能を得やすくする手法の総称は何か。",
      "options": [
        "転移学習",
        "アンサンブル学習",
        "教師なし学習",
        "強化学習"
      ],
      "answer": 0,
      "explanation": "転移学習 (Transfer Learning) は、ImageNetなどで学習済みモデルを別の画像診断に使うなど、知識の再利用を行う非常に実践的なアプローチです。"
    },
    {
      "id": 105,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "軽量化",
      "question": "大きなモデル（教師モデル）の出力（ソフトターゲット）を、小さなモデル（生徒モデル）に模倣させることで、精度を保ちつつモデルを軽量化する手法はどれか。",
      "options": [
        "知識の蒸留",
        "枝刈り",
        "量子化",
        "ドロップアウト"
      ],
      "answer": 0,
      "explanation": "知識の蒸留 (Distillation) は、単なる正解ラベルだけでなく、教師モデルが出力する確率分布（迷いも含めた情報）を学習することで、生徒モデルの性能を引き上げます。"
    },
    {
      "id": 106,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "攻撃",
      "question": "入力画像に人間には知覚できない微小なノイズを加えることで、AI（分類器）を誤認識させる攻撃手法を何と呼ぶか。",
      "options": [
        "Adversarial Examples",
        "ポイズニング攻撃",
        "モデル反転攻撃",
        "メンバーシップ推論攻撃"
      ],
      "answer": 0,
      "explanation": "Adversarial Examplesは、ディープラーニングモデルの脆弱性を突く攻撃で、自動運転の標識誤認識などのリスクが懸念されています。"
    },
    {
      "id": 107,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "説明可能性",
      "question": "ブラックボックスになりがちなAIの判断根拠を説明するための手法で、局所的に線形モデルで近似して「なぜその予測になったか」を解釈する手法はどれか。",
      "options": [
        "LIME",
        "SHAP",
        "Grad-CAM",
        "t-SNE"
      ],
      "answer": 0,
      "explanation": "LIMEは、特定の入力データの周辺にデータを生成してモデルの挙動を調べ、簡易なモデルでその振る舞いを近似することで説明を行います。"
    },
    {
      "id": 108,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "説明可能性",
      "question": "CNNの判断根拠を可視化する手法で、最後の畳み込み層の勾配情報を使って、画像のどの部分が予測に寄与したかをヒートマップで表示する手法はどれか。",
      "options": [
        "Grad-CAM",
        "LIME",
        "Saliency Map",
        "Attention Map"
      ],
      "answer": 0,
      "explanation": "Grad-CAM (Gradient-weighted Class Activation Mapping) は、特定のクラス判定にとって重要な領域を赤く表示するなど、視覚的な説明に優れています。"
    },
    {
      "id": 109,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "計算資源",
      "question": "Googleが開発した、ディープラーニング（特にテンソル計算）に特化した専用プロセッサはどれか。",
      "options": [
        "TPU",
        "GPU",
        "CPU",
        "FPGA"
      ],
      "answer": 0,
      "explanation": "TPUはGoogleが自社のAIサービスやTensorFlow処理を加速するために開発したASIC（特定用途向け集積回路）です。"
    },
    {
      "id": 110,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "軽量化",
      "question": "モデルのパラメータ（重み）の数値を、32bit浮動小数点数から8bit整数などに変換し、メモリ使用量と計算量を削減する手法はどれか。",
      "options": [
        "量子化",
        "プルーニング / 枝刈り",
        "蒸留",
        "正則化"
      ],
      "answer": 0,
      "explanation": "量子化 (Quantization) は、表現精度を落とすことでモデルサイズを劇的に小さくし、エッジデバイス等での推論を高速化します。"
    },
    {
      "id": 111,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "プライバシー",
      "question": "データを中央サーバに集約せず、各デバイス（エッジ）上で学習を行い、学習したパラメータ（勾配）のみをサーバに送って統合する手法はどれか。",
      "options": [
        "連合学習 / フェデレーテッドラーニング",
        "分散学習",
        "転移学習",
        "マルチタスク学習"
      ],
      "answer": 0,
      "explanation": "連合学習 (Federated Learning) は、個人のプライバシーデータ（スマホの入力履歴など）を外部に出さずに、AIモデルの学習を行える技術です。"
    },
    {
      "id": 112,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "自動化",
      "question": "ニューラルネットワークの最適なアーキテクチャ（層の数や結合方法など）を、AI自身に探索・設計させる技術を何と呼ぶか。",
      "options": [
        "NAS",
        "HPO",
        "RPA",
        "GAN"
      ],
      "answer": 0,
      "explanation": "NAS（ニューラルアーキテクチャ探索）は、強化学習や進化的アルゴリズムを用いて、人間が設計するよりも高性能なモデル構造を自動発見することを目指します。"
    },
    {
      "id": 113,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "課題",
      "question": "以前学習したタスクの後に新しいタスクを学習させると、以前のタスクの知識が急激に失われてしまう現象を何と呼ぶか。",
      "options": [
        "破滅的忘却",
        "勾配消失",
        "過学習",
        "モード崩壊"
      ],
      "answer": 0,
      "explanation": "破滅的忘却 (Catastrophic Forgetting) は、ニューラルネットワークが新しい情報を学習する際に、既存の重みを大きく書き換えてしまうことで発生する、継続学習の主要な課題です。"
    },
    {
      "id": 114,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "定義",
      "question": "「学習の仕方を学習する（Learning to Learn）」ことで、新しいタスクに対して少量のデータで素早く適応できるモデルを目指すアプローチはどれか。",
      "options": [
        "メタ学習",
        "転移学習",
        "マルチタスク学習",
        "オンライン学習"
      ],
      "answer": 0,
      "explanation": "メタ学習には、MAML (Model-Agnostic Meta-Learning) などの手法があり、未知のタスクへの適応能力（汎化能力）を高めることを目的としています。"
    },
    {
      "id": 115,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "手法",
      "question": "ラベルのない大量のデータから、データ自身の変換（回転、切り抜き、色変換など）を用いて「同じ画像から作られたものは近く、違う画像は遠く」なるように表現を学習する手法はどれか。",
      "options": [
        "対照学習",
        "敵対的学習",
        "能動学習",
        "強化学習"
      ],
      "answer": 0,
      "explanation": "SimCLRやMoCoなどの対照学習 (Contrastive Learning) は、自己教師あり学習の一種として、ラベルなしデータから強力な画像特徴表現を獲得できます。"
    },
    {
      "id": 116,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "生成AIの手法",
      "question": "スタンフォード大学の研究者らが提唱した、広範なデータで大規模に学習され、様々な下流タスクに適応可能なモデル（BERT, GPT-3, CLIPなど）を指す用語は何か。",
      "options": [
        "基盤モデル / ファウンデーションモデル",
        "汎用人工知能",
        "エキスパートシステム",
        "ラージモデル"
      ],
      "answer": 0,
      "explanation": "基盤モデル (Foundation Models) は、一つの巨大なモデルが、翻訳、要約、画像生成、コード生成など多岐にわたるタスクの「基盤」として機能するパラダイムシフトを表しています。"
    },
    {
      "id": 117,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "マルチモーダル",
      "question": "テキスト、画像、音声、動画など、複数の種類のデータを同時に処理・理解できるAIを何と呼ぶか。",
      "options": [
        "マルチモーダルAI",
        "クロスドメインAI",
        "ハイブリッドAI",
        "シンボリックAI"
      ],
      "answer": 0,
      "explanation": "GPT-4VやGeminiのように、テキストだけでなく画像を見て内容を理解したり、音声を扱えるAIがマルチモーダルAIです。"
    },
    {
      "id": 118,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "テクニック",
      "question": "LLMに対して「ステップバイステップで考えて」と指示したり、推論過程の例示を与えたりすることで、論理的な推論精度を向上させる手法は何か。",
      "options": [
        "Chain-of-Thought  プロンプティング",
        "Few-shot プロンプティング",
        "Zero-shot プロンプティング",
        "ReAct"
      ],
      "answer": 0,
      "explanation": "Chain-of-Thought (思考の連鎖) は、答えだけでなく「考え方の手順」を出力させることで、複雑な計算や推論の問題解決能力を引き出す手法です。"
    },
    {
      "id": 119,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AI倫理",
      "question": "LLMが、事実とは異なる内容や架空の情報を、あたかも事実であるかのようにもっともらしく生成してしまう現象を何と呼ぶか。",
      "options": [
        "ハルシネーション / 幻覚",
        "バイアス",
        "破滅的忘却",
        "オーバフィッティング"
      ],
      "answer": 0,
      "explanation": "ハルシネーション (Hallucination) は、LLMが確率的に次の単語を予測する仕組みであることに起因し、整合性がとれていても事実ではないことを言ってしまう問題です。"
    },
    {
      "id": 120,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "技術",
      "question": "LLMが学習していない最新情報や社内ドキュメントなどの外部知識を検索し、その情報をプロンプトに含めることで回答精度を高める仕組みは何か。",
      "options": [
        "RAG",
        "Fine-tuning",
        "RLHF",
        "LoRA"
      ],
      "answer": 0,
      "explanation": "RAG（検索拡張生成）は、検索エンジンやデータベースとLLMを組み合わせることで、ハルシネーションを抑制しつつ、最新知識に基づいた回答を生成させる技術です。"
    },
    {
      "id": 121,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AI規制",
      "question": "EU（欧州連合）において、AIのリスクレベルに応じて禁止や義務を定める法規制案（2024年成立）を何と呼ぶか。",
      "options": [
        "AI法",
        "GDPR",
        "デジタルサービス法",
        "デジタル市場法"
      ],
      "answer": 0,
      "explanation": "AI法 (EU AI Act) は、AIシステムをリスク（許容できないリスク、高リスク、限定的リスク、最小リスク）に分類し、リスクに応じた規制を適用する世界初の包括的なAI規制法です。"
    },
    {
      "id": 122,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "法規制・権利",
      "question": "日本の著作権法第30条の4において、著作物をAIの学習データ（情報解析）として利用することが原則として適法とされる要件として、正しいものはどれか。",
      "options": [
        "著作権者の利益を不当に害する場合を除き、営利・非営利を問わず利用できる",
        "非営利目的かつ学術研究目的に限って利用できる",
        "事前に著作権者から許諾を得た場合のみ利用できる",
        "元データがクリエイティブ・コモンズライセンスである場合のみ利用できる"
      ],
      "answer": 0,
      "explanation": "日本の著作権法30条の4では、「享受」を目的としない情報解析のための利用（AI学習など）については、原則として権利者の許諾なく行えることが規定されています。"
    },
    {
      "id": 123,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "著作権侵害",
      "question": "AI生成物が既存の著作物の著作権侵害とされる要件である「依拠性」と「類似性」のうち、「依拠性」が意味するものはどれか。",
      "options": [
        "既存の著作物を知っていて、それに基づいていること",
        "生成物が既存の著作物と外見上よく似ていること",
        "生成者が著作権者に対して対価を支払っていないこと",
        "AI生成物が商用利用されていること"
      ],
      "answer": 0,
      "explanation": "著作権侵害が成立するには、既存の著作物に似ている（類似性）だけでなく、その著作物に依拠して作成された（依拠性）ことが必要です。"
    },
    {
      "id": 124,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "法規制・権利",
      "question": "個人情報保護法において、人種、信条、社会的身分、病歴、犯罪歴など、不当な差別や偏見が生じないよう、特に慎重な取り扱いが求められる情報を何と呼ぶか。",
      "options": [
        "要配慮個人情報",
        "特定個人情報",
        "仮名加工情報",
        "匿名加工情報"
      ],
      "answer": 0,
      "explanation": "要配慮個人情報は、本人の同意なく取得することが原則禁止されており、AI学習データとして利用する際も特に注意が必要です。"
    },
    {
      "id": 125,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "法規制・権利",
      "question": "GDPR（EU一般データ保護規則）において、AIによる完全自動化された意思決定（プロファイリングなど）に対して異議を唱え、人間による関与を求める権利を何と呼ぶか。",
      "options": [
        "説明を求める権利 / 人間の関与を求める権利",
        "忘れられる権利",
        "データポータビリティの権利",
        "アクセス権"
      ],
      "answer": 0,
      "explanation": "GDPR第22条では、法的効果をもたらすような自動化された意思決定のみに服さない権利が認められています。"
    },
    {
      "id": 126,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "偽情報",
      "question": "AIを用いて、実在する人物の顔や声を合成し、実際には言っていないことを言っているように見せる動画などの偽情報を何と呼ぶか。",
      "options": [
        "ディープフェイク",
        "フィルターバブル",
        "エコーチェンバー",
        "フィッシング"
      ],
      "answer": 0,
      "explanation": "ディープフェイクは、GANなどの生成技術を用いて作られた高度な偽メディアであり、政治的偽情報やポルノへの悪用が社会問題化しています。"
    },
    {
      "id": 127,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AI倫理",
      "question": "新しい科学技術が社会に導入される際に生じる「倫理的・法的・社会的課題」の頭文字をとった言葉は何か。",
      "options": [
        "ELSI",
        "SDGs",
        "ESG",
        "CSR"
      ],
      "answer": 0,
      "explanation": "AI開発においては、技術的な性能だけでなく、ELSIの観点から社会への影響を考慮することが不可欠です。"
    },
    {
      "id": 128,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "バイアス",
      "question": "検索エンジンやSNSのレコメンド機能により、自分の好みに合う情報ばかりが表示され、それ以外の情報から隔離されてしまう現象を何と呼ぶか。",
      "options": [
        "フィルターバブル",
        "エコーチェンバー",
        "確証バイアス",
        "バンドワゴン効果"
      ],
      "answer": 0,
      "explanation": "フィルターバブルは、アルゴリズムによるパーソナライズの結果、ユーザーが意図せず偏った情報環境に置かれてしまう問題を指します。"
    },
    {
      "id": 129,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "バイアス",
      "question": "SNSなどで、自分と同じ意見の人々とばかり交流することで、特定の意見や思想が増幅・強化されてしまう閉鎖的な状況を何と呼ぶか。",
      "options": [
        "エコーチェンバー現象",
        "フィルターバブル",
        "集団浅慮",
        "フレーミング効果"
      ],
      "answer": 0,
      "explanation": "エコーチェンバー（反響室）現象は、同じような意見が反響し合うことで、あたかもそれが世の中の常識であるかのように錯覚してしまう現象です。"
    },
    {
      "id": 130,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AI倫理",
      "question": "AIの公平性において、意図的な差別がなくても、結果として特定のグループに不利益が生じること（例：特定の地域への採用率が低い）を何と呼ぶか。",
      "options": [
        "不公平なインパクト",
        "不公平な扱い",
        "逆差別",
        "統計的差別"
      ],
      "answer": 0,
      "explanation": "Disparate Impactは、手続き自体は中立に見えても、結果的にマイノリティなどに著しい不利益を与えることを指し、これも差別とみなされる場合があります。"
    },
    {
      "id": 131,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AI倫理",
      "question": "AIシステムの動作原理や学習データなどが外部から検証可能であることを指す言葉で、「説明可能性 (Explainability)」と密接に関連する概念は何か。",
      "options": [
        "透明性",
        "頑健性",
        "再現性",
        "アカウンタビリティ"
      ],
      "answer": 0,
      "explanation": "透明性 (Transparency) は、AIがどのように作られ、動作しているかがブラックボックスになっていない状態を指し、信頼性の基盤となります。"
    },
    {
      "id": 132,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "責任",
      "question": "AIシステムの判断や結果に対して、最終的に人間が責任を負うべきであるという考え方や、AIの運用中に人間が関与し続ける仕組みを指す言葉はどれか。",
      "options": [
        "Human-in-the-loop",
        "End-to-End",
        "Peer-to-Peer",
        "Zero-shot"
      ],
      "answer": 0,
      "explanation": "Human-in-the-loopは、AIの処理プロセスの中に人間の判断や監視を組み込むことで、誤りを防ぎ、責任の所在を明確にするアプローチです。"
    },
    {
      "id": 133,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "軍事利用",
      "question": "顔認識技術やドローン制御などのAI技術が、民生用だけでなく軍事用にも利用可能であるという性質（両義性）を何と呼ぶか。",
      "options": [
        "デュアルユース",
        "ダブルスタンダード",
        "マルチモーダル",
        "ハイブリッド戦争"
      ],
      "answer": 0,
      "explanation": "デュアルユース技術は、平和利用のために開発されても、容易に兵器や監視などの軍事目的に転用できるリスクを持っています。"
    },
    {
      "id": 134,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "レベル定義",
      "question": "自動運転のレベル定義において、「条件付き自動運転」と呼ばれ、システムが運転を行うが、緊急時などシステムからの要請があればドライバーが運転を交代しなければならないレベルはどれか。",
      "options": [
        "レベル3",
        "レベル2",
        "レベル4",
        "レベル5"
      ],
      "answer": 0,
      "explanation": "レベル3では、特定の条件下（高速道路など）でシステムが主体となって運転しますが、ドライバーはいつでも運転に戻れる状態で待機する必要があります。"
    },
    {
      "id": 135,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "モビリティ",
      "question": "電車、バス、タクシー、シェアサイクルなどの様々な移動手段を、ITを用いてシームレスにつなぎ、一つのサービスとして提供する概念は何か。",
      "options": [
        "MaaS",
        "SaaS",
        "CASE",
        "IoT"
      ],
      "answer": 0,
      "explanation": "MaaSは、移動を単なる手段ではなくサービスとして捉え、検索・予約・決済を一括で行えるようにすることで利便性を高めます。"
    },
    {
      "id": 136,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "医療AI",
      "question": "AIを用いた診断支援システムなどが該当する、「プログラム医療機器」の略称は何か。",
      "options": [
        "SaMD",
        "IoMT",
        "PHR",
        "EHR"
      ],
      "answer": 0,
      "explanation": "SaMDは、ハードウェアの医療機器と一体ではなく、汎用PCやスマホなどで動作する医療用プログラムを指し、薬機法の規制対象となります。"
    },
    {
      "id": 137,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "原則",
      "question": "日本の内閣府が策定した「人間中心のAI社会原則」に含まれないものはどれか。",
      "options": [
        "AIの法的権利の確立",
        "プライバシーの確保",
        "公平性、説明責任及び透明性の確保",
        "セキュリティの確保"
      ],
      "answer": 0,
      "explanation": "現在のところ、AI自体に法的な権利（人権のようなもの）を認めることは原則に含まれていません。あくまで人間が中心で、道具としてAIを使う考え方です。"
    },
    {
      "id": 138,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "課題",
      "question": "AIプロジェクトにおいて、概念実証（PoC）ばかりを繰り返し、なかなか本番運用や実用化に進まない状況を何と呼ぶか。",
      "options": [
        "PoC疲れ / 死の谷",
        "パレートの法則",
        "技術的負債",
        "シンギュラリティ"
      ],
      "answer": 0,
      "explanation": "「PoC死」や「PoC疲れ」は、とりあえず試作（PoC）はするものの、費用対効果が見えないなどの理由でプロジェクトが頓挫することを指します。"
    },
    {
      "id": 139,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "手法",
      "question": "仕様を最初にすべて決めてから作るウォーターフォール型に対し、短いサイクルで開発・テスト・改善を繰り返す、AI開発に適した手法は何か。",
      "options": [
        "アジャイル開発",
        "スパイラルモデル",
        "V字モデル",
        "プロトタイピング"
      ],
      "answer": 0,
      "explanation": "AI開発は試行錯誤（正解率がどのくらい出るかやってみないとわからない）が不可避なため、柔軟に変更対応できるアジャイル開発が適しています。"
    },
    {
      "id": 140,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "管理・運用",
      "question": "機械学習モデルの開発（Dev）と運用（Ops）を統合し、継続的な学習・デプロイ・監視を行うための取り組みや基盤を何と呼ぶか。",
      "options": [
        "MLOps",
        "DevOps",
        "AIOps",
        "NoOps"
      ],
      "answer": 0,
      "explanation": "MLOpsは、単なるソフトウェアのDevOpsに加え、データのバージョン管理やモデルの劣化（ドリフト）監視など、ML特有の課題に対応する概念です。"
    },
    {
      "id": 141,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "モデル劣化",
      "question": "AIモデル運用中に、入力データの傾向や環境が変化することで、当初の精度が出なくなってしまう現象を総称して何と呼ぶか。",
      "options": [
        "ドリフト",
        "過学習",
        "バイアス",
        "ハルシネーション"
      ],
      "answer": 0,
      "explanation": "ドリフトは、市場環境の変化や季節性などにより、学習時のデータ分布と推論時のデータ分布がズレることで発生します。再学習が必要です。"
    },
    {
      "id": 142,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "データの扱い",
      "question": "大規模なデータセットの情報を、性能を落とさずにごく少数の合成画像などに凝縮する技術を何と呼ぶか。",
      "options": [
        "データセット蒸留",
        "データ拡張",
        "データクレンジング",
        "アノテーション"
      ],
      "answer": 0,
      "explanation": "データセット蒸留は、学習効率の向上や、プライバシー保護（元画像そのものを保持しなくて済む）の観点で注目されています。"
    },
    {
      "id": 143,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "防御",
      "question": "Adversarial Examples（敵対的サンプル）への防御策として、敵対的サンプル自体を学習データに含めて再学習させる手法はどれか。",
      "options": [
        "敵対的学習",
        "正則化",
        "蒸留",
        "アンサンブル学習"
      ],
      "answer": 0,
      "explanation": "敵対的学習は、攻撃に対してモデルを堅牢（ロバスト）にする最も直接的かつ強力な手法の一つです。"
    },
    {
      "id": 144,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AI倫理",
      "question": "AIによって生成された画像やテキストであることを識別するために、目に見えない信号やパターンを埋め込む技術は何か。",
      "options": [
        "電子透かし / ウォーターマーク",
        "電子署名",
        "暗号化",
        "ハッシュ化"
      ],
      "answer": 0,
      "explanation": "生成AIの普及に伴い、AI生成コンテンツの明示や、偽情報対策として、電子透かし（Watermarking）の技術開発と標準化が進められています。"
    },
    {
      "id": 145,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ライセンス",
      "question": "インターネット上の著作物に対し、「表示(BY)」「非営利(NC)」「改変禁止(ND)」「継承(SA)」などの条件を組み合わせて利用許諾を表示するライセンス体系は何か。",
      "options": [
        "クリエイティブ・コモンズ・ライセンス",
        "GPL",
        "MITライセンス",
        "Apacheライセンス"
      ],
      "answer": 0,
      "explanation": "CCライセンスは、著作者が自分の作品を一定の条件の下で自由に利用してよいという意思表示をするための標準的なツールです。"
    },
    {
      "id": 146,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "モデル公開",
      "question": "Meta社のLlama 2のように、モデルの重みパラメータが公開されており、条件付きで商用利用や改変が可能なモデルを一般に何と呼ぶか。",
      "options": [
        "オープンソースモデル",
        "プロプライエタリモデル",
        "クローズドソースモデル",
        "SaaSモデル"
      ],
      "answer": 0,
      "explanation": "厳密なOSI定義のオープンソースとは異なる場合もありますが、重みが公開されているモデルはオープンモデルと呼ばれ、開発の民主化を促進しています。"
    },
    {
      "id": 147,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "エコシステム",
      "question": "自社でAIモデルを開発するのではなく、GoogleやOpenAIなどが提供するAPIを利用してサービスを構築する経済圏を何と呼ぶか。",
      "options": [
        "APIエコノミー",
        "ギグエコノミー",
        "シェアリングエコノミー",
        "トークンエコノミー"
      ],
      "answer": 0,
      "explanation": "APIエコノミーの拡大により、高度なAI技術を持たない企業でも、API経由で最新のAI機能を自社サービスに組み込めるようになりました。"
    },
    {
      "id": 148,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "メリット",
      "question": "クラウドではなくデバイス側（エッジ）でAI処理を行うメリットとして、適切でないものはどれか。",
      "options": [
        "大規模な学習データを無制限に蓄積・処理できる",
        "通信遅延を小さくできる",
        "プライバシー情報を外部に出さずに済む",
        "通信環境がない場所でも動作する"
      ],
      "answer": 0,
      "explanation": "大規模なデータの蓄積や、巨大なモデルの学習はクラウドの方が適しています。エッジのメリットは応答速度、プライバシー、通信コスト削減などです。"
    },
    {
      "id": 149,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "環境",
      "question": "AIモデルの巨大化に伴う消費電力の増大を懸念し、エネルギー効率の良いAI開発や運用を目指す取り組みを何と呼ぶか。",
      "options": [
        "グリーンAI",
        "レッドAI",
        "ブルーAI",
        "サステナブルAI"
      ],
      "answer": 0,
      "explanation": "精度追求のために計算資源を大量消費する「レッドAI」に対し、環境負荷を低減し効率を重視する考え方が「グリーンAI」です。"
    },
    {
      "id": 150,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "雇用",
      "question": "AIやロボットによる自動化が進むことで、人間の雇用が奪われ失業者が増加するという懸念を表す言葉は何か。",
      "options": [
        "技術的失業",
        "構造的失業",
        "摩擦的失業",
        "循環的失業"
      ],
      "answer": 0,
      "explanation": "技術的失業は、ケインズも予言した概念ですが、一方で新しい職種が生まれるという反論もあり、リスキリング（再教育）が重要視されています。"
    },
    {
      "id": 151,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "国際指針",
      "question": "2019年に採択された、AIが人々の生活を豊かにし、信頼できるものであるための国際的な政策指針はどれか。",
      "options": [
        "OECD AI原則",
        "アジロマーAI原則",
        "アシモフのロボット三原則",
        "国連憲章"
      ],
      "answer": 0,
      "explanation": "OECD AI原則は、包摂的成長、人間中心の価値観、透明性、セキュリティ、説明責任などを掲げ、G20 AI原則の基礎ともなりました。"
    },
    {
      "id": 152,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "国際指針",
      "question": "2021年にユネスコ（UNESCO）総会で採択された、AIの開発・利用に関する初の世界的な倫理勧告は何か。",
      "options": [
        "AIの倫理に関する勧告",
        "世界人権宣言",
        "持続可能な開発目標",
        "京都議定書"
      ],
      "answer": 0,
      "explanation": "この勧告は、AIが人権や人間の尊厳を侵害しないよう、加盟国に対して法整備や政策立案を促すものです。"
    },
    {
      "id": 153,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "国際指針",
      "question": "2023年のG7サミットを機に発足した、生成AIに関する国際的なルール作りやガバナンスを議論する枠組みは何か。",
      "options": [
        "広島AIプロセス",
        "ダボス会議",
        "パリ協定",
        "ブレットン・ウッズ体制"
      ],
      "answer": 0,
      "explanation": "広島AIプロセスでは、生成AIの開発者向けの国際指針や行動規範などが策定されました。"
    },
    {
      "id": 154,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "規制のあり方",
      "question": "法律のような強制力のある規制（ハードロー）に対し、企業の自主ガイドラインや倫理規定など、法的拘束力はないが実効性を持つ規範を何と呼ぶか。",
      "options": [
        "ソフトロー",
        "コモンロー",
        "自然法",
        "判例法"
      ],
      "answer": 0,
      "explanation": "AI技術の進化は速いため、法改正が追いつかない部分は、柔軟なソフトローによってガバナンスを効かせることが重要とされています。"
    },
    {
      "id": 155,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "企業",
      "question": "企業がAIを開発・利活用する際に、リスク管理や倫理的な整合性を保つための社内体制やルールのことを何と呼ぶか。",
      "options": [
        "AIガバナンス",
        "コンプライアンス",
        "コーポレートガバナンス",
        "内部統制"
      ],
      "answer": 0,
      "explanation": "AIガバナンスは、AIによる事故や不祥事を防ぎ、社会からの信頼を得てAI活用を推進するために不可欠な経営課題です。"
    },
    {
      "id": 156,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "リスク",
      "question": "AIの誤判断などにより損害が生じた場合に備え、リスクを移転するための金融商品は何か。",
      "options": [
        "AI保険",
        "デリバティブ",
        "クラウドファンディング",
        "ストックオプション"
      ],
      "answer": 0,
      "explanation": "AI特有のリスク（ハルシネーションによる権利侵害や、システムの予期せぬ挙動など）をカバーするAI専用保険が登場しています。"
    },
    {
      "id": 157,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "教育",
      "question": "DXやAI導入に伴い、従業員が新しいスキル（AIリテラシーやプログラミングなど）を習得し、業務内容の変化に適応することを何と呼ぶか。",
      "options": [
        "リスキリング",
        "OJT",
        "リカレント教育",
        "アクティブラーニング"
      ],
      "answer": 0,
      "explanation": "リスキリングは、単なる学び直しではなく、「新しい職業や業務に就くために」スキルを獲得するという再職業訓練のニュアンスが強いです。"
    },
    {
      "id": 158,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "関係性",
      "question": "AIが人間に取って代わるのではなく、AIが人間の能力を拡張し、人間とAIが協力して問題解決を行うあり方を何と呼ぶか。",
      "options": [
        "Human-AI Collaboration / 協調",
        "対立",
        "服従",
        "排他"
      ],
      "answer": 0,
      "explanation": "AIが得意なこと（計算、パターン認識）と人間が得意なこと（創造、文脈理解、倫理判断）を組み合わせることで、最大の価値を生み出す考え方です。"
    },
    {
      "id": 159,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AIの汎用性",
      "question": "特定のタスクだけでなく、人間と同じようにあらゆる知的タスクをこなすことができる、汎用性の高い人工知能を何と呼ぶか。",
      "options": [
        "汎用人工知能",
        "特化型AI",
        "弱いAI",
        "古典的AI"
      ],
      "answer": 0,
      "explanation": "現在のAIの多くは特化型AIですが、AGIの実現はAI研究の究極の目標の一つであり、急速な進化により現実味を帯びて議論されています。"
    },
    {
      "id": 160,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "まとめ",
      "question": "G検定（ジェネラリスト検定）の目的として、最も適切なものはどれか。",
      "options": [
        "AIを事業活用するために必要な体系的な知識を持ち、エンジニアと橋渡しができる人材を育成する",
        "Pythonによる高度なプログラミング実装能力を持つ人材を認定する",
        "新しいAIアルゴリズムを数学的に証明できる研究者を育成する",
        "AIに関する法律の専門家を認定する"
      ],
      "answer": 0,
      "explanation": "G検定は、エンジニア（E資格）とは異なり、ビジネスの現場でAIを有効活用するための「ジェネラリスト」としてのリテラシーを認定する試験です。"
    },
    {
      "id": 159,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "法的権利",
      "question": "AI技術の進展に伴い議論されている「ロボット（AI）に法的権利を認めるべきか」という論点に関し、現時点での一般的な法的解釈として正しいものはどれか。",
      "options": [
        "AI自体は権利の主体とはみなされない",
        "AIは製造された時点で人間と同等の人権を持つ",
        "高度な推論が可能なAIは特定の国において市民権を得ている",
        "AIが独自に創作した著作物はAI自身に著作権が帰属する"
      ],
      "answer": 0,
      "explanation": "現行の法体系において、権利や義務の主体となれるのは「自然人」および「法人」のみです。AIは道具（物）として扱われ、権利の主体とはみなされません。"
    }
  ]
}