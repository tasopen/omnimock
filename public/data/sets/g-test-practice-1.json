{
  "metadata": {
    "title": "G検定 模擬試験 1",
    "description": "JDLA_G検定シラバス2024対応 実戦形式160問",
    "totalQuestions": 160,
    "passLine": 70,
    "timeLimit": 100
  },
  "questions": [
    {
      "id": 1,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の定義",
      "question": "人工知能のレベル分類において、特定のアルゴリズムに基づき学習を行わず、あらかじめ決められたルールに従って動作するレベルはどれか。",
      "options": [
        "レベル1：単純な制御プログラム",
        "レベル2：古典的な人工知能",
        "レベル3：機械学習を取り入れた人工知能",
        "レベル4：ディープラーニングを取り入れた人工知能"
      ],
      "answer": 0,
      "explanation": "レベル1はエアコンや洗濯機などの単純な制御プログラムを指します。"
    },
    {
      "id": 2,
      "majorCategory": "人工知能とは",
      "subCategory": "エージェント",
      "question": "環境を観測し、その情報に基づいて行動を選択し、環境に働きかける実体のことを何と呼ぶか。",
      "options": [
        "エージェント",
        "コントローラ",
        "プロセッサ",
        "アクチュエータ"
      ],
      "answer": 0,
      "explanation": "AIの世界では、環境との相互作用を行う主体をエージェントと呼びます。"
    },
    {
      "id": 3,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "探索・推論",
      "question": "迷路の解法などで、現在の状態から到達可能なすべての状態を調べ、目的の状態を見つける手法の総称はどれか。",
      "options": [
        "探索",
        "推論",
        "学習",
        "認識"
      ],
      "answer": 0,
      "explanation": "目的の状態に到達するための手順を探すことを探索と呼びます。"
    },
    {
      "id": 4,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "第1次AIブーム",
      "question": "1960年代の第1次AIブームにおいて、チェスやパズルのようなパズル的な問題は解けたが、現実の複雑な問題は解けなかった限界を何と呼ぶか。",
      "options": [
        "トイ・プロブレム",
        "フレーム問題",
        "シンボルグラウンディング問題",
        "組合せ爆発"
      ],
      "answer": 0,
      "explanation": "トイ・プロブレムは、単純なルール下の問題しか解けなかった当時の限界を象徴する言葉です。"
    },
    {
      "id": 5,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "探索手法",
      "question": "探索において、現在のノードから一番近いノード（浅い階層）を優先的に探索する手法はどれか。",
      "options": [
        "幅優先探索",
        "深さ優先探索",
        "モンテカルロ法",
        "αβ法"
      ],
      "answer": 0,
      "explanation": "幅優先探索は、上の階層から順に横に広げていく手法です。"
    },
    {
      "id": 6,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習用データ",
      "question": "機械学習において、モデルの学習には使用せず、最終的な性能を評価するためにのみ使用するデータを何と呼ぶか。",
      "options": [
        "テストデータ",
        "訓練データ",
        "検証用データ",
        "教師データ"
      ],
      "answer": 0,
      "explanation": "テストデータ（ホールドアウトデータ）は、モデルの汎化性能を最終確認するために隔離保存されるデータです。"
    },
    {
      "id": 7,
      "majorCategory": "機械学習の概要",
      "subCategory": "特徴量",
      "question": "データの予測に寄与する、対象を特徴づける変数のことを何と呼ぶか。",
      "options": [
        "特徴量",
        "ハイパーパラメータ",
        "損失関数",
        "活性化関数"
      ],
      "answer": 0,
      "explanation": "機械学習では、入力データのどの部分に着目するかを数値化したものを特徴量と呼びます。"
    },
    {
      "id": 8,
      "majorCategory": "機械学習の概要",
      "subCategory": "回帰",
      "question": "線形回帰において、予測値と実際の値の差の2乗の平均を最小化するようにパラメータを決定する手法はどれか。",
      "options": [
        "最小二乗法",
        "最尤推定法",
        "ベイズ推定",
        "アンサンブル学習"
      ],
      "answer": 0,
      "explanation": "最小二乗法は、残差平方和を最小にする回帰直線を求める基本的な手法です。"
    },
    {
      "id": 9,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師なし学習",
      "question": "似た性質を持つデータ同士をグループに分ける手法を何というか。",
      "options": [
        "クラスタリング",
        "回帰",
        "分類",
        "強化学習"
      ],
      "answer": 0,
      "explanation": "正解ラベルがないデータから構造を見出す教師なし学習の代表例がクラスタリングです。"
    },
    {
      "id": 10,
      "majorCategory": "機械学習の概要",
      "subCategory": "次元の呪い",
      "question": "特徴量の数（次元数）が増えすぎると、学習に必要なデータ量が指数関数的に増大し、精度が低下する現象を何というか。",
      "options": [
        "次元の呪い",
        "オーバーフィッティング",
        "局所最適解",
        "勾配消失"
      ],
      "answer": 0,
      "explanation": "高次元空間ではデータが疎になり、学習が困難になることを次元の呪いと呼びます。"
    },
    {
      "id": 11,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ニューラルネットワーク",
      "question": "ニューラルネットワークの基本的な単位であり、人間の神経細胞を模したものを何と呼ぶか。",
      "options": [
        "パーセプトロン",
        "ニューロン",
        "シナプス",
        "レイヤー"
      ],
      "answer": 1,
      "explanation": "モデル上の計算単位はニューロンまたはユニットと呼ばれます。パーセプトロンはそれを用いたアルゴリズム全体を指すことが多いです。"
    },
    {
      "id": 12,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "誤差逆伝播法",
      "question": "出力層で生じた誤差を逆向きに伝えて各層の重みを更新する手法を何というか。",
      "options": [
        "誤差逆伝播法",
        "順伝播",
        "勾配降下法",
        "正則化"
      ],
      "answer": 0,
      "explanation": "連鎖律を利用して効率的に勾配を計算する手法です。"
    },
    {
      "id": 13,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "活性化関数",
      "question": "中間層の活性化関数として、シグモイド関数と比較して勾配消失が起きにくい関数はどれか。",
      "options": [
        "ReLU関数",
        "恒等関数",
        "ステップ関数",
        "サイン関数"
      ],
      "answer": 0,
      "explanation": "ReLU（Rectified Linear Unit）はx>0で傾きが一定のため勾配が消失しにくい。"
    },
    {
      "id": 14,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "CNN",
      "question": "CNNにおいて、特徴マップを圧縮し、位置のずれに対する不変性を高める層を何というか。",
      "options": [
        "プーリング層",
        "畳み込み層",
        "全結合層",
        "正規化層"
      ],
      "answer": 0,
      "explanation": "Max Poolingなどは局所的な情報の集約（ダウンサンプリング）を行います。"
    },
    {
      "id": 15,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "RNN",
      "question": "時系列データのように順序があるデータを扱うのに適した、内部に再帰構造を持つネットワークはどれか。",
      "options": [
        "RNN",
        "CNN",
        "GAN",
        "Autoencoder"
      ],
      "answer": 0,
      "explanation": "RNN（Recurrent Neural Network）は過去の情報を保持しながら処理できます。"
    },
    {
      "id": 16,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Attention",
      "question": "Transformerの核心となる、入力のどの部分に注目すべきかを動的に計算する機構を何というか。",
      "options": [
        "Attention",
        "Dropout",
        "Normalization",
        "Pruning"
      ],
      "answer": 0,
      "explanation": "Self-Attentionなどの仕組みにより、文中の単語間の関係性を効率的に捉えます。"
    },
    {
      "id": 17,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "画像認識",
      "question": "画像の中から物体の位置（バウンディングボックス）と種類を特定するタスクを何と呼ぶか。",
      "options": [
        "物体検出",
        "画像分類",
        "セマンティックセグメンテーション",
        "超解像"
      ],
      "answer": 0,
      "explanation": "何がどこにあるかを当てるのが物体検出（Object Detection）です。"
    },
    {
      "id": 18,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "自然言語処理",
      "question": "大量のテキストデータを学習し、文脈を理解して高精度な文章生成を行うChatGPTなどのモデルの総称はどれか。",
      "options": [
        "LLM",
        "RNN",
        "LSTM",
        "HMM"
      ],
      "answer": 0,
      "explanation": "Large Language Modelの略です。"
    },
    {
      "id": 19,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "プロジェクトの進め方",
      "question": "AIプロジェクトにおいて、本格導入の前に小規模に実施して実現可能性を確認するプロセスを何というか。",
      "options": [
        "PoC",
        "MVP",
        "デプロイ",
        "アノテーション"
      ],
      "answer": 0,
      "explanation": "Proof of Conceptの略です。"
    },
    {
      "id": 20,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "個人情報保護法",
      "question": "特定の個人を識別できないように加工し、かつ復元できないようにした情報のことを何というか。",
      "options": [
        "匿名加工情報",
        "仮名加工情報",
        "個人識別符号",
        "センシティブデータ"
      ],
      "answer": 0,
      "explanation": "匿名加工情報は、元の個人を特定できないよう不可逆的に加工されたものです。"
    },
    {
      "id": 21,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "探索・推論",
      "question": "対戦ゲームなどで、相手が常に最善の手を打つと仮定して、自分の利益を最大化する手を選ぶアルゴリズムはどれか。",
      "options": [
        "Mini-Max法",
        "幅優先探索",
        "深さ優先探索",
        "ブロードキャスト"
      ],
      "answer": 0,
      "explanation": "Mini-Max法は、相手は最小化（自分のスコアを減らす）、自分は最大化する手を選ぶ手法です。"
    },
    {
      "id": 22,
      "majorCategory": "機械学習の概要",
      "subCategory": "評価指標",
      "question": "正解率（Accuracy）が不適切な評価指標となる代表的なケースはどれか。",
      "options": [
        "不均衡データ",
        "回帰問題",
        "データの欠損が多い場合",
        "モデルが複雑な場合"
      ],
      "answer": 0,
      "explanation": "99%が正常で1%が故障のデータでは、すべて正常と答えるだけで正解率99%になってしまうため、再現率などが重視されます。"
    },
    {
      "id": 23,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "正規化層",
      "question": "ミニバッチごとに各層の入力を正規化し、学習の安定化と高速化を図る技術はどれか。",
      "options": [
        "バッチ正規化",
        "レイヤー正規化",
        "Dropout",
        "Weigth Decay"
      ],
      "answer": 0,
      "explanation": "Batch Normalizationは、学習過程でデータの分布が変わる「内部共変量シフト」を抑制する効果があります。"
    },
    {
      "id": 24,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "公平性",
      "question": "AIが特定の性別や人種に対して不利益な予測を行うようになってしまう原因となる、データの偏りを何というか。",
      "options": [
        "アルゴリズムバイアス",
        "過学習",
        "局所解",
        "次元の呪い"
      ],
      "answer": 0,
      "explanation": "学習データに含まれる偏りがAIの判断に反映されてしまう問題です。"
    },
    {
      "id": 25,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "最適化手法",
      "question": "学習時の重みの更新量を表し、適切に設定しないと収束しなかったり局所解に陥ったりするパラメータはどれか。",
      "options": [
        "学習率",
        "バッチサイズ",
        "エポック数",
        "フィルタサイズ"
      ],
      "answer": 0,
      "explanation": "学習率は重みの微調整の幅を決定する最も重要なハイパーパラメータの一つです。"
    },
    {
      "id": 26,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "スキップ結合",
      "question": "層を飛び越して信号を伝える構造を持ち、勾配消失を防ぎ、超多層化を可能にしたResNet（Residual Network）の特徴的な構造はどれか。",
      "options": [
        "スキップ結合",
        "回帰結合",
        "プーリング",
        "畳み込み"
      ],
      "answer": 0,
      "explanation": "入力を出力にそのまま足すことで、層を深くしても学習が進みやすくなります。"
    },
    {
      "id": 27,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "著作権法",
      "question": "AIが生成した画像に「創作的寄与」が認められず、著作権が発生しないとされる主な理由はどれか。",
      "options": [
        "思想または感情を創作的に表現したものではないから",
        "コンピュータが作ったものはすべて公有財産だから",
        "著作者が人間ではないから",
        "デジタルデータには著作権がないから"
      ],
      "answer": 0,
      "explanation": "著作権法上の「著作物」は、人間が思想・感情を表現したものである必要があります。"
    },
    {
      "id": 28,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "計算リソース",
      "question": "並列計算能力に優れ、ニューラルネットワークの学習に多用されるプロセッサはどれか。",
      "options": [
        "GPU",
        "CPU",
        "ASIC",
        "RAM"
      ],
      "answer": 0,
      "explanation": "グラフィックス処理用のGPUは、行列演算の並列処理が得意なためAI学習に最適です。"
    },
    {
      "id": 29,
      "majorCategory": "機械学習の概要",
      "subCategory": "強化学習",
      "question": "AIが環境と相互作用し、将来得られる「報酬」の合計を最大化するように行動を学習する手法はどれか。",
      "options": [
        "強化学習",
        "教師あり学習",
        "教師なし学習",
        "転移学習"
      ],
      "answer": 0,
      "explanation": "エージェントが試行錯誤して最適戦略（方策）を学ぶのが強化学習です。"
    },
    {
      "id": 30,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "データ拡張",
      "question": "学習データの不足を補うため、画像を回転、反転、切り抜きするなどして水増しする手法を何というか。",
      "options": [
        "データ拡張",
        "正規化",
        "プルーニング",
        "蒸留"
      ],
      "answer": 0,
      "explanation": "モデルの汎化性能を高めるために一般的な手法です。"
    },
    {
      "id": 31,
      "majorCategory": "人工知能分野で議論される問題",
      "subCategory": "身体性",
      "question": "AIが知能を持つには、現実世界と干渉できる「体」を持つことが不可欠であるとする考え方を何というか。",
      "options": [
        "身体性",
        "強いAI",
        "シンギュラリティ",
        "フレーム問題"
      ],
      "answer": 0,
      "explanation": "感覚や行動を通じた経験が知識の形成に必要であるという主張です。"
    },
    {
      "id": 32,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "知識表現",
      "question": "概念と言語の関係をネットワーク状に表した図を何というか。",
      "options": [
        "意味ネットワーク",
        "オントロジー",
        "決定木",
        "ニューラルネット"
      ],
      "answer": 0,
      "explanation": "「is-a」などの関係で結ばれた知識表現形式です。"
    },
    {
      "id": 33,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "探索・推論",
      "question": "チェスや将棋などの完全情報確定ゲームにおいて、相手が最善手を指すと仮定して自分の利益を最大化する手法を何というか。",
      "options": [
        "αβ法",
        "Mini-Max法",
        "モンテカルロ木探索",
        "A*探索"
      ],
      "answer": 1,
      "explanation": "Mini-Max法（ミニマックス法）は、相手が自分にとって最も不利な手（相手にとっての最善手）を指すと仮定し、その中で自分の利益が最大になる手を選択する手法です。"
    },
    {
      "id": 34,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "知識表現",
      "question": "1984年にダグラス・レナートによって開始された、人間の持つ一般常識をすべてコンピュータに組み込もうとするプロジェクトを何というか。",
      "options": [
        "Cycプロジェクト",
        "第5世代コンピュータプロジェクト",
        "ELIZAプロジェクト",
        "シリアスゲームプロジェクト"
      ],
      "answer": 0,
      "explanation": "Cyc（サイク）プロジェクトは、人間と同等の常識知識を数千万件の「推論ルール」として記述し、汎用的な知能を実現しようとしたプロジェクトです。"
    },
    {
      "id": 35,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師あり学習",
      "question": "個々の学習器を並列に学習させ、それらの予測結果の平均や多数決をとるアンサンブル学習の手法を何というか。",
      "options": [
        "バギング",
        "ブースティング",
        "スタッキング",
        "ホールドアウト"
      ],
      "answer": 0,
      "explanation": "バギング（Bagging）は、ブートストラップサンプリングによって作成された複数のデータセットで個別のモデルを並列に学習させる手法です。代表例にランダムフォレストがあります。"
    },
    {
      "id": 36,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師あり学習",
      "question": "複数の学習器を逐次的に学習させ、前の学習器が間違えたデータに重みを付けて学習するアンサンブル学習の手法を何というか。",
      "options": [
        "バギング",
        "ブースティング",
        "スタッキング",
        "クロスバリデーション"
      ],
      "answer": 1,
      "explanation": "ブースティング（Boosting）は、逐次的にモデルを学習させ、誤分類されたデータへの集中度を高める手法です。AdaBoostや勾配ブースティングがあります。"
    },
    {
      "id": 37,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "予測値と実値の差の2乗の平均をとった指標を何というか。",
      "options": [
        "MSE",
        "RMSE",
        "MAE",
        "MAPE"
      ],
      "answer": 0,
      "explanation": "MSE（Mean Squared Error：平均二乗誤差）は、各データの誤差を2乗したものの平均です。外れ値の影響を強く受ける特徴があります。"
    },
    {
      "id": 38,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "予測値と実値の差の絶対値の平均をとった指標を何というか。",
      "options": [
        "MSE",
        "RMSE",
        "MAE",
        "R2"
      ],
      "answer": 2,
      "explanation": "MAE（Mean Absolute Error：平均絶対誤差）は、各データの誤差の絶対値を平均したものです。MSEに比べて外れ値の影響を抑えられます。"
    },
    {
      "id": 39,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師あり学習",
      "question": "サポートベクターマシン（SVM）において、低次元では分離不可能なデータを高次元空間へ写像して分離可能にする手法を何というか。",
      "options": [
        "カーネルトリック",
        "マージン最大化",
        "ソフトマージン",
        "次元の呪い"
      ],
      "answer": 0,
      "explanation": "カーネルトリックは、高次元への写像を直接計算せずに内積を計算することで、計算負荷を抑えつつ非線形な境界を扱えるようにする手法です。"
    },
    {
      "id": 40,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師なし学習",
      "question": "データセットの中から類似したデータ同士をグループに分ける手法を何というか。",
      "options": [
        "分類",
        "クラスタリング",
        "回帰",
        "次元削減"
      ],
      "answer": 1,
      "explanation": "クラスタリングは、正解ラベルのないデータ（教師なし）を、データ間の類似度に基づいてグループ（クラススト）に分ける手法です。"
    },
    {
      "id": 41,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師なし学習",
      "question": "高次元のデータを、情報の損失を最小限に抑えつつ低次元に圧縮する手法の代表例はどれか。",
      "options": [
        "主成分分析",
        "k-means法",
        "決定木",
        "ロジスティック回帰"
      ],
      "answer": 0,
      "explanation": "主成分分析（PCA）は、データの分散が最大になる方向（主成分）を見つけ出し、低次元に射影する代表的な次元削減手法です。"
    },
    {
      "id": 42,
      "majorCategory": "機械学習の概要",
      "subCategory": "強化学習",
      "question": "強化学習において、エージェントが過去の経験に基づいて期待値が高い行動を選ぶことと、未知の行動を試すことのバランスを何というか。",
      "options": [
        "活用と探索のトレードオフ",
        "汎化と特化のトレードオフ",
        "バイアスと分散のトレードオフ",
        "適合率と再現率のトレードオフ"
      ],
      "answer": 0,
      "explanation": "強化学習では、現在の知識で最善と思う行動をとること（活用）と、より良い報酬を求めて新しい行動を試すこと（探索）のバランスが重要です。"
    },
    {
      "id": 43,
      "majorCategory": "機械学習の概要",
      "subCategory": "強化学習",
      "question": "強化学習において、ある状態で特定の行動をとった時の価値（期待報酬和）を学習する手法を何というか。",
      "options": [
        "Q学習",
        "GAN",
        "VAE",
        "CNN"
      ],
      "answer": 0,
      "explanation": "Q学習は、状態と行動の組み合わせに対して「Q値」という価値を割り当て、それをベルマン方程式に基づいて更新していく手法です。"
    },
    {
      "id": 44,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "2値分類の評価で、正解が「陽性」のものを「陽性」と正しく予測できた割合を何というか。",
      "options": [
        "適合率",
        "再現率",
        "正解率",
        "F値"
      ],
      "answer": 1,
      "explanation": "再現率（Recall）は、実際に陽性であるデータのうち、どれだけを陽性と予測できたかの割合です。感度（Sensitivity）とも呼ばれます。"
    },
    {
      "id": 45,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "2値分類の評価で、「陽性」と予測したもののうち、実際に陽性であった割合を何というか。",
      "options": [
        "適合率",
        "再現率",
        "正解率",
        "特異度"
      ],
      "answer": 0,
      "explanation": "適合率（Precision）は、陽性と予測したデータの中にどれだけ真の陽性が含まれているかの割合です。"
    },
    {
      "id": 46,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "適合率と再現率の調和平均をとり、両方のバランスを評価する指標を何というか。",
      "options": [
        "F値",
        "正解率",
        "AUC",
        "特異度"
      ],
      "answer": 0,
      "explanation": "F値（F-measure）は適合率と再現率の調和平均です。不均衡なデータセットにおいて単なる正解率よりも有効な指標となります。"
    },
    {
      "id": 47,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "統計学",
      "question": "データの散らばり具合を表す指標で、各データの値と平均値の差を2乗したものの平均を何というか。",
      "options": [
        "標準偏差",
        "分散",
        "中央値",
        "相関係数"
      ],
      "answer": 1,
      "explanation": "分散は、データが平均からどれだけ離れているかを表す統計量です。その平方根が標準偏差となります。"
    },
    {
      "id": 48,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "活性化関数",
      "question": "入力が0以下の場合は0、0より大きい場合は入力をそのまま出力する、現在のディープラーニングで最も一般的に使われる関数は何か。",
      "options": [
        "シグモイド関数",
        "ReLU関数",
        "ソフトマックス関数",
        "tanh関数"
      ],
      "answer": 1,
      "explanation": "ReLU（Rectified Linear Unit）関数は、計算が単純で勾配消失が起きにくため、深層中間層で広く利用されています。"
    },
    {
      "id": 49,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "正則化",
      "question": "学習時にネットワークの一部のノードをランダムに無効化することで、過学習を防ぐ手法を何というか。",
      "options": [
        "正規化",
        "ドロップアウト",
        "プーリング",
        "パディング"
      ],
      "answer": 1,
      "explanation": "ドロップアウト（Dropout）は、学習のたびにランダムにニューロンを間引くことで、モデルの汎化能力を高める手法です。"
    },
    {
      "id": 50,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "誤差逆伝播法",
      "question": "多層ネットワークにおいて、出力層で求めた誤差を逆方向に伝えて重みを更新する手法の基礎となる数学的原理はどれか。",
      "options": [
        "微分",
        "連鎖律",
        "ベイズの定理",
        "大数の法則"
      ],
      "answer": 1,
      "explanation": "誤差逆伝播法は、合成関数の微分である連鎖律（チェーンルール）を利用して、各層の重みに関する勾配を効率よく計算する手法です。"
    },
    {
      "id": 51,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "畳み込みニューラルネットワーク",
      "question": "畳み込みニューラルネットワーク（CNN）において、フィルタを適用した後の特徴マップのサイズを調整したり、情報の要約を行う層を何というか。",
      "options": [
        "全結合層",
        "プーリング層",
        "再帰層",
        "スキップ結合"
      ],
      "answer": 1,
      "explanation": "プーリング層は、画像の位置ずれに対する不変性を高め、計算量を削減するためのダウンサンプリングを行う層です。"
    },
    {
      "id": 52,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "回帰結合層",
      "question": "時系列データのように、過去の情報を内部状態として保持し、現在の入力に反映させるネットワークを何というか。",
      "options": [
        "CNN",
        "RNN",
        "GAN",
        "SVM"
      ],
      "answer": 1,
      "explanation": "RNN（Recurrent Neural Network：回帰型ニューラルネットワーク）は、再帰的な構造を持つことで時系列情報を扱えます。"
    },
    {
      "id": 53,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "回帰結合層",
      "question": "RNNの勾配消失・爆発問題を解決するために、「ゲート」という仕組みを導入して長期記憶を可能にしたモデルは何か。",
      "options": [
        "LSTM",
        "VGG",
        "AlexNet",
        "k-means"
      ],
      "answer": 0,
      "explanation": "LSTM（Long Short-Term Memory）は、忘却ゲート・入力ゲート・出力ゲートを持つメモリセルによって、長期間の依存関係を学習できます。"
    },
    {
      "id": 54,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "画像認識",
      "question": "2012年のILSVRCで圧勝し、ディープラーニングの有効性を世界に知らしめたヒントン教授らのチームによるモデルを何というか。",
      "options": [
        "LeNet",
        "AlexNet",
        "ResNet",
        "GoogLeNet"
      ],
      "answer": 1,
      "explanation": "AlexNetは、ReLUの使用やGPUによる高速学習、ドロップアウトの導入など、現代のDLの基本要素を組み込んだエポックメイキングなモデルです。"
    },
    {
      "id": 55,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Attention",
      "question": "翻訳などのSeq2Seqモデルにおいて、入力文のどの部分が重要かを動的に判断する仕組みを何というか。",
      "options": [
        "自己注意 (Self-Attention)",
        "Attention",
        "オートエンコーダ",
        "バックプロパゲーション"
      ],
      "answer": 1,
      "explanation": "Attention（アテンション：注意機構）は、特定の情報に重みを置くことで、長い文章などのコンテキストを適切に処理する仕組みです。"
    },
    {
      "id": 56,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Attention",
      "question": "RNNを一切使わず、Attention機構のみで構成された、現在の自然言語処理の主流となっているアーキテクチャは何か。",
      "options": [
        "Transformer",
        "GAN",
        "DenseNet",
        "YOLO"
      ],
      "answer": 0,
      "explanation": "Transformerは「Attention is All You Need」という論文で提案され、並列処理の容易さと高い精度からLLMの基盤となっています。"
    },
    {
      "id": 57,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "データ生成",
      "question": "生成器（Generator）と識別器（Discriminator）が互いに競い合うように学習することで、実在しない高品質なデータを生成する手法を何というか。",
      "options": [
        "VAE",
        "GAN",
        "Diffusion Model",
        "RNN"
      ],
      "answer": 1,
      "explanation": "GAN（Generative Adversarial Networks：敵対的生成ネットワーク）は、2つのネットワークが競合することで精巧な画像を生成します。"
    },
    {
      "id": 58,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIプロジェクトの進め方",
      "question": "AI開発において、本格的な開発に着手する前に、その手法やシステムが実現可能であることを検証する「概念実証」を何というか。",
      "options": [
        "PoC",
        "MVP",
        "A/Bテスト",
        "フィジビリティスタディ"
      ],
      "answer": 0,
      "explanation": "PoC（Proof of Concept）は、AIプロジェクトの初期段階で技術的な実現可能性を確認するために行われます。"
    },
    {
      "id": 59,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "正規化層",
      "question": "各層の入力を、バッチ統計量を用いて平均0、分散1に正規化することで、学習の安定化と高速化を図る手法は何か。",
      "options": [
        "バッチ正規化",
        "初期化",
        "プーリング",
        "平滑化"
      ],
      "answer": 0,
      "explanation": "バッチ正規化は、内部共変量シフトを抑制し、高い学習率の使用や初期値への依存軽減を可能にします。"
    },
    {
      "id": 60,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "正規化層",
      "question": "Transformerなどで用いられる、各サンプルの特徴量次元にわたって正規化を行う手法は何か。",
      "options": [
        "バッチ正規化",
        "レイヤー正規化",
        "インスタンス正規化",
        "グループ正規化"
      ],
      "answer": 1,
      "explanation": "Layer Normalizationは、バッチサイズに依存せず正規化を行えるため、系列長が変動するRNNやTransformerでの使用に適しています。"
    },
    {
      "id": 61,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "最適化手法",
      "question": "学習率を自動的に調整する最適化アルゴリズムのうち、AdaGradとRMSprop メリットを組み合わせ、現在最も広く使われているものはどれか。",
      "options": [
        "SGD",
        "Adam",
        "Momentum",
        "AdaBound"
      ],
      "answer": 1,
      "explanation": "Adam（Adaptive Moment Estimation）は、勾配の1次・2次モーメントを利用して、各パラメータごとに最適な学習率を動的に設定します。"
    },
    {
      "id": 62,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "画像認識",
      "question": "画像内の物体が「何であるか」だけでなく、「どこにあるか」を矩形（バウンディングボックス）で特定するタスクを何というか。",
      "options": [
        "物体識別",
        "物体検出",
        "セマンティックセグメンテーション",
        "姿勢推定"
      ],
      "answer": 1,
      "explanation": "物体検出（Object Detection）は、画像のクラス分類と座標特定を同時に行うタスクです。"
    },
    {
      "id": 63,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "画像認識",
      "question": "ピクセル単位でクラスラベルを割り当て、背景や物体の境界を明確に分離するタスクを何というか。",
      "options": [
        "物体検出",
        "物体分類",
        "セマンティックセグメンテーション",
        "インスタンスセグメンテーション"
      ],
      "answer": 2,
      "explanation": "セマンティックセグメンテーションは、ピクセルごとにどのカテゴリに属するかを分類します。"
    },
    {
      "id": 64,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "スキップ結合",
      "question": "非常に深いネットワークにおいて、入力を後の層に直接足し合わせることで、勾配消失を防ぎ、非常に高い精度を達成したネットワークを何というか。",
      "options": [
        "ResNet",
        "Inception",
        "MobileNet",
        "VGG"
      ],
      "answer": 0,
      "explanation": "ResNet（Residual Network）は、残差学習（Residual Learning）のためのショートカットコネクションを用いることで、100層を超える深層化を可能にしました。"
    },
    {
      "id": 65,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "自然言語処理",
      "question": "Googleが2018年に発表した、Transformerの双方向エンコーダを利用し、多くの自然言語処理タスクで最高性能を記録した事前学習モデルは何か。",
      "options": [
        "Word2Vec",
        "ELMo",
        "BERT",
        "GPT"
      ],
      "answer": 2,
      "explanation": "BERT（Bidirectional Encoder Representations from Transformers）は、文脈を双方向から学習できることが特徴です。"
    },
    {
      "id": 66,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "自然言語処理",
      "question": "学習データに基づき、次の単語を予測することで高度な文章生成を可能にしたモデル（Generative Pre-trained Transformer）は何か。",
      "options": [
        "BERT",
        "GPT",
        "ResNet",
        "RNN"
      ],
      "answer": 1,
      "explanation": "GPTは、Transformerのデコーダ部分を使用し、大規模なコーパスでの事前学習によって汎用的なテキスト生成を可能にします。"
    },
    {
      "id": 67,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "データ生成",
      "question": "ノイズの状態から徐々にノイズを除去していく過程をモデル化し、高品質な画像や動画を生成する近年の主流となっている手法は何か。",
      "options": [
        "GAN",
        "拡散モデル",
        "VAE",
        "オートエンコーダ"
      ],
      "answer": 1,
      "explanation": "拡散モデルは、学習した逆拡散過程を用いて、ランダムなノイズから鮮明な画像を再構成する手法です。"
    },
    {
      "id": 68,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "生成 AI",
      "question": "AIが生成したテキストなどの成果物に対して、人間がフィードバックを与えて学習を微調整する手法を何というか。",
      "options": [
        "ファインチューニング",
        "自己教師あり学習",
        "RLHF",
        "データ拡張"
      ],
      "answer": 2,
      "explanation": "RLHF（Reinforcement Learning from Human Feedback：人間のフィードバックによる強化学習）は、ChatGPTなどの調整に不可欠な技術です。"
    },
    {
      "id": 69,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "著作権法",
      "question": "日本の著作権法第30条の4において、AIの「情報解析」を目的とした著作物の利用について、正しい説明はどれか。",
      "options": [
        "営利目的であれば一切利用できない",
        "著作者の承諾がなければ利用できない",
        "著作者の利益を不当に害する場合を除き、原則として許諾なしに可能である",
        "著作権法はAIの学習には適用されないため自由に利用できる"
      ],
      "answer": 2,
      "explanation": "日本の著作権法第30条の4は、AIの学習（情報解析）のための著作物利用を幅広く認めており、世界的に見ても柔軟な規定とされています。"
    },
    {
      "id": 70,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "個人情報保護法",
      "question": "特定の個人を識別できないように加工し、復元できないようにした情報のことを何というか。",
      "options": [
        "匿名加工情報",
        "仮名加工情報",
        "秘密情報",
        "統計データ"
      ],
      "answer": 0,
      "explanation": "匿名加工情報は、特定の個人を識別できないようにし、かつ復元できないように加工されたもので、一定のルールの下で自由な二次利用が認められます。"
    },
    {
      "id": 71,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "個人情報保護法",
      "question": "EUで施行されている、強固な個人情報保護の枠組みを定め、違反には巨額の制裁金が課される規定を何というか。",
      "options": [
        "GDPR",
        "DPO",
        "Privacy Policy",
        "CCPA"
      ],
      "answer": 0,
      "explanation": "GDPR（General Data Protection Regulation：一般データ保護規則）は、EU域内の個人データの保護を目的とした法律です。"
    },
    {
      "id": 72,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "透明性",
      "question": "AIの判断プロセスが人間にとってブラックボックス化している問題に対し、判断の根拠を示せるようにする技術や取り組みを総称して何というか。",
      "options": [
        "DX",
        "XAI",
        "MLOps",
        "NLP"
      ],
      "answer": 1,
      "explanation": "XAI（eXplainable AI：説明可能なAI）は、AIの判断根拠や重要視した特徴を提示することで、AIの信頼性を高める技術です。"
    },
    {
      "id": 73,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "統計学",
      "question": "データを大きさの順に並べたときに、ちょうど中央に位置する値を何というか。",
      "options": [
        "平均値",
        "中央値 (メジアン)",
        "最頻値 (モード)",
        "期待値"
      ],
      "answer": 1,
      "explanation": "中央値（メジアン）は、外れ値の影響を受けにくい統計量として、所得などの不均衡なデータ分析によく用いられます。"
    },
    {
      "id": 74,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "統計学",
      "question": "データの中で最も頻繁に現れる値を何というか。",
      "options": [
        "平均値",
        "中央値",
        "最頻値",
        "分散"
      ],
      "answer": 2,
      "explanation": "最頻値（モード）は、質的変数（カテゴリカルデータ）などの分析において、最も多く代表的なカテゴリを見落とさないために重要です。"
    },
    {
      "id": 75,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "統計学",
      "question": "2つの変数の相関の強さを表す「ピアソンの積率相関係数」が取る値の下限と上限の範囲はどれか。",
      "options": [
        "0 〜 1",
        "-1 〜 1",
        "-100 〜 100",
        "0 〜 ∞"
      ],
      "answer": 1,
      "explanation": "相関係数は -1（負の相関）から 1（正の相関）までの値を取り、0に近いほど相関が弱いことを示します。"
    },
    {
      "id": 76,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "線形代数",
      "question": "ディープラーニングにおいて複数のデータを並行して扱う多次元配列（3次元以上も含む）のことを何というか。",
      "options": [
        "スカラー",
        "ベクトル",
        "行列",
        "テンソル"
      ],
      "answer": 3,
      "explanation": "テンソル（Tensor）は、0階（スカラー）、1階（ベクトル）、2階（行列）を含めた、多次元的な数値の集まりを指します。"
    },
    {
      "id": 77,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "統計学",
      "question": "事前の確率が、新たに得られた「証拠（データ）」に基づいてどのように更新されるかを記述する定理は何か。",
      "options": [
        "中心極限定理",
        "大数の法則",
        "ベイズの定理",
        "ピタゴラスの定理"
      ],
      "answer": 2,
      "explanation": "ベイズの定理は、尤度（データを説明する確率）を用いて、事前確率を事後確率へと更新するための基本式です。迷惑メールフィルタなどで応用されています。"
    },
    {
      "id": 78,
      "majorCategory": "機械学習の概要",
      "subCategory": "強化学習",
      "question": "現在の状態と行動のみによって次の状態が決まる、強化学習の理論的枠組みを何というか。",
      "options": [
        "マルコフ決定過程",
        "エージェント・指向",
        "探索・推論",
        "ベルマン方程式"
      ],
      "answer": 0,
      "explanation": "マルコフ決定過程は、過去の履歴に依存せず、現在の状態が将来の遷移を決定するという「マルコフ性」に基づいた意思決定モデルです。"
    },
    {
      "id": 79,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ニューラルネットワーク",
      "question": "計算速度を向上させるため、複雑な計算を避け、並列処理を重視して設計された画像処理用プロセッサを一般に何というか。",
      "options": [
        "CPU",
        "GPU",
        "TPU",
        "RAM"
      ],
      "answer": 1,
      "explanation": "GPU（ Graphics Processing Unit）は、数千ものコアを利用した並列計算に優れており、行列演算が主体のディープラーニングにおいて不可欠なハードウェアです。"
    },
    {
      "id": 80,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ニューラルネットワーク",
      "question": "Googleが開発した、ディープラーニング（テンソルフロー）の演算を高速化するための専用ASICは何か。",
      "options": [
        "GPU",
        "Core i9",
        "TPU",
        "FPGA"
      ],
      "answer": 2,
      "explanation": "TPUは低精度な行列演算に特化させることで、電力効率と学習速度を劇的に向上させたDL専用チップです。"
    },
    {
      "id": 81,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "活性化関数",
      "question": "ニューラルネットワークの出力層で用いられ、各ノードの出力の和を1にすることで「確率」のように扱えるようにする関数は何か。",
      "options": [
        "シグモイド関数",
        "ソフトマックス関数",
        "ReLU関数",
        "tanh関数"
      ],
      "answer": 1,
      "explanation": "ソフトマックス関数は多クラス分類の出力層で一般的に用いられ、各クラスに属する確率を表すことができます。"
    },
    {
      "id": 82,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "誤差関数",
      "question": "多クラス分類において、予測した確率分布と実際のラベル（ワンホットベクトル）の間の「違い」を測るために一般的に用いられる誤差関数はどれか。",
      "options": [
        "平均二乗誤差",
        "平均絶対誤差",
        "交差エントロピー誤差",
        "Contrastive Loss"
      ],
      "answer": 2,
      "explanation": "交差エントロピー誤差は、情報量の一致度を測る指標で、特に分類問題において広く用いられます。"
    },
    {
      "id": 83,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "学習データに対しては高い精度を示すが、未知のデータに対しては適合しきれない現象を何というか。",
      "options": [
        "未学習",
        "過学習",
        "学習不足",
        "欠損値"
      ],
      "answer": 1,
      "explanation": "過学習はモデルが複雑すぎてノイズまで学習してしまった状態です。正規化やドロップアウトなどの手法で抑制します。"
    },
    {
      "id": 84,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "情報学",
      "question": "ディープラーニングなどで重い計算を行う際、複数のGPUやコンピュータを用いて計算を分担することを何というか。",
      "options": [
        "分散学習",
        "エッジAI",
        "転移学習",
        "ファインチューニング"
      ],
      "answer": 0,
      "explanation": "分散学習には、データを分割して配る「データ並列」と、モデルの層を分割して配る「モデル並列」の大きく2種類があります。"
    },
    {
      "id": 85,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "正則化",
      "question": "誤差関数に「重みの絶対値の和」を加えることで、不要な重みを0に近づけ、特徴選択の効果を持たせる正則化手法はどれか。",
      "options": [
        "L1正則化 (ラッソ回帰)",
        "L2正則化 (リッジ回帰)",
        "ドロップアウト",
        "プーリング"
      ],
      "answer": 0,
      "explanation": "L1正則化はスパース性が得られるため、寄与度の低い変数を自動的に除外する性質があります。"
    },
    {
      "id": 86,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "正則化",
      "question": "誤差関数に「重みの2乗の和」を加えることで、極端に大きな重みを持つことを抑制し、過学習を防ぐ一般的な手法はどれか。",
      "options": [
        "L1正則化",
        "L2正則化",
        "データ拡張",
        "早期終了"
      ],
      "answer": 1,
      "explanation": "L2正則化は、重みベクトルのL2ノルムを制限することで、滑らかなモデルを構築します。"
    },
    {
      "id": 87,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師あり学習",
      "question": "決定木を複数作成し、その各パスで各データがどの「葉」に落ちるかの結果を組み合わせる強力な手法はどれか。",
      "options": [
        "ランダムフォレスト",
        "k-means",
        "単純パーセプトロン",
        "PCA"
      ],
      "answer": 0,
      "explanation": "ランダムフォレストはバギングの一種で、決定木を弱学習器として使い、バリアンス（分散）を大幅に下げる手法です。"
    },
    {
      "id": 88,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "畳み込みニューラルネットワーク",
      "question": "CNNの畳み込み層において、フィルタが入力のどの程度の範囲を一度に「見る」かを定義する領域はどれか。",
      "options": [
        "受容野",
        "特徴マップ",
        "カーネルサイズ",
        "パディング"
      ],
      "answer": 2,
      "explanation": "カーネルサイズ（フィルタサイズ）は局所的な情報を抽出する範囲を決めます。これに対し、層を重ねることで広範囲を認識できる総体的な範囲を「受容野（Receptive Field）」と呼びます。"
    },
    {
      "id": 89,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師あり学習",
      "question": "回帰分析において、出力が連続値ではなく「確率」や「0か1かの分類」となる場合に用いられるモデルはどれか。",
      "options": [
        "線形回帰",
        "ロジスティック回帰",
        "リッジ回帰",
        "単回帰"
      ],
      "answer": 1,
      "explanation": "ロジスティック回帰は「回帰」という名前ですが、シグモイド関数を用いて出力を正規化する代表的な「分類」アルゴリズムです。"
    },
    {
      "id": 90,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師なし学習",
      "question": "顧客が過去に購入した商品の傾向から、次におすすめの商品を提案するシステムに利用される、データの関連性を探る手法を何というか。",
      "options": [
        "アソシエーション分析",
        "決定木分析",
        "主成分分析",
        "強化学習"
      ],
      "answer": 0,
      "explanation": "アソシエーション分析は「おむつを買う人はビールも買う」といった相関関係（共起）を見つけ出す手法です。"
    },
    {
      "id": 91,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "全結合層",
      "question": "ニューラルネットワークの最後に位置することが多く、抽出されたすべての特徴量を結合して最終的なクラス分類を行う層は何か。",
      "options": [
        "畳み込み層",
        "プーリング層",
        "全結合層",
        "Attention層"
      ],
      "answer": 2,
      "explanation": "全結合層（FC層）は、前の層の全ユニットと接続され、グローバルな情報を集約して判断を下します。"
    },
    {
      "id": 92,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "データを「訓練用」「検証用」「テスト用」に分割し、検証用データを使ってハイパーパラメータを調整することを何というか。",
      "options": [
        "交差検証 (Cross Validation)",
        "ホールドアウト法",
        "ブートストラップ",
        "アノテーション"
      ],
      "answer": 1,
      "explanation": "ホールドアウト法は、データを固定の割合で分割する最もシンプルな検証手法です。"
    },
    {
      "id": 93,
      "majorCategory": "機械学習の概要",
      "subCategory": "強化学習",
      "question": "強化学習などで、エージェントが行動することで得られる、ある期間内の報酬の合計（ただし割引率を考慮したもの）を何というか。",
      "options": [
        "割引現在価値",
        "期待報酬値",
        "収益",
        "累積報酬"
      ],
      "answer": 2,
      "explanation": "強化学習の目的は、この累積の報酬（収益）を最大化するような「方策」を学習することです。"
    },
    {
      "id": 94,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "オートエンコーダ",
      "question": "入力を圧縮して特徴を抽出し、再び元通りに復元することを目指す「自己符号化器」を何というか。",
      "options": [
        "オートエンコーダ",
        "GAN",
        "Transformer",
        "LSTM"
      ],
      "answer": 0,
      "explanation": "オートエンコーダは、入出力が同じになるように学習することで、中間の潜在空間においてデータの圧縮表現（次元削減）を実現します。"
    },
    {
      "id": 95,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "画像認識",
      "question": "人の目では捉えきれないような、マルチスペクトルカメラが捉える複雑な情報をAIで解析する応用分野はどれか。",
      "options": [
        "医療診断",
        "リモートセンシング",
        "自動運転",
        "顔認証"
      ],
      "answer": 1,
      "explanation": "人工衛星やドローンからの画像（マルチスペクトル画像）をAIで解析することで、農作物の育成状況や資源の有無を判定できます。"
    },
    {
      "id": 96,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "音声処理",
      "question": "テキストから人間の声を合成する「音声合成」のモデルで、Googleが開発したニューラルネットワークによる波形生成モデルはどれか。",
      "options": [
        "WaveNet",
        "Tacotron",
        "ResNet",
        "VQ-VAE"
      ],
      "answer": 0,
      "explanation": "WaveNetは、ディープラーニングを用いて生の音声波形を直接生成するモデルで、極めて自然な合成音声を実現しました。"
    },
    {
      "id": 97,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "モデルの学習済みパラメータを、似たような別のタスクの初期値として再利用する手法を何というか。",
      "options": [
        "転移学習",
        "ファインチューニング",
        "自己教師あり学習",
        "強化学習"
      ],
      "answer": 0,
      "explanation": "転移学習は、大量のデータで学習させた「知識」を、データの少ない別のタスクに流用することで効率的な学習を可能にします。その上でモデル全体を微調整することを「ファインチューニング」と呼びます。"
    },
    {
      "id": 98,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "マルチモーダル",
      "question": "画像とテキストなど、異なる種類の情報を組み合わせて一つのモデルで扱うタスクを何というか。",
      "options": [
        "マルチモーダル学習",
        "マルチタスク学習",
        "自己教師あり学習",
        "分散学習"
      ],
      "answer": 0,
      "explanation": "マルチモーダルAIは、視覚情報とテキスト情報を統合して理解することで、高精度な画像説明文生成などが可能です。CLIPなどが代表例です。"
    },
    {
      "id": 99,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "自然言語処理",
      "question": "単語をベクトル空間上の座標に配置し、単語同士の意味的な近さを計算できるようにする手法の代表例はどれか。",
      "options": [
        "Word2Vec",
        "CNN",
        "PCA",
        "Softmax"
      ],
      "answer": 0,
      "explanation": "Word2Vecは、周囲に出現する単語から対象の単語を予測することで、意味を反映したベクトル（単語埋め込み）を生成します。"
    },
    {
      "id": 100,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "データ生成",
      "question": "GANの一種で、あるドメインの画像（馬）を別のドメインの画像（シマウマ）へ、ペアとなるデータがなくても変換できる手法は何か。",
      "options": [
        "CycleGAN",
        "DCGAN",
        "StyleGAN",
        "Pix2Pix"
      ],
      "answer": 0,
      "explanation": "CycleGANは「変換して戻したときに元に戻る」というサイクルの一貫性を利用することで、対応するペア画像がなくてもスタイル変換を実現します。"
    },
    {
      "id": 101,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "情報学",
      "question": "PCのGPUを用いずに、インターネットを介してAIモデルを動作させることができる環境を一般に「(A)環境」と呼ぶ。 (A)に当てはまる言葉はどれか。",
      "options": [
        "ローカル",
        "クラウド",
        "エッジ",
        "オンプレミス"
      ],
      "answer": 1,
      "explanation": "クラウドAIは、強力なインフラをオンデマンドで利用でき、APIを通じて手軽に高度な機能を利用できるメリットがあります。"
    },
    {
      "id": 102,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "最適化手法",
      "question": "学習の初期段階で学習率を大きく設定し、学習が進むにつれて小さくしていくことを何というか。",
      "options": [
        "学習率スケジューリング",
        "早期終了",
        "初期化",
        "勾配爆発"
      ],
      "answer": 0,
      "explanation": "学習率スケジューリング（または学習率減衰）は、大域的な最適値へ素早く近づき、後半で安定して収束させるための重要な調整項目です。"
    },
    {
      "id": 103,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Attention",
      "question": "Transformerの内部において、入力された系列（文章など）の各単語が、同じ系列内の他のどの単語と関連しているかを計算する仕組みは何か。",
      "options": [
        "自己注意 (Self-Attention)",
        "階層的注意",
        "畳み込み（Convolutions）",
        "再帰構造"
      ],
      "answer": 0,
      "explanation": "Self-Attentionは系列全体の依存関係を一度に並列に計算でき、RNNよりも長い文脈を効率よく捉えられます。"
    },
    {
      "id": 104,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの解釈性",
      "question": "CNNの最終的な判断に大きく寄与した画像内のエリアを「ヒートマップ」として可視化する代表的な手法はどれか。",
      "options": [
        "Grad-CAM",
        "SHAP",
        "LIME",
        "Attention Map"
      ],
      "answer": 0,
      "explanation": "Grad-CAMは、勾配情報を利用して重要度を算出する手法で、AIの「目で見ている場所」を確認できます。"
    },
    {
      "id": 105,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの軽量化",
      "question": "学習済みの巨大で高精度なモデル（教師モデル）の知識を、より小さなモデル（生徒モデル）に受け継がせる軽量化手法はどれか。",
      "options": [
        "蒸留 (Distillation)",
        "量子化",
        "プルーニング (枝刈り)",
        "モデル圧縮"
      ],
      "answer": 0,
      "explanation": "蒸留は、教師モデルの出力確率分布（ソフトターゲット）を生徒モデルに学習させることで、精度を落とさずにサイズダウンを図る手法です。"
    },
    {
      "id": 106,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの軽量化",
      "question": "重みなどの数値を32ビット浮動小数点数（FP32）から、より精度の低い8ビット整数（INT8）などに変換して計算を高速化・軽量化する手法はどれか。",
      "options": [
        "量子化",
        "蒸留",
        "プルーニング",
        "バッチ正規化"
      ],
      "answer": 0,
      "explanation": "量子化（Quantization）は、モデルのサイズを劇的に削減でき、エッジデバイス（スマホや組み込み）へのAI実装に不可欠です。"
    },
    {
      "id": 107,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "大規模言語モデル",
      "question": "数千億以上のパラメータを持つ大規模言語モデルにおいて、個々の小規模モデルでは見られなかった高度な推論能力などが不連続に出現する現象を何というか。",
      "options": [
        "創発",
        "勾配爆発",
        "過学習",
        "転移学習"
      ],
      "answer": 0,
      "explanation": "創発は、規模の拡大（スケーリング）によって予想外に高い能力が発揮される現象です。"
    },
    {
      "id": 108,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "誤差逆伝播法",
      "question": "活性化関数にシグモイド関数を用いた多層ネットワークにおいて、層が深くなるにつれて勾配が極端に小さくなり学習が進まなくなる現象を何というか。",
      "options": [
        "勾配爆発",
        "勾配消失問題",
        "オーバーフィッティング",
        "鞍点問題"
      ],
      "answer": 1,
      "explanation": "シグモイド関数は微分の最大値が0.25であるため、掛け算を繰り返すと勾配が0に収束してしまいます。ReLUの導入などで解決されました。"
    },
    {
      "id": 109,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "著作権法",
      "question": "AIが生成した作品が「著作権」で保護されるために最低限必要とされる要件は何か。",
      "options": [
        "人間が明確なプロンプトを入力したこと",
        "人間に代わって公表したこと",
        "人間による「創作的寄与」が認められること",
        "著作権局に登録されていること"
      ],
      "answer": 2,
      "explanation": "単にAIに指示を出して出力されただけのものは「著作物」として認められませんが、人間が構成を練り、大幅な加筆修正を行うなど「創作性のある寄与」があれば著作権が発生し得ます。"
    },
    {
      "id": 110,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "特許法",
      "question": "日本の現行法において、「特許」の申請における「発明者」として認められるのは誰か。 ",
      "options": [
        "人間のみ",
        "AIそのもの",
        "AIを開発した企業法人",
        "プロンプトを入力したユーザー"
      ],
      "answer": 0,
      "explanation": "日本の特許法において、現在のところ「発明者」は自然人（人間）に限られており、AIを共同発明者とすることも原則として認められていません。"
    },
    {
      "id": 111,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "公平性",
      "question": "学習データそのものに、社会的な偏りや差別が含まれていることが原因で、AIの出力に偏りが生じてしまうことを何というか。",
      "options": [
        "アルゴリズムバイアス",
        "バリアンス",
        "フィードバックループ",
        "過学習"
      ],
      "answer": 0,
      "explanation": "アルゴリズムバイアスは、特定の属性（人種・性別等）に対する不利益や不公平を生み出す可能性があるため、AI倫理の重要な課題です。"
    },
    {
      "id": 112,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AI開発委託契約",
      "question": "AIプロジェクトの初期検証（PoC）段階で、開発目標の達成を保証せず、作業を行うこと自体を約束する契約形態はどれか。",
      "options": [
        "請負契約",
        "準委任契約",
        "雇用契約",
        "共同開発契約"
      ],
      "answer": 1,
      "explanation": "AI開発、特にPoCフェーズは結果が不確実であるため、完成責任を負わない「準委任契約」が好まれる傾向にあります。"
    },
    {
      "id": 113,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Attention",
      "question": "Transformerの各層において、学習を安定させるためにSelf-AttentionやFFNの出力を「正規化」してから足し合わせるプロセスを何というか。",
      "options": [
        "残差接続",
        "Dropout",
        "プーリング",
        "データの正規化"
      ],
      "answer": 0,
      "explanation": "残差接続は、入力をそのまま出力に足すことで勾配が消えにくくし、非常に深いネットワークの学習を可能にします。"
    },
    {
      "id": 114,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師あり学習",
      "question": "画像認識などの事前学習モデルを用い、最終層の重みだけを入れ替えて新しいタスクに適合させる最も軽いチューニング手法はどれか。",
      "options": [
        "フルファインチューニング",
        "重み凍結",
        "自己教師あり学習",
        "蒸留"
      ],
      "answer": 1,
      "explanation": "特定の中間層までの重みを固定（フリーズ）し、最終層（分類器）のみを学習させることで、計算コストを抑えつつ高い汎化能力を実現できます。"
    },
    {
      "id": 115,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "生成 AI",
      "question": "LLMなどの巨大なモデルの全パラメータを更新する代わりに、ごく一部の追加パラメータのみを学習させる効率的なファインチューニング手法の総称は何か。",
      "options": [
        "PEFT",
        "RLHF",
        "データ拡張",
        "転移学習"
      ],
      "answer": 0,
      "explanation": "PEFTにはLoRA（Low-Rank Adaptation）などが含まれ、少ないリソースでLLMを特定領域に特化させることが可能です。"
    },
    {
      "id": 116,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "大規模言語モデル",
      "question": "LLMの外部から最新の事実や内部情報を検索してプロンプトに挿入し、ハルシネーション（もっともらしい嘘）を抑制する技術を何というか。",
      "options": [
        "PEFT",
        "RAG",
        "RLHF",
        "Zero-shot学習"
      ],
      "answer": 1,
      "explanation": "RAG（検索拡張生成）は、信頼できる外部知識ベースを検索して回答を生成させることで、情報の正確性を高める手法です。"
    },
    {
      "id": 117,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "情報学",
      "question": "情報理論において、ある確率分布PとQがどれだけ「離れているか」を測る指標はどれか。",
      "options": [
        "ユークリッド距離",
        "カルバック・ライブラー情報量",
        "コサイン類似度",
        "ハミング距離"
      ],
      "answer": 1,
      "explanation": "KLダイバージェンスは、2つの確率分布の差異を定量化する指標で、ディープラーニングの誤差関数（VAEなど）でも利用されます。"
    },
    {
      "id": 118,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "誤差関数",
      "question": "似たもの同士を近くへ、異なるものを遠くへ配置するようにベクトルの距離を学習する手法を何というか。",
      "options": [
        "対照学習",
        "教師なし学習",
        "単純な回帰",
        "バイナリ分類"
      ],
      "answer": 0,
      "explanation": "対照学習は、Contrastive LossやTriplet Lossを用いて、サンプルの相対的な関係（類似性）を学習する手法です。"
    },
    {
      "id": 119,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "誤差逆伝播法",
      "question": "勾配降下法において、過去の勾配の移動平均を利用して「慣性」を持たせることで、平坦な地形を素早く進み局所最適解から抜け出しやすくする手法はどれか。",
      "options": [
        "モーメンタム",
        "Adam",
        "AdaGrad",
        "SGD"
      ],
      "answer": 0,
      "explanation": "モーメンタムは、現在の勾配に過去の速度ベクトルを加えることで、学習を加速させ振動を抑える効果があります。"
    },
    {
      "id": 120,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "マルチモーダル",
      "question": "OpenAIが開発した、大量の画像とテキストのペアから両者の共通概念を学習し、画像からテキストを予測できるようにしたモデルはどれか。",
      "options": [
        "CLIP",
        "BERT",
        "ResNet",
        "DALL-E"
      ],
      "answer": 0,
      "explanation": "CLIP（Contrastive Language-Image Pre-training）は、画像と説明文の類似度を学習することで、ゼロショット画像分類などを可能にしました。"
    },
    {
      "id": 121,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIプロジェクトの進め方",
      "question": "データマイニングやAIプロジェクトにおける標準的なプロセスモデルで、ビジネスの理解から評価、展開までの6つのフェーズで構成されるものはどれか。",
      "options": [
        "PPDACサイクル",
        "CRISP-DM",
        "Agile",
        "Waterfall"
      ],
      "answer": 1,
      "explanation": "CRISP-DM（Cross Industry Standard Process for Data Mining）は、AIプロジェクトを成功させるための標準的なフレームワークです。"
    },
    {
      "id": 122,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIプロジェクトの進め方",
      "question": "AIモデルを一度構築して終わりにするのではなく、本番環境で運用し続け、精度低下を監視し、改善（再学習）し続けるサイクルを何というか。",
      "options": [
        "DevOps",
        "MLOps",
        "AIOps",
        "NoOps"
      ],
      "answer": 1,
      "explanation": "MLOps（Machine Learning Operations）は、機械学習をビジネスに安定して組み込むための運用手法と自動化の仕組みです。"
    },
    {
      "id": 123,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "転移学習・ファインチューニング",
      "question": "正解ラベルが付いていない大量のデータ自身から「一部を隠して当てる」などの問題を解かせて特徴を学習させる手法を何というか。",
      "options": [
        "教師なし学習",
        "自己教師あり学習",
        "強化学習",
        "対照学習"
      ],
      "answer": 1,
      "explanation": "自己教師あり学習は、データ自体からラベルを自動生成して学習するため、ラベル付けコストをかけずに高性能な事前学習モデルを構築できます。"
    },
    {
      "id": 124,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "データ生成",
      "question": "複数のニューラル放射輝度場（Neural Radiance Fields）を利用して、2D画像から自由視点の3Dシーンを再構成する技術はどれか。",
      "options": [
        "NeRF",
        "GAN",
        "VAE",
        "YOLO"
      ],
      "answer": 0,
      "explanation": "NeRFは、物体の密度や色をディープラーニングで関数化することで、写真から高精度な3Dスキャンを行う技術です。"
    },
    {
      "id": 125,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "悪用",
      "question": "ディープラーニングを用いて作成された、本物と見分けがつかないような高度な偽画像や偽動画のことを一般に何というか。",
      "options": [
        "フェイクニュース",
        "ディープフェイク",
        "スパム",
        "フィッシング"
      ],
      "answer": 1,
      "explanation": "ディープフェイク（Deepfake）は、著名人の顔を入れ替えるなど、なりすましやデマの拡散に悪用されるリスクが指摘されています。"
    },
    {
      "id": 126,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "生成 AI",
      "question": "生成AIにおいて、あるタスクを一例も示さずに指示だけで解かせることを (A)-shot学習、数例の見本を示して解かせることを (B)-shot学習という。(A)・(B)の組み合わせで正しいものはどれか。",
      "options": [
        "(A) Zero, (B) Few",
        "(A) Single, (B) Multi",
        "(A) First, (B) Last",
        "(A) No, (B) Sample"
      ],
      "answer": 0,
      "explanation": "LLMの学習能力の高さにより、一例も見せない「Zero-shot」や、少数の具体例（2〜10件程度）を見せる「Few-shot」での推論が可能です。"
    },
    {
      "id": 127,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "音声処理",
      "question": "音声波形をそのまま出力するのではなく、音声学的な「特徴量」を取り出しやすいように変換処理した、時間ごとの周波数分布図を何というか。",
      "options": [
        "オシロスコープ",
        "スペクトログラム",
        "ヒストグラム",
        "時系列波形"
      ],
      "answer": 1,
      "explanation": "スペクトログラムは音声認識や異常検知のAIで、入力を「画像」として扱うための前処理としてよく使われます。"
    },
    {
      "id": 128,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "自然言語処理",
      "question": "文章を意味のある最小単位に分割する処理（品詞分解など）を行うためのプログラムを一般に何というか。",
      "options": [
        "形態素解析器",
        "コンパイラ",
        "リンカ",
        "スクレイパー"
      ],
      "answer": 0,
      "explanation": "日本語は英語と異なり単語間がスペースで区切られていないため、「MeCab」や「Janome」などの形態素解析器による処理が重要です。"
    },
    {
      "id": 129,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの解釈性",
      "question": "モデルの推論結果が「もし特徴量Xが別の値だったら、結果はどう変わっていたか」という仮定（反実仮想）を基に説明する手法を何というか。",
      "options": [
        "反実仮想説明",
        "Grad-CAM",
        "LIME",
        "SHAP"
      ],
      "answer": 0,
      "explanation": "反実仮想説明は、「あと◯◯円年収が高ければローンが通った」のように、結果を変えるために必要な最小限の変化を示すことで理解を促します。"
    },
    {
      "id": 130,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "データの収集・加工・分析・学習",
      "question": "機械学習モデルの学習効率を高めるため、わざとデータにノイズを加えたり、反転・回転させたりしてデータ数を人工的に増やす手法を何というか。",
      "options": [
        "データクレンジング",
        "データ拡張",
        "アノテーション",
        "正則化"
      ],
      "answer": 1,
      "explanation": "データ拡張は、特に画像認識において、限られた学習用データから汎用性の高いモデルを作るために非常に有効です。"
    },
    {
      "id": 131,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "国内外のガイドライン",
      "question": "OECDや内閣府などが提唱している、AI開発・利用において「人間中心の原則」や「透明性」などを重視する考え方の拠り所を何というか。",
      "options": [
        "AI倫理指針",
        "知的財産基本法",
        "サイバーセキュリティ法",
        "PL法"
      ],
      "answer": 0,
      "explanation": "政府や国際機関が発表するガイドラインは法的拘束力のない「ソフトロー」ですが、企業の社会的責任や国際的な調和のために重視されます。"
    },
    {
      "id": 132,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "最適化手法",
      "question": "誤差関数の勾配が0になる地点のうち、ある方向からは極小値だが別の方向からは極大値となっている、学習が停滞しやすい地点を何というか。",
      "options": [
        "局所最適解",
        "大域的最適解",
        "鞍点",
        "プラトー"
      ],
      "answer": 2,
      "explanation": "多次元空間では局所最適解よりも「鞍点」が多く存在すると考えられており、勾配が小さいため学習が停止してしまうリスクがあります。"
    },
    {
      "id": 133,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "画像認識",
      "question": "画像内の物体を単にカテゴリ分けするだけでなく、同じカテゴリの別々の個体（例：犬Aと犬B）を区別して塗り分けるタスクはどれか。",
      "options": [
        "セマンティックセグメンテーション",
        "インスタンスセグメンテーション",
        "物体検出",
        "画像分類"
      ],
      "answer": 1,
      "explanation": "インスタンスセグメンテーションは、ピクセル単位の分類と個体識別を同時に行う高度なタスクです。"
    },
    {
      "id": 134,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "大規模言語モデル",
      "question": "LLMにおいて、入力できる最大の情報の塊（単語や部分単語の単位）の数を何というか。",
      "options": [
        "パラメータ数",
        "コンテキストウィンドウ",
        "エポック数",
        "レイヤー数"
      ],
      "answer": 1,
      "explanation": "コンテキストウィンドウ（または最大トークン数）が大きいほど、一度に長大な文書や過去の会話履歴を考慮して回答を生成できます。"
    },
    {
      "id": 135,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師あり学習",
      "question": "時系列解析において、自分自身の過去の値を説明変数として用いる回帰モデルを何というか。",
      "options": [
        "線形回帰",
        "自己回帰モデル",
        "ロジスティック回帰",
        "主成分分析"
      ],
      "answer": 1,
      "explanation": "AR（Autoregressive）モデルは、過去の変化パターンから将来を予測する、最も基本的な時系列アルゴリズムです。"
    },
    {
      "id": 136,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "知的財産権",
      "question": "自社のAIモデルや独自のノウハウを特許として公開せずに、秘密として管理して他社から隠し通す戦略に関連の深い法律はどれか。",
      "options": [
        "特許法",
        "著作権法",
        "不正競争防止法",
        "独占禁止法"
      ],
      "answer": 2,
      "explanation": "特許と異なり営業秘密として管理すれば、技術を独占し続けることが可能ですが、流出時の対策として「不正競争防止法」の要件を満たす必要があります。"
    },
    {
      "id": 137,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ニューラルネットワーク",
      "question": "人間の脳内の神経細胞同士のつながり（シナプス）の結合の強さが、学習によって変化する仕組みを模した数値を、NNでは何と呼ぶか。",
      "options": [
        "入力値",
        "バイアス",
        "重み",
        "活性化度"
      ],
      "answer": 2,
      "explanation": "ニューラルネットワークの学習とは、誤差を最小化するように各接続の「重み」を調整するプロセスそのものです。"
    },
    {
      "id": 138,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "回帰結合層",
      "question": "RNNにおいて、非常に長い系列を学習する際に、過去へ遡って勾配を計算する手法を何というか。",
      "options": [
        "誤差逆伝播法",
        "BPTT",
        "フォワードプロパゲーション",
        "注意機構"
      ],
      "answer": 1,
      "explanation": "BPTTは系列データを「時間の方向に展開」して通常の誤差逆伝播法を適用する手法です。"
    },
    {
      "id": 139,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "安全性とセキュリティ",
      "question": "画像に目に見えない特殊なノイズを加え、AIモデルを意図的に誤認させる攻撃手法を総称して何というか。",
      "options": [
        "SQLインジェクション",
        "フィッシング攻撃",
        "敵対的攻撃",
        "DDos攻撃"
      ],
      "answer": 2,
      "explanation": "Adversarial Examplesと呼ばれる入力を意図的に作成することで、自動運転の標識認識を誤らせるなどのリスクが懸念されています。"
    },
    {
      "id": 140,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "2つのモデルを比較する際、モデルの複雑さ（パラメータ数）に対してペナルティを課し、「できるだけシンプルで当てはまりの良いモデル」を選ぶための指標はどれか。",
      "options": [
        "赤池情報量規準",
        "F値",
        "正解率",
        "学習率"
      ],
      "answer": 0,
      "explanation": "AICは、過学習を防ぎつつ汎化性能の高いモデルを選択するための統計的指標です。値が小さいほど良いモデルとされます。"
    },
    {
      "id": 141,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "生成 AI",
      "question": "LLMにおいて、適切な「指示（指示文）」を工夫することで、モデルの能力を最大限に引き出す手法や学問領域を何というか。",
      "options": [
        "プロンプトエンジニアリング",
        "データ工学",
        "機械学習工学",
        "ナレッジグラフ"
      ],
      "answer": 0,
      "explanation": "Chain-of-Thought（思考の連鎖）のように、推論過程を明示させるプロンプトなどはその代表的な手法です。"
    },
    {
      "id": 142,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "民主主義",
      "question": "AIのアルゴリズムが、個人の好みに合わせた情報の偏りを強めてしまい、特定の意見や思想ばかりが表示される状態を何というか。",
      "options": [
        "フィルターバブル",
        "エコーチェンバー",
        "デジタルデバイド",
        "ハルシネーション"
      ],
      "answer": 0,
      "explanation": "フィルターバブルは、パーソナライズされた検索結果やSNSによって、自分が見たい情報だけに囲まれてしまう現象です。"
    },
    {
      "id": 143,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "統計学",
      "question": "回帰分析において、全てのデータポイントが完全に回帰直線（または曲線）の上に乗っているとき、決定係数（R2値）はいくつになるか。",
      "options": [
        "-1",
        "0",
        "0.5",
        "1"
      ],
      "answer": 3,
      "explanation": "決定係数（R2）は0から1の範囲をとり、1に近いほどモデルの当てはまりが良いことを示します。1は完全に誤差がない状態です。"
    },
    {
      "id": 144,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "知識表現",
      "question": "1960年代に開発された最初期のエキスパートシステムで、未知の有機化合物の構造を推定することを目的としたものはどれか。",
      "options": [
        "MYCIN",
        "DENDRAL",
        "SHRDLU",
        "ELIZA"
      ],
      "answer": 1,
      "explanation": "DENDRALはIF-THEN形式の知識ベースを用いたエキスパートシステムの先駆けとなりました。"
    },
    {
      "id": 145,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "知識表現",
      "question": "1970年代にスタンフォード大学で開発された、血液中の感染症の診断と治療方針を提案するエキスパートシステムは何か。",
      "options": [
        "MYCIN",
        "DENDRAL",
        "DeepBlue",
        "Watson"
      ],
      "answer": 0,
      "explanation": "MYCINは、専門家の知識をルール化し、不確実性を考慮した推論を行う初期の代表的な医療支援AIです。"
    },
    {
      "id": 146,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "探索・推論",
      "question": "囲碁AIのAlphaGoがプロ棋士との対局で用いた、盤面の評価に「価値ネットワーク」と「方策ネットワーク」を組み合わせる探索手法は何か。",
      "options": [
        "完全探索",
        "αβ法",
        "モンテカルロ木探索",
        "幅優先探索"
      ],
      "answer": 2,
      "explanation": "AlphaGoは、ディープラーニングによる盤面予測とモンテカルロ木探索を融合させることで、膨大な指し手の中から最善手を選び出しました。"
    },
    {
      "id": 147,
      "majorCategory": "機械学習の概要",
      "subCategory": "教師なし学習",
      "question": "クラスタリングにおいて、事前にクラスタ数を決める必要がなく、データ間の類似度をもとに「木構造（デンドログラム）」を作成する手法を何というか。",
      "options": [
        "k-means法",
        "主成分分析",
        "階層的クラスタリング",
        "最近傍法"
      ],
      "answer": 2,
      "explanation": "階層的クラスタリング（ウォード法など）は、個々のデータを最も近いものから順に統合していく過程を階層的に記述する手法です。"
    },
    {
      "id": 148,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "誤差関数",
      "question": "異常検知のAIモデルにおいて、正常なデータの「再現誤差」を指標として異常を判定する場合によく用いられるモデルはどれか。",
      "options": [
        "オートエンコーダ",
        "ロジスティック回帰",
        "GAN",
        "RNN"
      ],
      "answer": 0,
      "explanation": "正常データのみで学習したオートエンコーダは、正常データは元通りに復元できますが、異常データを入れると大きな誤差が生じる性質を利用します。"
    },
    {
      "id": 149,
      "majorCategory": "数理・統計・情報学",
      "subCategory": "確率論",
      "question": "サイコロを振ったときの目の期待値はいくつか。",
      "options": [
        "3",
        "3.5",
        "4",
        "4.5"
      ],
      "answer": 1,
      "explanation": "期待値は (1+2+3+4+5+6)/6 = 3.5 となります。データ全体の平均的な予測値を示す重要な指標です。"
    },
    {
      "id": 150,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIプロジェクトの進め方",
      "question": "AIシステムを外部のアプリケーションから呼び出して利用するために、データの受け渡しルールを定めた窓口のことを何というか。",
      "options": [
        "UI (User Interface)",
        "API (Application Programming Interface)",
        "Backend",
        "Gateway"
      ],
      "answer": 1,
      "explanation": "AIモデルをWeb APIとして公開することで、既存の業務システムやスマホアプリからAIを簡単に活用できるようになります。"
    },
    {
      "id": 151,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "プライバシー",
      "question": "店舗などの防犯カメラ画像をAIで分析する際、プライバシー保護の観点から推奨される処理はどれか。",
      "options": [
        "すべての通行人の顔を保存し続ける",
        "特定の個人を識別できないよう、入店後速やかに顔をぼかす、または特徴量のみを抽出して破棄する",
        "インターネットに全データを公開する",
        "加工せずに氏名と紐付けたデータベースを作成する"
      ],
      "answer": 1,
      "explanation": "「カメラ画像利活用ガイドブック」などでは、個人識別性を低減するための適切な加工や、利用目的の明示が求められています。"
    },
    {
      "id": 152,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "不正競争防止法",
      "question": "不正競争防止法において保護される「営業秘密」として認められるための3要件（秘密管理性、有用性、非公知性）に含まれないものはどれか。",
      "options": [
        "政府に登録されていること",
        "秘密として管理されていること",
        "事業活動に有用であること",
        "公に知られていないこと"
      ],
      "answer": 0,
      "explanation": "営業秘密は、特許と異なり登録義務はなく、自社で厳重に管理（秘密管理性等）していることが要件となります。"
    },
    {
      "id": 153,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "自然言語処理",
      "question": "ユーザーの質問（入力プロンプト）に対して、AIが学習データに基づき「もっともらしいが事実とは異なる回答」をしてしまう現象を何というか。",
      "options": [
        "オーバーフィッティング",
        "ハルシネーション",
        "バリアンス",
        "勾配消失"
      ],
      "answer": 1,
      "explanation": "ハルシネーションは生成AIの主要なリスクであり、RAGなどの外部知識統合によって軽減が図られています。"
    },
    {
      "id": 154,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデルの選択・評価",
      "question": "多クラス分類において、あるクラスが極端に少ない場合に、単純な正解率ではなく「クラスごとの正解率の平均」を重視して評価することを何というか。",
      "options": [
        "マクロ平均",
        "マイクロ平均",
        "加重平均",
        "算術平均"
      ],
      "answer": 0,
      "explanation": "マクロ平均は全てのクラスを対等に扱うため、不均衡なデータの評価に適しています。一方マイクロ平均はデータ個数を重視します。"
    },
    {
      "id": 155,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "画像認識",
      "question": "1枚の画像のみ、または極めて少数の学習データだけで、新しい物体を認識できるようにする学習手法を何というか。",
      "options": [
        "Few-shot学習",
        "フルファインチューニング",
        "一斉学習",
        "アンサンブル学習"
      ],
      "answer": 0,
      "explanation": "Few-shot学習（またはOne-shot学習）は、メタ学習などの技術を用いて、少量の教材から知識を獲得するAIの研究分野です。"
    },
    {
      "id": 156,
      "majorCategory": "ディープラーニングをめぐる動向",
      "subCategory": "生成 AI",
      "question": "プロンプトの中に思考の過程（推理ステップ）を一行ずつ記述させることで、LLMの推論精度を向上させるテクテクニックを何というか。",
      "options": [
        "Chain-of-Thought",
        "Zero-shot",
        "RLHF",
        "データアノテーション"
      ],
      "answer": 0,
      "explanation": "CoT（思考の連鎖）を用いることで、複雑な算術や論理的な問題をステップバイステップで正しく解けるようになります。"
    },
    {
      "id": 157,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "環境保護",
      "question": "大規模なAIモデルの学習において、消費電力や二酸化炭素排出量の増大が懸念されている。この課題に対する取り組みの指標を何というか。",
      "options": [
        "グリーンAI",
        "モデル圧縮",
        "カーボンニュートラル",
        "省電力CPU"
      ],
      "answer": 0,
      "explanation": "性能だけでなく「環境負荷（学習コスト）」の低減も目指すAI開発の潮流は、グリーンAIと呼ばれています。"
    },
    {
      "id": 158,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "知識表現",
      "question": "IBMが開発し、米国のクイズ番組「ジェパディ!」で人間に勝利した、質問応答に特化したAIシステムは何か。",
      "options": [
        "DeepBlue",
        "Watson",
        "AlphaGo",
        "Siri"
      ],
      "answer": 1,
      "explanation": "Watson（ワトソン）はNLP、知識抽出、仮説生成などの技術を組み合わせた、2010年代初頭の代表的なAIです。"
    },
    {
      "id": 159,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "労働政策",
      "question": "AIの普及により、単純作業が自動化され「人間の仕事が奪われる」懸念がある一方で、AIを活用する新しいスキルが求められる変化を何というか。",
      "options": [
        "リスキリング",
        "アウトソーシング",
        "オフショア",
        "デジタルトランスフォーメーション"
      ],
      "answer": 0,
      "explanation": "リスキリング（学び直し）は、AI社会において労働者が新しい役割に適応するために不可欠なプロセスとされています。"
    },
    {
      "id": 160,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の定義",
      "question": "「計算機に知能を持たせる」というビジョンの下、1956年に開催されたAI研究の起源とされる会議は何というか。",
      "options": [
        "ダートマス会議",
        "チューリングカンファンレンス",
        "Google I/O",
        "世界経済フォーラム"
      ],
      "answer": 0,
      "explanation": "ダートマス会議（Dartmouth Workshop）において、「Artificial Intelligence（人工知能）」という言葉が初めて公式に使われました。"
    }
  ]
}