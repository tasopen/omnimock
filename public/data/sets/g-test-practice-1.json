{
  "metadata": {
    "title": "G検定 模擬試験 1",
    "description": "シラバス2024対応 分野別網羅・実戦問題（人工知能・機械学習・ディープラーニング・社会実装・法令）",
    "totalQuestions": 160,
    "passLine": 70,
    "timeLimit": 100
  },
  "questions": [
    {
      "id": 1,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の定義",
      "question": "人工知能（AI）の定義に関する説明として、最も適切なものはどれか。",
      "options": [
        "専門家の間でも明確な定義は定まっていない",
        "人間の脳の構造を完全に模倣したシステムである",
        "自律的に意思を持ち、人間と対話できる機械である",
        "特定のタスクにおいて人間を超える性能を持つプログラムである"
      ],
      "answer": 0,
      "explanation": "人工知能には統一された定義が存在せず、研究者によって「人間の知能を模倣するもの」「合理的に行動するもの」など様々な解釈がなされています。"
    },
    {
      "id": 2,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の定義",
      "question": "人工知能のレベル分類（レベル1〜4）において、「レベル3」に該当するものはどれか。",
      "options": [
        "検索エンジンなどの機械学習を取り入れたAI",
        "掃除ロボットなどの単純な制御プログラム",
        "将棋プログラムなどのルールベースの古典的AI",
        "ディープラーニングを用いた画像認識AI"
      ],
      "answer": 0,
      "explanation": "レベル3は「機械学習」を取り入れ、データからルールや知識を学習するAIを指します。レベル1は制御、レベル2は探索・推論（古典的AI）、レベル4は深層学習（特徴表現学習）です。"
    },
    {
      "id": 3,
      "majorCategory": "人工知能とは",
      "subCategory": "AI効果",
      "question": "「AI効果」と呼ばれる現象の説明として適切なものはどれか。",
      "options": [
        "AIの原理が解明されると、それは単なる自動化とみなされ「知能」とは呼ばれなくなる現象",
        "AIが社会に普及することで、人間の仕事が奪われる現象",
        "AIの学習データが増えるほど、指数関数的に性能が向上する現象",
        "AIが自らより賢いAIを作り出し、知能が無限に向上する現象"
      ],
      "answer": 0,
      "explanation": "AI効果とは、新しい技術が実現され仕組みが分かってしまうと、「それは単なる計算/自動化であって知能ではない」とみなされてしまう心理的な現象を指します。"
    },
    {
      "id": 4,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "第1次AIブーム",
      "question": "1960年代の第1次AIブームで中心となった技術で、迷路やパズルなどの問題を解くために用いられた手法はどれか。",
      "options": [
        "探索・推論",
        "エキスパートシステム",
        "機械学習",
        "ディープラーニング"
      ],
      "answer": 0,
      "explanation": "第1次AIブームでは、「探索」と「推論」によって特定の問題（トイ・プロブレム）を解く研究が進みました。"
    },
    {
      "id": 5,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "第2次AIブーム",
      "question": "1980年代の第2次AIブームにおいて注目された、専門家の知識をコンピュータに移植して問題解決を図るシステムを何というか。",
      "options": [
        "エキスパートシステム",
        "ニューラルネットワーク",
        "サポートベクターマシン",
        "知的エージェント"
      ],
      "answer": 0,
      "explanation": "エキスパートシステムは、専門家の知識を「もし〜なら、〜である（If-Thenルール）」という形式で記述し、推論を行うシステムです。"
    },
    {
      "id": 6,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "第3次AIブーム",
      "question": "2010年代から続く第3次AIブームのきっかけとなった、データに含まれる特徴的な要素（特徴量）を機械自らが学習する技術はどれか。",
      "options": [
        "ディープラーニング",
        "サポートベクターマシン",
        "遺伝的アルゴリズム",
        "ベイジアンネットワーク"
      ],
      "answer": 0,
      "explanation": "第3次AIブームは、ディープラーニングにより「特徴量」を人間が設計しなくても機械が自動で獲得できるようになった（表現学習）ことが大きな要因です。"
    },
    {
      "id": 7,
      "majorCategory": "人工知能とは",
      "subCategory": "トイ・プロブレム",
      "question": "第1次AIブームの終焉に関わる課題で、迷路のような単純な問題は解けるが、現実世界の複雑な問題は解けないことを何と呼ぶか。",
      "options": [
        "トイ・プロブレム",
        "フレーム問題",
        "シンボルグラウンディング問題",
        "チューリングテスト"
      ],
      "answer": 0,
      "explanation": "トイ・プロブレムは、ルールが明確で限定された単純な問題のことです。当時のAIはこれしか解けませんでした。"
    },
    {
      "id": 8,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の課題",
      "question": "「あるタスクを実行する際、関係のある知識だけを選び出すことが（無限の可能性を考慮する必要があるため）論理的に困難である」という問題を何というか。",
      "options": [
        "フレーム問題",
        "シンボルグラウンディング問題",
        "中国語の部屋",
        "ノーフリーランチ定理"
      ],
      "answer": 0,
      "explanation": "フレーム問題は、マッカーシーらが提唱した人工知能における難問の一つで、現実世界のような枠組み（フレーム）のない環境での対処の難しさを指摘しています。"
    },
    {
      "id": 9,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の課題",
      "question": "「コンピュータは記号（シンボル）の意味を理解しておらず、記号と実世界の対象が結びついていない」という問題を何というか。",
      "options": [
        "シンボルグラウンディング問題",
        "フレーム問題",
        "身体性",
        "モラベックのパラドックス"
      ],
      "answer": 0,
      "explanation": "記号接地問題とも呼ばれ、AIが「シマウマ」という言葉を知っていても、実物のシマウマと結び付けられない（意味を理解していない）状態を指します。"
    },
    {
      "id": 10,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能のコンセプト",
      "question": "哲学者ジョン・サールが提唱した、コンピュータは記号操作を行っているだけであり、本当に「理解」しているわけではないという思考実験を何というか。",
      "options": [
        "中国語の部屋",
        "チューリングテスト",
        "トロッコ問題",
        "水槽の脳"
      ],
      "answer": 0,
      "explanation": "中国語の部屋は、マニュアル通りに漢字を操作して返答できても、その人は中国語を理解しているとは言えないという例えで、強いAI（真の理解）を否定する議論です。"
    },
    {
      "id": 11,
      "majorCategory": "人工知能とは",
      "subCategory": "シンギュラリティ",
      "question": "レイ・カーツワイルらが提唱した、AIが人間の知能を超え、技術的進歩が加速度的に進む転換点のことを何というか。",
      "options": [
        "シンギュラリティ",
        "収穫加速の法則",
        "ムーアの法則",
        "AIの冬"
      ],
      "answer": 0,
      "explanation": "シンギュラリティに到達すると、AIが自分より賢いAIを作り出し、人間の予測を超えた進化を始めるとされています。カーツワイルは2045年と予測しました。"
    },
    {
      "id": 12,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "入力データとそれに対応する正解（ラベル）のペアを与えてモデルを学習させる手法を何というか。",
      "options": [
        "教師あり学習",
        "教師なし学習",
        "強化学習",
        "半教師あり学習"
      ],
      "answer": 0,
      "explanation": "教師あり学習は、正解データ（教師データ）をもとに、入力から出力を予測するモデルを学習します。回帰や分類が該当します。"
    },
    {
      "id": 13,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "正解ラベルを与えず、データそのものが持つ構造や特徴を学習させる手法はどれか。",
      "options": [
        "クラスタリング",
        "回帰分析",
        "サポートベクターマシン",
        "ランダムフォレスト"
      ],
      "answer": 0,
      "explanation": "クラスタリングや次元削減など、データの背後にあるパターンを見つけ出す手法が教師なし学習です。"
    },
    {
      "id": 14,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "「エージェント」が「環境」の中で行動し、得られる「報酬」を最大化するように学習する手法はどれか。",
      "options": [
        "強化学習",
        "深層学習",
        "転移学習",
        "アンサンブル学習"
      ],
      "answer": 0,
      "explanation": "強化学習は、試行錯誤を通じて最適な行動指針（方策）を獲得する手法です。"
    },
    {
      "id": 15,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習データ",
      "question": "手元の全データを「訓練データ」「検証データ」「テストデータ」の3つに分割する目的として、最も適切なものはどれか。",
      "options": [
        "過学習を防ぎ、未知のデータに対する汎化性能を正しく評価するため",
        "データ数を減らして計算時間を短縮するため",
        "データの偏りをなくして正解率を上げるため",
        "ハイパーパラメータの調整を不要にするため"
      ],
      "answer": 0,
      "explanation": "訓練で学習し、検証でハイパーパラメータ等を調整し、最終的に学習に使っていないテストデータで性能を評価することで、汎化性能を確認します。"
    },
    {
      "id": 16,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習の課題",
      "question": "訓練データに対しては高い精度を示すが、未知のデータ（テストデータ）に対しては精度が著しく低くなる現象を何というか。",
      "options": [
        "過学習",
        "学習不足",
        "次元の呪い",
        "勾配消失"
      ],
      "answer": 0,
      "explanation": "過学習は、モデルが訓練データのノイズや細かい特徴まで覚えすぎてしまい、一般的な法則を捉えられなくなった状態です。"
    },
    {
      "id": 17,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "単回帰分析 $y = ax + b$ において、実際のデータ点と予測値との差（残差）の二乗和を最小にするように $a, b$ を求める手法はどれか。",
      "options": [
        "最小二乗法",
        "最尤法",
        "勾配降下法",
        "ラグランジュの未定乗数法"
      ],
      "answer": 0,
      "explanation": "最小二乗法（Least Squares Method）は、回帰分析でパラメータを推定する最も基本的な手法です。"
    },
    {
      "id": 18,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習のテクニック",
      "question": "過学習を防ぐために、誤差関数に重みの大きさ（ノルム）を表す項（罰則項）を加える手法を何というか。",
      "options": [
        "正則化",
        "正規化",
        "標準化",
        "最適化"
      ],
      "answer": 0,
      "explanation": "正則化（L1正則化、L2正則化など）は、パラメータの値が大きくなりすぎるのを防ぎ、モデルを単純化して過学習を抑制します。"
    },
    {
      "id": 19,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "L1正則化を用いた回帰分析で、不要な特徴量の重みを完全に0にできる性質（スパース性）を持つものはどれか。",
      "options": [
        "ラッソ回帰",
        "リッジ回帰",
        "エラスティックネット",
        "ロジスティック回帰"
      ],
      "answer": 0,
      "explanation": "ラッソ回帰はL1ノルム（重みの絶対値の和）を罰則項に使い、特定の特徴量を0にする（変数選択の効果がある）のが特徴です。"
    },
    {
      "id": 20,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "名前に「回帰」とつくが、実際には2値分類問題に使われる手法で、出力をシグモイド関数で0から1の確率に変換するものはどれか。",
      "options": [
        "ロジスティック回帰",
        "線形回帰",
        "ポアソン回帰",
        "サポートベクターマシン"
      ],
      "answer": 0,
      "explanation": "ロジスティック回帰は、線形結合の結果をシグモイド関数に通して確率を出力し、ある閾値（0.5など）で分類を行います。"
    },
    {
      "id": 21,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "データを分離する境界線（超平面）と、最も近いデータ点（サポートベクター）との距離（マージン）を最大化する分類手法はどれか。",
      "options": [
        "サポートベクターマシン",
        "決定木",
        "k-近傍法",
        "ナイーブベイズ"
      ],
      "answer": 0,
      "explanation": "マージン最大化により汎化性能の高い境界線を引くのがSVMの特徴です。"
    },
    {
      "id": 22,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "データを特定の条件（「年齢が30以上か？」など）で分岐させ、木構造で分類や回帰を行う手法を何というか。",
      "options": [
        "決定木",
        "ランダムフォレスト",
        "ニューラルネットワーク",
        "k-means法"
      ],
      "answer": 0,
      "explanation": "決定木は結果の解釈が容易（ホワイトボックス性が高い）ですが、単体では過学習しやすい傾向があります。"
    },
    {
      "id": 23,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "複数の決定木を並列に学習させ、その多数決で結果を決めることで精度と安定性を高める「バギング」の代表的な手法はどれか。",
      "options": [
        "ランダムフォレスト",
        "勾配ブースティング",
        "AdaBoost",
        "XGBoost"
      ],
      "answer": 0,
      "explanation": "ランダムフォレストは、バギング（データを復元抽出）と特徴量のランダム選択を組み合わせた強力な手法です。"
    },
    {
      "id": 24,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "複数の弱学習器を逐次的に学習させ、前のモデルが間違えたデータを重視して次のモデルを学習させる手法の総称はどれか。",
      "options": [
        "ブースティング",
        "バギング",
        "スタッキング",
        "投票法"
      ],
      "answer": 0,
      "explanation": "ブースティング（Boosting）は、弱学習器を直列につなげて性能を高める手法で、AdaBoostやGBDT（勾配ブースティング木）が有名です。"
    },
    {
      "id": 25,
      "majorCategory": "機械学習の概要",
      "subCategory": "k-means法",
      "question": "教師なし学習のクラスタリング手法で、あらかじめ決めた数k個の重心（セントロイド）を更新しながらデータをグループ分けする手法はどれか。",
      "options": [
        "k-means法",
        "k-近傍法",
        "階層的クラスタリング",
        "DBSCAN"
      ],
      "answer": 0,
      "explanation": "k-means法はシンプルで高速ですが、初期値依存性やkの値を事前に決める必要がある点が課題です。"
    },
    {
      "id": 26,
      "majorCategory": "機械学習の概要",
      "subCategory": "データ前処理・分析",
      "question": "高次元データの分散が最大になる方向（主成分）を見つけ、低い次元にデータを圧縮する手法はどれか。",
      "options": [
        "主成分分析",
        "t-SNE",
        "LDA",
        "特異値分解"
      ],
      "answer": 0,
      "explanation": "PCAは、データの情報をなるべく損なわずに次元を減らすための代表的な手法です。"
    },
    {
      "id": 27,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "混同行列（Confusion Matrix）において、実際は「陽性」なのに誤って「陰性」と予測してしまった事例を何と呼ぶか。",
      "options": [
        "偽陰性",
        "偽陽性",
        "真陰性",
        "真陽性"
      ],
      "answer": 0,
      "explanation": "実際は陽性（Positive）なのを見逃した（Negativeと判定した）ので、False Negative（偽陰性）です。取りこぼしです。"
    },
    {
      "id": 28,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "「実際に陽性であるデータ」のうち、「正しく陽性と予測できた」割合を示す指標はどれか。（見逃しの少なさを表す）",
      "options": [
        "再現率",
        "適合率",
        "正解率",
        "特異度"
      ],
      "answer": 0,
      "explanation": "再現率（Recall）は、病気の発見など「見逃し（偽陰性）を減らしたい」場合に重視される指標です。"
    },
    {
      "id": 29,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "「陽性と予測したデータ」のうち、「実際に陽性であった」割合を示す指標はどれか。（誤検知の少なさを表す）",
      "options": [
        "適合率",
        "再現率",
        "F値",
        "正解率"
      ],
      "answer": 0,
      "explanation": "適合率（Precision）は、スパム判定など「正常なものを誤って排除したくない（偽陽性を減らしたい）」場合に重視されます。"
    },
    {
      "id": 30,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "適合率と再現率のバランスをとった指標であるF値（F1-score）の計算式として正しいものはどれか。",
      "options": [
        "適合率と再現率の調和平均",
        "適合率と再現率の算術平均",
        "適合率と再現率の幾何平均",
        "適合率と再現率の積"
      ],
      "answer": 0,
      "explanation": "F値は $\\frac{2 \\times Precision \\times Recall}{Precision + Recall}$ で計算される調和平均です。"
    },
    {
      "id": 31,
      "majorCategory": "機械学習の概要",
      "subCategory": "ROC曲線",
      "question": "分類モデルの評価において、横軸に偽陽性率（FPR）、縦軸に真陽性率（TPR）をとり、閾値を変化させたときの軌跡を描いた曲線を何というか。",
      "options": [
        "ROC曲線",
        "PR曲線",
        "学習曲線",
        "シグモイド曲線"
      ],
      "answer": 0,
      "explanation": "ROC曲線の下側の面積（AUC）が大きいほど、優れたモデルであると評価できます。"
    },
    {
      "id": 32,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "パーセプトロン",
      "question": "1958年にローゼンブラットが考案した、複数の入力に重みを掛けて足し合わせ、閾値判定を行う単純なモデルを何というか。",
      "options": [
        "単純パーセプトロン",
        "多層パーセプトロン",
        "ニューロン",
        "シナプス"
      ],
      "answer": 0,
      "explanation": "単純パーセプトロンは線形分離可能な問題しか解けず、XOR問題（排他的論理和）を解けないという限界が指摘されました（ミンスキーらによる指摘）。"
    },
    {
      "id": 33,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ディープラーニングの基礎",
      "question": "単純パーセプトロンの限界であった「線形分離不可能な問題（XORなど）」を解決するために導入された構造はどれか。",
      "options": [
        "隠れ層を追加した多層化",
        "活性化関数の除去",
        "重みの固定",
        "入力層の削除"
      ],
      "answer": 0,
      "explanation": "入力層と出力層の間に隠れ層を入れることで、非線形な領域を表現できるようになり、XOR問題などが解決されました。"
    },
    {
      "id": 34,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "NNの構成要素",
      "question": "多層ニューラルネットワークの学習（重みの更新）を効率的に行うためのアルゴリズムで、出力誤差を入力側に向かって伝播させる手法はどれか。",
      "options": [
        "誤差逆伝播法",
        "フィードフォワード",
        "自己符号化",
        "最尤推定"
      ],
      "answer": 0,
      "explanation": "誤差逆伝播法は、連鎖律（Chain Rule）を用いて各パラメータの勾配を効率的に計算し、勾配降下法で学習を進めるための核心技術です。"
    },
    {
      "id": 35,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習の課題",
      "question": "層を深くすると、出力側の誤差が入力側に伝わるにつれて小さくなり、学習が進まなくなる現象を何というか。",
      "options": [
        "勾配消失問題",
        "勾配爆発問題",
        "過学習",
        "局所最適解"
      ],
      "answer": 0,
      "explanation": "シグモイド関数などを活性化関数に使うと、微分値が最大でも0.25にしかならないため、層を経るごとに勾配が消えてしまう問題です。"
    },
    {
      "id": 36,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "NNの構成要素",
      "question": "勾配消失問題を緩和するために提案され、入力が0より大きければそのまま出力し、0以下なら0を出力する関数はどれか。",
      "options": [
        "ReLU",
        "Sigmoid",
        "Tanh",
        "Softmax"
      ],
      "answer": 0,
      "explanation": "ReLUは正の領域で微分値が常に1であるため、勾配が消失しにくく、現在のディープラーニングで標準的に使われています。"
    },
    {
      "id": 37,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "NNの構成要素",
      "question": "多クラス分類問題において、出力層で用いられ、出力を確率（合計が1）に変換する関数はどれか。",
      "options": [
        "ソフトマックス関数",
        "シグモイド関数",
        "恒等関数",
        "ステップ関数"
      ],
      "answer": 0,
      "explanation": "ソフトマックス関数は、複数の出力の合計が1になるように正規化するため、確率として解釈できます。"
    },
    {
      "id": 38,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "事前学習",
      "question": "ディープラーニングの学習において、層ごとにオートエンコーダなどを使って良い初期値を求めてから学習する手法（現在はあまり使われない）はどれか。",
      "options": [
        "事前学習  とファインチューニング",
        "バッチ正規化",
        "ドロップアウト",
        "データ拡張"
      ],
      "answer": 0,
      "explanation": "2006年にヒントンらが提案した「積層オートエンコーダによる事前学習」は、深層学習が可能になるブレイクスルーでしたが、現在はReLUやBatch Norm等の登場により、教師あり学習のみで学習可能となり使われなくなりました。"
    },
    {
      "id": 39,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "勾配降下法において、学習全体を通して一度に全データを使うのではなく、少数のデータをランダムに選んで更新する手法を何というか。",
      "options": [
        "確率的勾配降下法",
        "最急降下法",
        "ニュートン法",
        "モーメンタム"
      ],
      "answer": 0,
      "explanation": "SGD（Stochastic Gradient Descent）は、局所解に陥りにくく、計算も高速であるため、ディープラーニング学習の基本となっています。"
    },
    {
      "id": 40,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "SGDの欠点を改善するために、過去の勾配の「慣性（Momentum）」を利用して振動を抑えつつ加速する手法はどれか。",
      "options": [
        "Momentum",
        "AdaGrad",
        "RMSProp",
        "Adam"
      ],
      "answer": 0,
      "explanation": "Momentum（モーメンタム）は、物理の慣性のように、過去に進んでいた方向に勢いをつけることで、学習を安定・高速化させます。"
    },
    {
      "id": 41,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "学習率をパラメータごとに自動調整する手法で、MomentumとRMSPropの利点を組み合わせた、現在最もよく使われる手法はどれか。",
      "options": [
        "Adam",
        "AdaDelta",
        "AdaGrad",
        "SGD"
      ],
      "answer": 0,
      "explanation": "Adam（Adaptive Moment Estimation）は、勾配の平均（1次モーメント）と分散（2次モーメント）を利用してパラメータごとに学習率を調整します。"
    },
    {
      "id": 42,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "学習が進まなくなったときに、学習率を徐々に小さくしていく手法を何というか。",
      "options": [
        "学習率減衰",
        "重み減衰",
        "勾配クリッピング",
        "早期終了"
      ],
      "answer": 0,
      "explanation": "学習率減衰（Learning Rate Scheduling）は、最初は大きく更新し、後半は小さく更新することで、最適解に収束させやすくします。"
    },
    {
      "id": 43,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "テストデータの誤差が増加し始めた時点で学習を強制的に打ち切り、過学習を防ぐ手法はどれか。",
      "options": [
        "早期終了",
        "ドロップアウト",
        "データ拡張",
        "バッチ正規化"
      ],
      "answer": 0,
      "explanation": "Early Stoppingは、検証データの誤差を監視し、性能が悪化（過学習開始）する前に学習を止める実用的な手法です。"
    },
    {
      "id": 44,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "各層の入力を、平均0、分散1になるように正規化することで、学習を劇的に安定・高速化させる手法はどれか。",
      "options": [
        "バッチ正規化",
        "局所コントラスト正規化",
        "白色化",
        "ドロップアウト"
      ],
      "answer": 0,
      "explanation": "Batch Normalizationは、内部共変量シフト（層ごとの分布の変化）を抑える効果があり、初期値への依存性を下げるなどの利点があります。"
    },
    {
      "id": 45,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "学習時にランダムにニューロンを選んで無効化（出力を0に）し、擬似的にアンサンブル学習のような効果を得る手法はどれか。",
      "options": [
        "ドロップアウト",
        "ドロップコネクト",
        "プーリング",
        "スキップ結合"
      ],
      "answer": 0,
      "explanation": "ドロップアウトは、特定のニューロンへの依存（共適応）を防ぎ、モデルのロバスト性を高めます。"
    },
    {
      "id": 46,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "畳み込みニューラルネットワーク（CNN）において、画像などの局所的な特徴（エッジなど）を抽出する層はどれか。",
      "options": [
        "畳み込み層",
        "プーリング層",
        "全結合層",
        "正規化層"
      ],
      "answer": 0,
      "explanation": "畳み込み層は、フィルタ（カーネル）をスライドさせながら積和演算を行い、特徴マップを生成します。"
    },
    {
      "id": 47,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "畳み込み層のハイパーパラメータで、フィルタを一回に何ピクセルずらすかを指定する値はどれか。",
      "options": [
        "ストライド",
        "パディング",
        "カーネルサイズ",
        "チャンネル数"
      ],
      "answer": 0,
      "explanation": "ストライドを大きくすると出力サイズは小さくなり、小さく（1など）すると出力サイズは大きくなります。"
    },
    {
      "id": 48,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "画像の周囲に0などを埋めて、畳み込みによるサイズ縮小を防ぐ処理を何というか。",
      "options": [
        "パディング",
        "マスキング",
        "クロッピング",
        "プーリング"
      ],
      "answer": 0,
      "explanation": "ゼロパディングが一般的です。画像の端の情報を活用するためにも重要です。"
    },
    {
      "id": 49,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "CNNにおいて、特徴マップの微小な位置ズレを許容し、重要な情報を残しながらサイズを小さくする層はどれか。",
      "options": [
        "プーリング層",
        "畳み込み層",
        "全結合層",
        "ソフトマックス層"
      ],
      "answer": 0,
      "explanation": "Max Pooling（最大値プーリング）などが代表的で、局所領域の最大値を取り出すことで、多少の位置ズレにおける不変性（Translation Invariance）を獲得します。"
    },
    {
      "id": 50,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "データ拡張",
      "question": "画像の回転、反転、拡大縮小、明度変更などを行い、学習データを水増しして汎化性能を高める手法はどれか。",
      "options": [
        "Data Augmentation",
        "Fine-tuning",
        "Transfer Learning",
        "Ensemble Learning"
      ],
      "answer": 0,
      "explanation": "データ拡張は、限られたデータ量で高い性能を出すために必須のテクニックです。CutoutやMixupなどの高度な手法もあります。"
    },
    {
      "id": 51,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "CNNアーキテクチャ",
      "question": "2012年のILSVRCで圧勝し、ディープラーニングブームの火付け役となったモデルはどれか。",
      "options": [
        "AlexNet",
        "LeNet",
        "VGG",
        "ResNet"
      ],
      "answer": 0,
      "explanation": "AlexNetは、ReLUやDropout、GPUの実装などを取り入れた8層のモデルで、従来手法に大差をつけて優勝しました。"
    },
    {
      "id": 52,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "CNNアーキテクチャ",
      "question": "2014年に登場した、3×3の小さなフィルタを積み重ねて層を深く（16層や19層）したシンプルなモデルはどれか。",
      "options": [
        "VGG",
        "GoogLeNet",
        "ResNet",
        "DenseNet"
      ],
      "answer": 0,
      "explanation": "VGG（Visual Geometry Group）は構造が単純で扱いやすく、現在でも転移学習のベースモデルとしてよく利用されます。"
    },
    {
      "id": 53,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "時系列データや自然言語のように、前後の文脈が重要なデータを扱うのに適した、内部にループ構造を持つネットワークはどれか。",
      "options": [
        "RNN",
        "CNN",
        "MLP",
        "GAN"
      ],
      "answer": 0,
      "explanation": "RNNは隠れ層の状態を次の時刻の入力として利用することで、過去の情報を記憶しながら処理できます。"
    },
    {
      "id": 54,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "RNNの学習において、時間を遡って誤差を伝播させる手法を何というか。",
      "options": [
        "BPTT",
        "BP",
        "SGD",
        "LSTM"
      ],
      "answer": 0,
      "explanation": "RNNを展開したネットワークに対して誤差逆伝播法を適用することをBPTTと呼びます。"
    },
    {
      "id": 55,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "RNNの課題である勾配消失問題を解決し、長期的な依存関係を学習できるように「ゲート」機構を導入したモデルはどれか。",
      "options": [
        "LSTM",
        "GRU",
        "Simple RNN",
        "Elman Net"
      ],
      "answer": 0,
      "explanation": "LSTMは「入力ゲート」「出力ゲート」「忘却ゲート」と「セル状態」を持ち、情報の保持・破棄を選択的に行えます。"
    },
    {
      "id": 56,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "LSTMを簡素化し、パラメータ数を減らしつつ同等の性能を維持することを目指したモデルはどれか。",
      "options": [
        "GRU",
        "Bi-LSTM",
        "Transformer",
        "Echo State Network"
      ],
      "answer": 0,
      "explanation": "GRUは「リセットゲート」と「更新ゲート」の2つのみを持ち、セル状態を持たないシンプルな構造です。"
    },
    {
      "id": 57,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Seq2Seq",
      "question": "機械翻訳などで用いられる、入力系列を固定長のベクトルに変換するEncoderと、そこから出力系列を生成するDecoderからなるモデルはどれか。",
      "options": [
        "Seq2Seq",
        "Word2Vec",
        "AutoEncoder",
        "ResNet"
      ],
      "answer": 0,
      "explanation": "Seq2Seqは、時系列データを別の時系列データに変換するモデルで、機械翻訳やチャットボットに応用されます。"
    },
    {
      "id": 58,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Attention",
      "question": "Seq2Seqの「長い文章だと文脈を忘れてしまう」という課題を解決するため、入力のどの単語に注目すべきかを学習する機構はどれか。",
      "options": [
        "Attention",
        "Dropout",
        "Normalization",
        "Pooling"
      ],
      "answer": 0,
      "explanation": "Attentionは、文中の重要な単語に重み（注意）を向けることで、長い系列でも適切に翻訳・生成できるようにする技術です。"
    },
    {
      "id": 59,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "2017年に発表され、RNNを使わずにAttention機構のみで高い性能を達成し、現在のLLMの基礎となったモデルはどれか。",
      "options": [
        "Transformer",
        "BERT",
        "GPT",
        "LSTM"
      ],
      "answer": 0,
      "explanation": "「Attention Is All You Need」という論文で提案され、並列計算が可能で学習効率が高いため、NLPのデファクトスタンダードとなりました。"
    },
    {
      "id": 60,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Self-Attention",
      "question": "Transformerにおいて、入力文の中の単語同士の関係性を計算するために用いられる、Query、Key、Valueの3つのベクトルを使う仕組みはどれか。",
      "options": [
        "Self-Attention",
        "Source-Target Attention",
        "Hard Attention",
        "Convolution"
      ],
      "answer": 0,
      "explanation": "Self-Attentionにより、「it」が何を指すかなど、文脈内の依存関係を捉えることができます。"
    },
    {
      "id": 61,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "Positional Encoding",
      "question": "TransformerはRNNのような順序処理を行わないため、単語の語順情報（位置情報）を埋め込みベクトルに加算する処理を何というか。",
      "options": [
        "Positional Encoding",
        "Word Embedding",
        "One-hot Encoding",
        "Tokenization"
      ],
      "answer": 0,
      "explanation": "サイン波やコサイン波を用いて、各単語が文中のどこにあるかという情報を付与します。"
    },
    {
      "id": 62,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "Googleが開発した、TransformerのEncoder部分を用い、文脈を双方向から学習することで高い理解能力を持つモデルはどれか。",
      "options": [
        "BERT",
        "GPT",
        "T5",
        "Word2Vec"
      ],
      "answer": 0,
      "explanation": "BERT（Bidirectional Encoder Representations from Transformers）は、マスクされた単語を予測する事前学習により、文脈理解に優れています。"
    },
    {
      "id": 63,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "OpenAIが開発した、TransformerのDecoder部分を用い、次に来る単語を予測することで文章生成に特化したモデルはどれか。",
      "options": [
        "GPT",
        "BERT",
        "ResNet",
        "VGG"
      ],
      "answer": 0,
      "explanation": "GPTシリーズは、大量のテキストデータを自己回帰的に学習させ、圧倒的な文章生成能力を実現しました。"
    },
    {
      "id": 64,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "画像の中から物体の「位置（バウンディングボックス）」と「種類（クラス）」を特定するタスクを何と呼ぶか。",
      "options": [
        "物体検出",
        "画像分類",
        "セマンティックセグメンテーション",
        "インスタンスセグメンテーション"
      ],
      "answer": 0,
      "explanation": "画像分類は「何が写っているか」、物体検出は「何がどこにあるか」を特定します。"
    },
    {
      "id": 65,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "物体検出の評価指標として、予測した枠と正解の枠の重なり具合（共通部分の面積÷和集合の面積）を表すものはどれか。",
      "options": [
        "IoU",
        "FPS",
        "AUC",
        "mAP"
      ],
      "answer": 0,
      "explanation": "IoU（Jaccard係数）が一定以上であれば「正解」とみなすなどして精度を計算します。"
    },
    {
      "id": 66,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "画像をグリッドに分割し、領域候補の提案とクラス分類を同時に行うことで、リアルタイム処理が可能な高速な物体検出モデルはどれか。",
      "options": [
        "YOLO",
        "R-CNN",
        "Fast R-CNN",
        "Faster R-CNN"
      ],
      "answer": 0,
      "explanation": "YOLOは1回の推論（One-stage）で検出を行うため、Two-stage系のR-CNNなどより高速です。"
    },
    {
      "id": 67,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "セグメンテーション",
      "question": "画像のすべての画素に対してクラスラベルを付与するが、同じクラスの個体（インスタンス）は区別しないタスクはどれか。",
      "options": [
        "セマンティックセグメンテーション",
        "インスタンスセグメンテーション",
        "パノプティックセグメンテーション",
        "物体検出"
      ],
      "answer": 0,
      "explanation": "例えば、複数の「人」が写っていても、すべて同じ「人」ピクセルとして扱います。"
    },
    {
      "id": 68,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "セグメンテーション",
      "question": "医療画像分析などで使われる、Encoderで特徴抽出しDecoderで元のサイズに復元するU字型の構造を持つモデルはどれか。",
      "options": [
        "U-Net",
        "FCN",
        "SegNet",
        "DeepLab"
      ],
      "answer": 0,
      "explanation": "U-Netは、スキップ結合を用いて位置情報をDecoderに伝えることで、境界を正確に抽出できます。"
    },
    {
      "id": 69,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "スキップ結合",
      "question": "層を飛び越して入力を出力に加算する「スキップ結合（ショートカット）」を導入し、152層などの超深層ネットワークの学習を可能にしたモデルはどれか。",
      "options": [
        "ResNet",
        "Inception",
        "DenseNet",
        "MobileNet"
      ],
      "answer": 0,
      "explanation": "残差（Residual）を学習させることで勾配消失を防ぎ、層を深くしても性能が向上するようになりました。"
    },
    {
      "id": 70,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "学習手法",
      "question": "あるタスクで学習済みのモデル（重み）を、別の関連するタスクの学習の初期値として利用する手法を何というか。",
      "options": [
        "転移学習",
        "ファインチューニング",
        "蒸留",
        "マルチタスク学習"
      ],
      "answer": 0,
      "explanation": "転移学習により、少ないデータ量でも高い精度のモデルを短時間で作成できます。"
    },
    {
      "id": 71,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "学習のテクニック",
      "question": "学習済みモデルの重みを初期値とし、新しいデータセットでネットワーク全体（または一部）を再学習させ、重みを微調整する手法はどれか。",
      "options": [
        "ファインチューニング",
        "特徴抽出",
        "メタ学習",
        "ゼロショット学習"
      ],
      "answer": 0,
      "explanation": "初期値が良い状態からスタートするため、学習が早く収束し、精度も高くなりやすいです。"
    },
    {
      "id": 72,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの軽量化",
      "question": "大規模なモデル（教師モデル）の知識を、小規模なモデル（生徒モデル）に継承させ、軽量化を図る手法を何というか。",
      "options": [
        "蒸留",
        "プルーニング",
        "量子化",
        "低ランク近似"
      ],
      "answer": 0,
      "explanation": "教師モデルの出力（ソフトラベル）を真似ることで、生徒モデルは軽量ながら高い性能を獲得できます。"
    },
    {
      "id": 73,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの軽量化",
      "question": "ニューラルネットワークのパラメータのうち、寄与度の低い重みを削除してモデルを軽量化する手法はどれか。",
      "options": [
        "プルーニング",
        "ドロップアウト",
        "量子化",
        "蒸留"
      ],
      "answer": 0,
      "explanation": "不要な接続を切ることで、推論速度の向上やメモリ削減を図ります。"
    },
    {
      "id": 74,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの軽量化",
      "question": "パラメータの表現ビット数を減らす（例：32bit浮動小数点を8bit整数にする）ことで、モデルサイズを圧縮する手法はどれか。",
      "options": [
        "量子化",
        "二値化",
        "ハッシング",
        "符号化"
      ],
      "answer": 0,
      "explanation": "精度をほとんど落とさずにメモリ使用量と計算コストを大幅に削減できるため、エッジAIなどで重要です。"
    },
    {
      "id": 75,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "生成AIの手法",
      "question": "入力データを潜在変数（低次元の特徴）に圧縮するEncoderと、そこからデータを復元するDecoderからなり、確率分布を学習して新しいデータを生成できるモデルはどれか。",
      "options": [
        "VAE",
        "GAN",
        "CNN",
        "RNN"
      ],
      "answer": 0,
      "explanation": "VAE（変分オートエンコーダ）は、潜在空間が連続的になるように学習するため、モーフィングのような生成が可能です。"
    },
    {
      "id": 76,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "生成AIの手法",
      "question": "「偽物を作る生成器」と「真贋を見抜く識別器」を競わせるように学習させることで、高品質なデータを生成するモデルはどれか。",
      "options": [
        "GAN",
        "VAE",
        "Flowモデル",
        "Pix2Pix"
      ],
      "answer": 0,
      "explanation": "GAN（敵対的生成ネットワーク）は、実在しない人物の顔画像などを非常にリアルに生成できます。"
    },
    {
      "id": 77,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "生成AIの手法",
      "question": "画像にノイズを加えていく過程を学習し、その逆変換（ノイズ除去）を行うことで画像を生成する、Stable Diffusionなどに使われているモデルはどれか。",
      "options": [
        "拡散モデル",
        "GAN",
        "Transformer",
        "LSTM"
      ],
      "answer": 0,
      "explanation": "拡散モデルは、学習の安定性が高く、多様で高品質な画像生成が可能です。"
    },
    {
      "id": 78,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "マルチモーダル",
      "question": "OpenAIが開発した、画像とテキストを共通の潜在空間に埋め込むことで、「テキストで画像を検索」したり「ゼロショット分類」を可能にしたモデルはどれか。",
      "options": [
        "CLIP",
        "DALL-E",
        "GPT-4",
        "ResNet"
      ],
      "answer": 0,
      "explanation": "CLIPは、大量の画像とテキストのペアを対照学習させることで、高い汎用性を持つマルチモーダルモデルです。"
    },
    {
      "id": 79,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "Q学習にディープラーニングを組み合わせ、Atariのゲームなどで人間を超える性能を出したDeepMind社のモデルはどれか。",
      "options": [
        "DQN",
        "A3C",
        "AlphaGo",
        "PPO"
      ],
      "answer": 0,
      "explanation": "DQN(Deep Q Network)は「経験再生（Experience Replay）」や「Target Network」といった工夫により、深層強化学習の学習を安定させました。"
    },
    {
      "id": 80,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "囲碁の世界チャンピオンに勝利したAI「AlphaGo」において、盤面の評価や次の一手の確率を計算するために使われた技術はどれか。",
      "options": [
        "モンテカルロ木探索  とディープラーニング",
        "完全解析",
        "遺伝的アルゴリズム",
        "ミニマックス法"
      ],
      "answer": 0,
      "explanation": "AlphaGoは、Value Network（盤面評価）とPolicy Network（手選び）という2つのCNNを、モンテカルロ木探索と組み合わせました。"
    },
    {
      "id": 81,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの解釈性",
      "question": "ブラックボックスになりがちなAIの判断根拠を人間が理解できるようにする技術体系を何というか。",
      "options": [
        "XAI",
        "AGI",
        "ANI",
        "HAI"
      ],
      "answer": 0,
      "explanation": "医療や金融など、説明責任が求められる分野で重要視されています。"
    },
    {
      "id": 82,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの解釈性",
      "question": "ある入力データの各特徴量が、予測結果にどれだけ影響を与えたかを「特徴量の重要度」として算出する手法はどれか。",
      "options": [
        "SHAP",
        "Grad-CAM",
        "t-SNE",
        "PCA"
      ],
      "answer": 0,
      "explanation": "SHAPは、協力ゲーム理論のシャープレイ値に基づいており、公平で一貫性のある重要度算出が可能です。"
    },
    {
      "id": 83,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの解釈性",
      "question": "CNNの判断根拠を可視化するため、最後の畳み込み層の勾配情報を使って、画像の中で「どこを見て判断したか」をヒートマップ表示する手法はどれか。",
      "options": [
        "Grad-CAM",
        "LIME",
        "Saliency Map",
        "Attention"
      ],
      "answer": 0,
      "explanation": "Grad-CAMは、特定のクラス判定に寄与した領域を視覚的に理解しやすいため、画像認識の説明によく使われます。"
    },
    {
      "id": 84,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "音声を周波数ごとの成分に分解し、時間の経過とともにどう変化するかを可視化した図を何というか。",
      "options": [
        "スペクトログラム",
        "オシログラム",
        "ヒストグラム",
        "散布図"
      ],
      "answer": 0,
      "explanation": "縦軸に周波数、横軸に時間、色で強さを表したもので、音声認識の入力データとしてよく使われます。"
    },
    {
      "id": 85,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "DeepMindが開発した、生の音声波形を直接生成することができ、非常に自然な音声を合成できるモデルはどれか。",
      "options": [
        "WaveNet",
        "Tacotron",
        "DeepVoice",
        "Vocoder"
      ],
      "answer": 0,
      "explanation": "WaveNetはDilated Convolution（穴あき畳み込み）を用いて広い受容野を確保し、長期的な波形の依存関係を学習します。"
    },
    {
      "id": 86,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "単語をベクトル化（埋め込み）する技術で、「王様 - 男性 + 女性 = 女王」のような演算ができることで有名なものはどれか。",
      "options": [
        "Word2Vec",
        "BoW",
        "TF-IDF",
        "One-hot Vector"
      ],
      "answer": 0,
      "explanation": "Word2Vecは、周囲の単語からその単語を予測する（またはその逆）タスクを通じて、単語の意味をベクトル空間上に配置します。"
    },
    {
      "id": 87,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "文書内の単語の出現頻度だけでなく、「多くの文書に出現する単語は重要度が低い」という考え方を反映した重み付け手法はどれか。",
      "options": [
        "TF-IDF",
        "BoW",
        "Word2Vec",
        "N-gram"
      ],
      "answer": 0,
      "explanation": "TF（Term Frequency：単語頻度）とIDF（Inverse Document Frequency：逆文書頻度）を掛け合わせた指標です。"
    },
    {
      "id": 88,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIプロジェクトの開発",
      "question": "AIプロジェクトの初期段階で行う、技術的な実現可能性や効果を検証するための小規模な試行を何というか。",
      "options": [
        "PoC",
        "アジャイル開発",
        "要件定義",
        "運用保守"
      ],
      "answer": 0,
      "explanation": "概念実証（PoC - Proof of Concept）を行い、データが十分か、AIで解ける問題か、ビジネス価値があるかを見定めてから本開発に進みます。"
    },
    {
      "id": 89,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIプロジェクトの開発",
      "question": "要件定義、設計、実装、テストと段階的に進める手法で、仕様が固まっている場合には適しているが、試行錯誤が必要なAI開発には不向きとされるのはどれか。",
      "options": [
        "ウォーターフォールモデル",
        "アジャイルモデル",
        "スパイラルモデル",
        "プロトタイピング"
      ],
      "answer": 0,
      "explanation": "AI開発はやってみないと精度が出るかわからない不確実性があるため、柔軟に変更できるアジャイル型が推奨されます。"
    },
    {
      "id": 90,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "データの収集",
      "question": "教師あり学習を行うために、収集したデータに対して正解ラベル（タグ）を付与する作業を何というか。",
      "options": [
        "アノテーション",
        "クレンジング",
        "オーグメンテーション",
        "スクレイピング"
      ],
      "answer": 0,
      "explanation": "アノテーション（Annotation）は、バウンディングボックス作成や分類ラベル付けなど、人手とコストがかかる工程です。"
    },
    {
      "id": 91,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "データの扱い",
      "question": "インターネットなどで無償で公開されており、利用規約の範囲内でAIの学習などに利用できるデータセットを何というか。",
      "options": [
        "オープンデータセット",
        "ビッグデータ",
        "ダークデータ",
        "シンセティックデータ"
      ],
      "answer": 0,
      "explanation": "Kaggleや政府、大学などが公開しているオープンデータセットを活用することで、データ収集の手間を省けます。"
    },
    {
      "id": 92,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "データの問題",
      "question": "学習データとテストデータに重複があったり、テストデータに含まれるべき答えが学習データに漏れてしまっている状態を何というか。",
      "options": [
        "リーケージ",
        "バイアス",
        "ノイズ",
        "欠損"
      ],
      "answer": 0,
      "explanation": "リーケージ（情報漏洩）が起きると、テスト時は高精度でも実運用で全く使えないモデルになってしまいます。"
    },
    {
      "id": 93,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "データ加工",
      "question": "データの前処理において、欠損値を平均値で埋めたり、異常値を除去したりする作業を総称して何というか。",
      "options": [
        "データクレンジング",
        "データ拡張",
        "データの正規化",
        "次元削減"
      ],
      "answer": 0,
      "explanation": "「Garbage In, Garbage Out（ゴミを入れたらゴミが出る）」と言われるように、クレンジングによるデータの質の確保は非常に重要です。"
    },
    {
      "id": 94,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "管理・運用",
      "question": "AIモデルを開発・運用する一連のサイクルを自動化・効率化し、継続的な改善を行うための手法や基盤を何というか。",
      "options": [
        "MLOps",
        "DevOps",
        "AIOps",
        "NoOps"
      ],
      "answer": 0,
      "explanation": "Machine Learning Operationsの略で、DevOpsの考え方を機械学習システムに適用したものです。"
    },
    {
      "id": 95,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "管理・運用",
      "question": "運用中のAIモデルの精度が、環境の変化やデータの傾向変化によって徐々に低下していく現象を何というか。",
      "options": [
        "コンセプトドリフト",
        "過学習",
        "破局的忘却",
        "勾配消失"
      ],
      "answer": 0,
      "explanation": "市場の変化などにより、学習時と運用時のデータの前提（コンセプト）がずれてしまうことです。定期的な再学習が必要です。"
    },
    {
      "id": 96,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "モデル評価",
      "question": "AIプロジェクトにおいて、AIの予測精度（Accuracyなど）だけでなく、ビジネス上の成果（売上向上、コスト削減など）を測るための指標を何というか。",
      "options": [
        "KPI",
        "AUC",
        "ROC",
        "KGI"
      ],
      "answer": 0,
      "explanation": "AI導入は手段であり、目的はビジネス価値の創出であるため、ビジネスKPI(Key Performance Indicator)の設定と評価が不可欠です。"
    },
    {
      "id": 97,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "日本の著作権法（第30条の4）において、AIの学習（情報解析）のための著作物の利用について正しい記述はどれか。",
      "options": [
        "営利・非営利を問わず、原則として著作権者の許諾なく利用できる",
        "非営利の研究目的に限り、許諾なく利用できる",
        "著作権者がAI学習禁止を明記している場合は利用できない",
        "利用するには文化庁への届け出が必要である"
      ],
      "answer": 0,
      "explanation": "日本は「機械学習パラダイス」とも呼ばれ、享受目的（鑑賞など）でなければ、原則として自由に学習データとして利用可能です。"
    },
    {
      "id": 98,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "AIが生成した作品に著作権が発生するための要件として、最も重要な要素はどれか。",
      "options": [
        "人間の創作的意図と創作的寄与があること",
        "AIが高性能であること",
        "プロンプトが長文であること",
        "生成にかかった時間が長いこと"
      ],
      "answer": 0,
      "explanation": "単にAIに指示を出しただけでは足りず、人間が道具としてAIを使いこなし、創作的な表現を加えたと認められる必要があります。"
    },
    {
      "id": 99,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "AI開発のために個人情報を第三者に提供する場合、原則として必要なことは何か。",
      "options": [
        "本人の同意を得ること",
        "匿名化すれば同意は不要",
        "契約書さえあればよい",
        "国への届け出"
      ],
      "answer": 0,
      "explanation": "個人データを第三者提供する場合は、原則として本人の同意が必要です。ただし、委託や法令に基づく場合などの例外があります。"
    },
    {
      "id": 100,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AI開発契約",
      "question": "経済産業省の「AI・データの利用に関する契約ガイドライン」において、AI開発契約はどのような形態が望ましいとされているか。",
      "options": [
        "探索的段階型",
        "一括請負型",
        "成果報酬型",
        "口頭契約"
      ],
      "answer": 0,
      "explanation": "AI開発は不確実性が高いため、アセスメント、PoC、開発、運用とフェーズを区切り、各段階で契約を見直すことが推奨されています。"
    },
    {
      "id": 101,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AI開発契約",
      "question": "成果物の完成義務を負わず、善管注意義務をもって業務を遂行する契約形態を何というか。",
      "options": [
        "準委任契約",
        "請負契約",
        "雇用契約",
        "売買契約"
      ],
      "answer": 0,
      "explanation": "PoC段階や探索的な開発では、完成（精度）を保証することが難しいため、準委任契約が一般的です。"
    },
    {
      "id": 102,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "パスワード制限などでアクセスが管理され、特定の会員などにのみ提供されているデータを保護する、不正競争防止法の枠組みはどれか。",
      "options": [
        "限定提供データ",
        "営業秘密",
        "特許",
        "商標"
      ],
      "answer": 0,
      "explanation": "秘密管理性が要件とならない点で営業秘密（秘密管理性が必須）と異なりますが、価値あるデータとして保護されます。"
    },
    {
      "id": 103,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "AI倫理",
      "question": "過去の採用データなどを学習したAIが、特定の性別や人種に不利な判断をしてしまう問題を何というか。",
      "options": [
        "アルゴリズムバイアス",
        "シンギュラリティ",
        "フレーム問題",
        "プライバシー侵害"
      ],
      "answer": 0,
      "explanation": "データに含まれる人間の偏見がAIに反映され、差別を助長するリスクがあり、公平性（Fairness）の担保が重要課題です。"
    },
    {
      "id": 104,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "セキュリティ",
      "question": "画像に目に見えない微小なノイズを加えることで、AIの誤認識を誘発する攻撃を何というか。",
      "options": [
        "敵対的サンプル",
        "SQLインジェクション",
        "DoS攻撃",
        "ソーシャルエンジニアリング"
      ],
      "answer": 0,
      "explanation": "パンダの画像にノイズを加えると、人間にはパンダに見えるが、AIは「テナガザル」と誤認するといった事例が有名です。"
    },
    {
      "id": 105,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "セキュリティ",
      "question": "AIモデルへの入出力（APIの応答など）を繰り返すことで、モデルそのものを盗み出す（コピーモデルを作成する）攻撃を何というか。",
      "options": [
        "モデル抽出攻撃",
        "モデル反転攻撃",
        "データ汚染攻撃",
        "メンバーシップ推論"
      ],
      "answer": 0,
      "explanation": "商用APIなどの挙動を模倣するモデルを泥棒する攻撃であり、知的財産権の侵害になります。"
    },
    {
      "id": 106,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "ディープフェイク",
      "question": "AI（GANなど）を用いて生成された、実在しない人物の動画や、有名人の顔を別人に合成した偽動画を何と呼ぶか。",
      "options": [
        "ディープフェイク",
        "バーチャルYouTuber",
        "デジタルツイン",
        "メタバース"
      ],
      "answer": 0,
      "explanation": "精巧な偽動画は、世論操作や詐欺などに悪用されるリスクがあり、真偽判定技術の開発や法規制が進められています。"
    },
    {
      "id": 107,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "AI倫理",
      "question": "AIなどの新技術が社会に与える影響を、倫理的、法的、社会的課題の観点から包括的に捉える概念を何というか。",
      "options": [
        "ELSI",
        "SDGs",
        "ESG",
        "CSR"
      ],
      "answer": 0,
      "explanation": "技術開発と並行して、ELSI(Engineering for Social and Ethical Issues)への配慮を行うことが、社会受容性を高めるために不可欠です。"
    },
    {
      "id": 108,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "ガイドライン",
      "question": "日本政府が策定した、AI開発者や利用者が守るべき原則（人間中心のAIなど）をまとめた指針はどれか。",
      "options": [
        "人間中心のAI社会原則",
        "ロボット工学三原則",
        "EU AI法",
        "GDPR"
      ],
      "answer": 0,
      "explanation": "「人間中心」を基本理念とし、教育・リテラシー、プライバシー、セキュリティ、公平性などの原則を掲げています。"
    },
    {
      "id": 109,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "プライバシー",
      "question": "個人のプライバシーを保護しつつ、データの統計的な分析結果などを利用可能にする技術（ノイズを加えるなど）はどれか。",
      "options": [
        "差分プライバシー",
        "暗号化",
        "ブロックチェーン",
        "ファイアウォール"
      ],
      "answer": 0,
      "explanation": "Differential Privacy（差分プライバシー）は、特定の個人のデータが含まれているかどうかを判別できないようにする数学的な枠組みです。"
    },
    {
      "id": 110,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "データの分布における「中心」を表す値のうち、データを大きさ順に並べたときに真ん中にくる値を何というか。",
      "options": [
        "中央値",
        "平均値",
        "最頻値",
        "期待値"
      ],
      "answer": 0,
      "explanation": "平均値は外れ値の影響を受けやすいですが、中央値は外れ値に対してロバスト（頑健）であるという特徴があります。"
    },
    {
      "id": 111,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "データのばらつき具合を表す指標で、分散の平方根をとったものは何か。",
      "options": [
        "標準偏差",
        "共分散",
        "相関係数",
        "不偏分散"
      ],
      "answer": 0,
      "explanation": "標準偏差は、元のデータと同じ単位でばらつきを評価できるため、実用上よく使われます。"
    },
    {
      "id": 112,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "相関",
      "question": "2つの変数の間に「一方が増えるともう一方も増える（または減る）」という直線的な関係の強さを表す、-1から1の値をとる指標はどれか。",
      "options": [
        "相関係数",
        "決定係数",
        "偏相関係数",
        "カイ二乗値"
      ],
      "answer": 0,
      "explanation": "1に近いと正の相関、-1に近いと負の相関、0に近いと相関がない（無相関）ことを示します。"
    },
    {
      "id": 113,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "相関と因果",
      "question": "2つの変数の間に因果関係がないにもかかわらず、隠れた第三の要因（交絡因子）などの影響で相関があるように見える現象を何というか。",
      "options": [
        "擬似相関",
        "多重共線性",
        "因果推論",
        "シンプソンのパラドックス"
      ],
      "answer": 0,
      "explanation": "「アイスクリームの売上」と「水難事故数」には相関がありますが、これは「気温」という共通の要因があるためであり、因果関係ではありません。"
    },
    {
      "id": 114,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "自然界や社会現象で最もよく見られる、平均値を中心に左右対称の釣鐘型を描く確率分布はどれか。",
      "options": [
        "正規分布",
        "一様分布",
        "ポアソン分布",
        "ベルヌーイ分布"
      ],
      "answer": 0,
      "explanation": "ガウス分布とも呼ばれ、多くの統計的手法の基礎となる重要な分布です。"
    },
    {
      "id": 115,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "2つのベクトル間の類似度を測る指標で、ベクトルのなす角度のコサイン（余弦）を用いたものを何というか。",
      "options": [
        "コサイン類似度",
        "ユークリッド距離",
        "マンハッタン距離",
        "マハラノビス距離"
      ],
      "answer": 0,
      "explanation": "文章の類似度判定などでよく使われます。ベクトルの大きさ（長さ）の影響を受けず、方向の類似性を評価できます。"
    },
    {
      "id": 116,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "ある事象が起こる確率が低いほど情報量は大きくなるという考えに基づき、不確実性の大きさを表す指標を何というか。",
      "options": [
        "エントロピー",
        "ジニ不純度",
        "尤度",
        "バイアス"
      ],
      "answer": 0,
      "explanation": "エントロピーが大きいほど、データは無秩序（予測困難）であることを意味します。"
    },
    {
      "id": 117,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "データをk個に分割し、そのうち1つをテストデータ、残りを学習データとしてk回検証を繰り返して平均をとる手法はどれか。",
      "options": [
        "k-分割交差検証",
        "ホールドアウト法",
        "ブートストラップ法",
        "ジャックナイフ法"
      ],
      "answer": 0,
      "explanation": "手持ちのデータを無駄なく使い、かつ信頼性の高い評価を得るための標準的な手法です。"
    },
    {
      "id": 118,
      "majorCategory": "機械学習の概要",
      "subCategory": "ハイパーパラメータ探索",
      "question": "ハイパーパラメータの組み合わせを格子状に網羅して探索し、最も性能が良いものを探す手法はどれか。",
      "options": [
        "グリッドサーチ",
        "ランダムサーチ",
        "ベイズ最適化",
        "勾配降下法"
      ],
      "answer": 0,
      "explanation": "確実ですが、パラメータ数が増えると計算量が爆発的に増えるため、ランダムサーチやベイズ最適化が使われることもあります。"
    },
    {
      "id": 119,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "活性化関数にReLUを使う場合、勾配消失や爆発を防ぐために推奨される重みの初期化手法はどれか。",
      "options": [
        "Heの初期化",
        "Xavierの初期化",
        "ガウス分布",
        "0で初期化"
      ],
      "answer": 0,
      "explanation": "Xavierの初期化はSigmoidやTanhに適しており、ReLUには分散を調整したHeの初期化が適しています。"
    },
    {
      "id": 120,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "RNNやTransformerなどで用いられる、データ（サンプル）ごとに全特徴量の平均と分散で正規化を行う手法はどれか。",
      "options": [
        "レイヤー正規化",
        "バッチ正規化",
        "インスタンス正規化",
        "グループ正規化"
      ],
      "answer": 0,
      "explanation": "バッチサイズに依存しないため、時系列データやバッチサイズを大きく取れない場合に有効です。"
    },
    {
      "id": 121,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習の課題",
      "question": "高次元空間において、ある方向では極小だが別の方向では極大になっている点（馬の鞍のような形状）を何というか。",
      "options": [
        "鞍点",
        "局所解",
        "大域解",
        "特異点"
      ],
      "answer": 0,
      "explanation": "勾配が0になるため、学習が停滞する原因の一つですが、SGDなどのノイズによって脱出しやすいとも言われています。"
    },
    {
      "id": 122,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習挙動",
      "question": "モデルを大きくしていくと、一度テスト誤差が上がり（過学習）、さらに大きくすると再び下がっていくという現象を何と呼ぶか。",
      "options": [
        "二重降下現象",
        "過学習",
        "次元の呪い",
        "バイアス・バリアンス・トレードオフ"
      ],
      "answer": 0,
      "explanation": "従来の統計的学習理論に反する現象として、近年のディープラーニング研究で注目されています。"
    },
    {
      "id": 123,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "生成AI",
      "question": "GANの学習において、生成器が特定の種類の画像しか生成しなくなってしまう（多様性が失われる）失敗現象を何というか。",
      "options": [
        "モード崩壊",
        "勾配消失",
        "過学習",
        "収束不全"
      ],
      "answer": 0,
      "explanation": "生成器が「識別器を騙しやすい特定のパターン」だけを学習してしまうことで発生します。"
    },
    {
      "id": 124,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "BERTやGPTなどで使われる、単語（Word）よりも細かい単位（Subword）でテキストを分割する手法はどれか。",
      "options": [
        "サブワードトークン化",
        "形態素解析",
        "N-gram",
        "One-hot化"
      ],
      "answer": 0,
      "explanation": "「unhappiness」を「un」「happi」「ness」に分けるなどして、未知語への対応力を高めています。"
    },
    {
      "id": 125,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "LLM",
      "question": "言語モデルの性能は、パラメータ数、データ量、計算量（計算リソース）の3要素に対してべき乗則に従って向上するという経験則を何というか。",
      "options": [
        "スケーリング則",
        "ムーアの法則",
        "アムダールの法則",
        "パレートの法則"
      ],
      "answer": 0,
      "explanation": "これにより、モデルの巨大化競争が加速しました。"
    },
    {
      "id": 126,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "LLM",
      "question": "LLMが学習データに含まれていない最新情報や具体的な固有名詞について答える際、外部のデータベースを検索し、その情報をプロンプトに含めて回答生成させる手法はどれか。",
      "options": [
        "RAG",
        "ファインチューニング",
        "プロンプトエンジニアリング",
        "強化学習"
      ],
      "answer": 0,
      "explanation": "RAGにより、ハルシネーション（嘘の生成）を抑制し、根拠のある回答を生成させることができます。"
    },
    {
      "id": 127,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "LLM",
      "question": "LLMに対して、「思考の過程をステップ・バイ・ステップで記述して」と指示することで、論理的な推論能力を向上させるプロンプト手法はどれか。",
      "options": [
        "Chain of Thought",
        "Few-shot Learning",
        "Zero-shot Learning",
        "Role Prompting"
      ],
      "answer": 0,
      "explanation": "いきなり答えを出させるのではなく、中間的な推論過程を出力させることで、複雑な問題の正答率が上がります。"
    },
    {
      "id": 128,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "LLM",
      "question": "LLMを特定のタスクに適応させる際、全パラメータを再学習するのではなく、一部のパラメータのみを追加・学習する効率的な手法（LoRAなど）を総称して何というか。",
      "options": [
        "PEFT",
        "フルファインチューニング",
        "事前学習",
        "蒸留"
      ],
      "answer": 0,
      "explanation": "計算コストとメモリ消費を大幅に抑えながら、タスク特化型の性能を引き出すことができます。"
    },
    {
      "id": 129,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "LLM",
      "question": "生成AIが、事実に基づかないもっともらしい嘘（虚偽の内容）を生成してしまう現象を何というか。",
      "options": [
        "ハルシネーション",
        "バイアス",
        "オーバーフィッティング",
        "破壊的忘却"
      ],
      "answer": 0,
      "explanation": "確率的に単語を繋げているために起こる現象で、事実確認（ファクトチェック）が重要です。"
    },
    {
      "id": 130,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "AIの応用分野",
      "question": "自然言語処理で成功したTransformerの構造を、画像をパッチ（小領域）に分割して入力することで画像認識に応用したモデルはどれか。",
      "options": [
        "Vision Transformer",
        "ResNet",
        "EfficientNet",
        "CNN"
      ],
      "answer": 0,
      "explanation": "大量のデータで事前学習すれば、CNNを超える性能を発揮することが示され、画像分野でもTransformerが普及しました。"
    },
    {
      "id": 131,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "3D",
      "question": "複数の視点からの画像を用いて、ニューラルネットワークに3次元空間の密度と色を学習させ、自由な視点からの画像を生成できる技術はどれか。",
      "options": [
        "NeRF",
        "LiDAR",
        "Photogrammetry",
        "SLAM"
      ],
      "answer": 0,
      "explanation": "NeRF(Neural Radiance Fields)は、3Dモデルをメッシュとしてではなく、ニューラルネットワークの重みとして表現する革新的な手法です。"
    },
    {
      "id": 132,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "エキスパート（人間など）の行動データを観察し、その背後にある報酬関数を推定する手法はどれか。",
      "options": [
        "逆強化学習",
        "模倣学習",
        "教師あり学習",
        "転移学習"
      ],
      "answer": 0,
      "explanation": "「どう行動すべきか」ではなく「何を目的としているか（報酬）」を学習することで、より柔軟な模倣が可能になります。"
    },
    {
      "id": 133,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "EUの一般データ保護規則（GDPR）において、個人が自分に関するデータの削除を求めることができる権利を何というか。",
      "options": [
        "忘れられる権利",
        "データポータビリティの権利",
        "説明を受ける権利",
        "プロファイリング拒否権"
      ],
      "answer": 0,
      "explanation": "AIが学習したデータに個人情報が含まれていた場合、学習済みモデルからの削除（忘却）は技術的に困難な場合があり、議論されています。"
    },
    {
      "id": 134,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "営業秘密として保護されるための3つの要件（秘密管理性、有用性）のあとひとつは何か。",
      "options": [
        "非公知性",
        "新規性",
        "進歩性",
        "独創性"
      ],
      "answer": 0,
      "explanation": "「公然と知られていないこと（非公知性）」が必要です。特許のような新規性は求められません。"
    },
    {
      "id": 135,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "現在の日本の特許法において、AI自身を発明者として特許出願することは認められているか。",
      "options": [
        "認められていない",
        "認められている",
        "AIの開発者が同意すれば認められる",
        "特許庁長官の許可があれば認められる"
      ],
      "answer": 0,
      "explanation": "主要国（日本、米国、欧州など）では現状、発明者は人間（自然人）に限るという解釈が一般的です（DABUS判決など）。"
    },
    {
      "id": 136,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "フィルターバブル",
      "question": "検索エンジンやSNSのレコメンド機能により、自分の好みに合う情報ばかりが表示され、それ以外の情報から隔離されてしまう現象を何というか。",
      "options": [
        "フィルターバブル",
        "エコーチェンバー",
        "確証バイアス",
        "集団浅慮"
      ],
      "answer": 0,
      "explanation": "知らず知らずのうちに情報が偏り、視野が狭くなるリスクがあります。"
    },
    {
      "id": 137,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "エコーチェンバー",
      "question": "SNSなどで自分と似た意見の人々とばかり交流することで、自分の意見が増幅・強化され、過激化・先鋭化してしまう現象を何というか。",
      "options": [
        "エコーチェンバー現象",
        "フィルターバブル",
        "バンドワゴン効果",
        "沈黙の螺旋"
      ],
      "answer": 0,
      "explanation": "閉じたコミュニティ内で同じ意見が反響（エコー）し続けることに由来します。"
    },
    {
      "id": 138,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "ロボティクス",
      "question": "ロボットが移動しながら、自己位置の推定と環境地図の作成を同時に行う技術を何というか。",
      "options": [
        "SLAM",
        "GPS",
        "PID制御",
        "インバース・キネマティクス"
      ],
      "answer": 0,
      "explanation": "SLAM(Simultaneous Localization and Mapping)は自動運転車や掃除ロボットなどが未知の環境で活動するための基本技術です。"
    },
    {
      "id": 139,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ハードウェア",
      "question": "Googleが開発した、ディープラーニング（特にTensorFlow）の計算に特化した専用プロセッサ（ASIC）はどれか。",
      "options": [
        "TPU",
        "GPU",
        "CPU",
        "FPGA"
      ],
      "answer": 0,
      "explanation": "TPU(Tensor Processing Unit)は行列演算に特化し、電力効率と処理速度を高めたAI専用チップです。"
    },
    {
      "id": 140,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "歴史",
      "question": "1956年に開催され、「人工知能（Artificial Intelligence）」という言葉が初めて使われた会議はどれか。",
      "options": [
        "ダートマス会議",
        "ダボス会議",
        "国際人工知能会議",
        "認知科学会"
      ],
      "answer": 0,
      "explanation": "ジョン・マッカーシーらが主催し、ミンスキー、シャノンらが参加しました。"
    },
    {
      "id": 141,
      "majorCategory": "人工知能とは",
      "subCategory": "AIアライメント",
      "question": "AIの目標や振る舞いを、人間の価値観や意図と合致させること（暴走を防ぐこと）を目指す研究分野を何というか。",
      "options": [
        "AIアライメント",
        "シンギュラリティ",
        "フレーム問題",
        "チューリングテスト"
      ],
      "answer": 0,
      "explanation": "例えば「ペーパークリップ生産を最大化せよ」という命令に対し、地球資源を全て使い尽くすようなAIを作らないための研究です。"
    },
    {
      "id": 142,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "ノーフリーランチ定理",
      "question": "「あらゆる問題に対して万能な、常に他より優れたアルゴリズムは存在しない」という定理を何というか。",
      "options": [
        "ノーフリーランチ定理",
        "中心極限定理",
        "大数の法則",
        "ゲーデルの不完全性定理"
      ],
      "answer": 0,
      "explanation": "特定の問題に特化したアルゴリズムを選択・設計することの重要性を示唆しています。"
    },
    {
      "id": 143,
      "majorCategory": "機械学習の概要",
      "subCategory": "ライブラリ",
      "question": "Pythonで利用できる、NumPyと密接に連携し、多くの機械学習アルゴリズム（SVM、ランダムフォレストなど）を手軽に扱えるライブラリはどれか。",
      "options": [
        "scikit-learn",
        "TensorFlow",
        "PyTorch",
        "Keras"
      ],
      "answer": 0,
      "explanation": "初学者が機械学習を学ぶ際に最適で、実務でも幅広く使われている標準的なライブラリです。"
    },
    {
      "id": 144,
      "majorCategory": "機械学習の概要",
      "subCategory": "ライブラリ",
      "question": "表形式のデータを扱うのに適したPythonライブラリで、データの読み込み、加工、集計などが容易に行えるものはどれか。",
      "options": [
        "pandas",
        "numpy",
        "matplotlib",
        "scipy"
      ],
      "answer": 0,
      "explanation": "DataFrameという形式でデータを扱い、Excelのような操作をプログラムで行えます。"
    },
    {
      "id": 145,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "2つの確率分布の間の「距離」のようなものを測る指標で、真の分布 $P$ と近似分布 $Q$ の違いを表すもの（常に非負）はどれか。",
      "options": [
        "カルバック・ライブラー情報量",
        "相互情報量",
        "エントロピー",
        "ジニ不純度"
      ],
      "answer": 0,
      "explanation": "VAEの損失関数などで、分布を近づけるために最小化すべき項として登場します。"
    },
    {
      "id": 146,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "局所最適解",
      "question": "勾配降下法において、真の最小値（大域的最適解）ではないが、周囲よりも値が小さいため抜け出せなくなってしまう点を何というか。",
      "options": [
        "局所最適解",
        "鞍点",
        "大域最適解",
        "特異点"
      ],
      "answer": 0,
      "explanation": "SGDなどの確率的な挙動や、高次元空間においては鞍点の方が多いという特性により、実際には大域解に近い良い解に到達できることが多いです。"
    },
    {
      "id": 147,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "コンテナ技術",
      "question": "アプリケーションの実行環境（OS、ライブラリ、コード）を「コンテナ」としてパッケージ化し、どこでも同じように動作させる技術（AI開発でも環境再現に使われる）はどれか。",
      "options": [
        "Docker",
        "Kubernetes",
        "VirtualBox",
        "VMware"
      ],
      "answer": 0,
      "explanation": "「自分のPCでは動いたのにサーバーでは動かない」という問題を解決し、開発・運用の効率を高めます。"
    },
    {
      "id": 148,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "エッジAI",
      "question": "クラウドにデータを送らず、スマートフォンやIoTデバイスなどの端末側でAIの推論処理を行う仕組みを何というか。",
      "options": [
        "エッジAI",
        "クラウドコンピューティング",
        "フォグコンピューティング",
        "分散処理"
      ],
      "answer": 0,
      "explanation": "通信遅延がない、通信コスト削減、プライバシー保護などのメリットがあります。"
    },
    {
      "id": 149,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "損失関数にL2ノルム（重みの二乗和）を加えることで、重みが大きくなりすぎるのを防ぐ正則化手法はどれか。",
      "options": [
        "リッジ回帰",
        "ラッソ回帰",
        "ドロップアウト",
        "バッチ正規化"
      ],
      "answer": 0,
      "explanation": "Weight Decay（重み減衰）とも呼ばれ、過学習抑制の最も基本的な手法の一つです。"
    },
    {
      "id": 150,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "AI倫理",
      "question": "公平性の定義の一つで、「予測結果がセンシティブ属性（性別など）に依存しないこと（独立であること）」を要求する概念はどれか。",
      "options": [
        "統計的パリティ",
        "機会の均等",
        "校正された確率",
        "説明責任"
      ],
      "answer": 0,
      "explanation": "例えば、男性の採用率と女性の採用率を同じにする、といった考え方です。"
    },
    {
      "id": 151,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "歴史",
      "question": "1997年、IBMの「DeepBlue」がチェスの世界チャンピオン、ガルリ・カスパロフに勝利した際に用いられた主な手法はどれか。",
      "options": [
        "ブルートフォースと評価関数",
        "ディープラーニング",
        "モンテカルロ木探索",
        "強化学習"
      ],
      "answer": 0,
      "explanation": "当時はまだディープラーニングではなく、圧倒的な計算力による先読みが勝因でした。"
    },
    {
      "id": 152,
      "majorCategory": "機械学習の概要",
      "subCategory": "機械学習の手法",
      "question": "複数の学習済みモデルを保存し、未知のデータに対する予測結果を多数決や平均で統合する手法はどれか。",
      "options": [
        "アンサンブル学習",
        "転移学習",
        "蒸留",
        "メタ学習"
      ],
      "answer": 0,
      "explanation": "「三人寄れば文殊の知恵」のように、単体モデルよりも精度や安定性が向上します。"
    },
    {
      "id": 153,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "確率変数 $X$ のとりうる値 $x$ とその確率 $P(x)$ の積の総和（平均的に期待できる値）を何というか。",
      "options": [
        "期待値",
        "分散",
        "尤度",
        "中央値"
      ],
      "answer": 0,
      "explanation": "ギャンブルでいうと、1回あたり平均してどれくらい勝てるか（または負けるか）を表す値です。"
    },
    {
      "id": 154,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "結果（データ）から原因（パラメータ）を推定する際に使われる、条件付き確率の公式「$P(A|B) = P(B|A)P(A) / P(B)$」を何というか。",
      "options": [
        "ベイズの定理",
        "大数の法則",
        "中心極限定理",
        "チェビシェフの不等式"
      ],
      "answer": 0,
      "explanation": "ベイズ統計学の基礎であり、迷惑メールフィルタ（ナイーブベイズ）などに応用されています。"
    },
    {
      "id": 155,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデルの解釈性",
      "question": "モデルの予測に対する各特徴量の影響度を測る指標で、ある特徴量の値をシャッフル（並べ替え）したときの精度の低下度合いを見る手法はどれか。",
      "options": [
        "Permutation Importance",
        "SHAP",
        "LIME",
        "Partial Dependence Plot"
      ],
      "answer": 0,
      "explanation": "重要な特徴量であれば、それをデタラメに混ぜると精度が大きく下がるはずだ、という直感的な手法です。"
    },
    {
      "id": 156,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "ガバナンス",
      "question": "AIシステムが予期せぬ挙動をした場合に備え、人間が監視・介入できる仕組みを残しておく考え方を何というか。",
      "options": [
        "Human-in-the-loop",
        "完全自動化",
        "ブラックボックス化",
        "シンギュラリティ"
      ],
      "answer": 0,
      "explanation": "AIに丸投げするのではなく、最終判断や重要局面には人間が介在することで安全性を担保します。"
    },
    {
      "id": 157,
      "majorCategory": "AI倫理・AIガバナンス",
      "subCategory": "環境",
      "question": "AIモデルの巨大化に伴う消費電力の増大を抑制し、環境負荷を低減しようとする取り組みを何というか。",
      "options": [
        "Green AI",
        "Red AI",
        "Sustainable AI",
        "Eco AI"
      ],
      "answer": 0,
      "explanation": "精度追求のために計算資源を大量消費する「Red AI」に対し、効率性を重視する考え方です。"
    },
    {
      "id": 158,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の課題",
      "question": "「高度な推論（チェスなど）は計算機には簡単だが、1歳児でもできる知覚や運動（積木や歩行）は非常に難しい」という逆説を何というか。",
      "options": [
        "モラベックのパラドックス",
        "フレーム問題",
        "シンボルグラウンディング問題",
        "不気味の谷現象"
      ],
      "answer": 0,
      "explanation": "人間の知能の進化の歴史において、本能的な運動能力の方が、論理的思考よりもはるかに長い最適化の期間を経ているためと説明されます。"
    },
    {
      "id": 159,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "AIの汎用性",
      "question": "特定のタスクだけでなく、人間のようにあらゆる課題をこなし、自ら学習して成長できるAIの概念を何というか。",
      "options": [
        "AGI",
        "ANI",
        "Explainable AI",
        "Strong AI"
      ],
      "answer": 0,
      "explanation": "現在のAIのほとんどは特化型（ANI）ですが、AGIの実現が最終的な目標とされています。"
    },
    {
      "id": 160,
      "majorCategory": "人工知能とは",
      "subCategory": "未来",
      "question": "AIのリスク管理や倫理において、AIが人類の存亡に関わるような破滅的な事態を引き起こすリスクのことを何と呼ぶか。",
      "options": [
        "実存的リスク",
        "バイアスリスク",
        "プライバシーリスク",
        "セキュリティリスク"
      ],
      "answer": 0,
      "explanation": "超知能の暴走や悪用によって、人類が滅亡したり回復不能なダメージを負ったりするリスクのことです。"
    }
  ]
}