{
  "metadata": {
    "title": "G検定 模擬試験 4",
    "description": "シラバス2024対応・実践編 (網羅的演習)",
    "timeLimit": 100,
    "passLine": 70,
    "totalQuestions": 160
  },
  "questions": [
    {
      "id": 1,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の定義",
      "question": "人工知能の定義において、ニールスニルソン（Nils Nilsson）が提唱した考え方はどれか。",
      "options": [
        "知能的な行動が、人工的な実体によって示されること。またはその研究分野",
        "人間の知能そのものを機械で再現することのみを指す",
        "大量のデータを処理する統計的なアルゴリズムの総称",
        "人間が記述したルールに基づいて論理的な推論を行うシステム"
      ],
      "answer": 0,
      "explanation": "ニールスニルソンは、「人工知能とは、人工的な実体（artificial entities）に知能的な行動（intelligent behavior）をさせること、およびその研究分野である」と定義しました。"
    },
    {
      "id": 2,
      "majorCategory": "人工知能とは",
      "subCategory": "人工知能の定義",
      "question": "ハンスモラベックが提唱した「モラベックのパラドックス」の内容として、最も適切なものはどれか。",
      "options": [
        "高度な推論は低コストで実現できるが、低度な感覚運動は非常に高い計算資源を必要とする",
        "AIが進化するほど、人間は自分が何を知らないかを自覚しなくなる現象",
        "コンピュータの性能が向上しても、それを利用するソフトウェアの複雑さが上回る現象",
        "記号が現実世界の実体と結びつかない問題"
      ],
      "answer": 0,
      "explanation": "モラベックのパラドックスは、「人間にとって高度で知的な推論（将棋、数学など）を機械に代行させるのは比較的簡単だが、幼児ができるような歩行や視覚認識などの感覚運動スキルを機械に持たせるのは極めて困難である」という矛盾を指します。"
    },
    {
      "id": 3,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理統計",
      "question": "単位時間あたりに平均 $\\lambda$ 回発生する稀な事象が、特定期間中に $x$ 回発生する確率を表す分布はどれか。",
      "options": [
        "ポアソン分布",
        "ベルヌーイ分布",
        "正規分布",
        "二項分布"
      ],
      "answer": 0,
      "explanation": "ポアソン分布は、滅多に起こらない事象の発生回数をモデル化するのに適しており、コールセンターへの着信数、事故の発生数、Webサイトへのアクセス数などの予測に利用されます。"
    },
    {
      "id": 4,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理統計",
      "question": "統計的仮説検定において、「本来は差がある（帰無仮説が偽である）のに、誤って帰無仮説を棄却しない」誤りを何と呼ぶか。",
      "options": [
        "第2種過誤",
        "第1種過誤",
        "偽陽性",
        "p値の誤認"
      ],
      "answer": 0,
      "explanation": "第2種過誤（β過誤）は、実際には効果や差があるにもかかわらず、それが検知できずに見逃してしまう（帰無仮説を棄却できない）誤り（偽陰性）を指します。"
    },
    {
      "id": 5,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理統計",
      "question": "多変量データにおいて、変数間の相関を考慮し、データの分布（楕円状の広がり）に基づいて計算される距離はどれか。",
      "options": [
        "マハラノビス距離",
        "ユークリッド距離",
        "マンハッタン距離",
        "コサイン類似度"
      ],
      "answer": 0,
      "explanation": "マハラノビス距離は、各変数の分散や変数間の相関（共分散行列）を考慮した距離尺度です。単位（スケール）の影響を受けにくく、異常検知などで正常データ群からの距離を測る際などに非常に有効です。"
    },
    {
      "id": 6,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理統計",
      "question": "統計的仮説検定において、帰無仮説が正しいのにもかかわらず誤って棄却してしまう（偽陽性を出す）確率を何と呼ぶか。",
      "options": [
        "有意水準",
        "検出力",
        "p値",
        "信頼区間"
      ],
      "answer": 0,
      "explanation": "有意水準（α）は、あらかじめ設定した「第1種過誤（誤って帰無仮説を棄却してしまうこと）」を許容する限界の確率です。一般的に5%や1%が用いられます。"
    },
    {
      "id": 7,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "人工知能分野で議論される問題",
      "question": "1970年代にスタンフォード大学で開発され、感染症の診断と抗菌剤の処方を目的とした、確信度（Certainty Factor）という概念を導入したエキスパートシステムはどれか。",
      "options": [
        "MYCIN",
        "DENDRAL",
        "ELIZA",
        "SHRDLU"
      ],
      "answer": 0,
      "explanation": "MYCINは初期の有名なエキスパートシステムで、専門医の知識をルール化し、不確実な情報を扱うために「確信度（CF値）」という独自の推論メカニズムを導入しました。"
    },
    {
      "id": 8,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "人工知能分野で議論される問題",
      "question": "初期のAI研究において、コンピュータ内部の論理的な記号処理を「物理記号システム」と呼び、それが知能の必要十分条件であると主張した「物理記号システム仮説」を提唱したのは誰か。",
      "options": [
        "アレンニューウェルとハーバートサイモン",
        "ジョンマッカーシーとマービンミンスキー",
        "アランチューリング",
        "ジェフリーヒントン"
      ],
      "answer": 0,
      "explanation": "アレンニューウェルとハーバートサイモンは、「物理記号システム（Physical Symbol System）」が、一般的知的な行動を実現するための必要かつ十分な手段であるという仮説を提唱し、第1次AIブームの中心となりました。"
    },
    {
      "id": 9,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ディープラーニングのテクニック",
      "question": "ニューラルネットワークの学習において、特定のニューロン間の結合重みが極端に大きくなるのを防ぐため、損失関数に重みの二乗和（L2ノルム）などのペナルティ項を加える手法を何というか。",
      "options": [
        "荷重減衰",
        "ドロップアウト",
        "バッチ正規化",
        "早期終了"
      ],
      "answer": 0,
      "explanation": "荷重減衰（Weight Decay）は、過学習を抑制するための正則化手法の一つで、一般的にL2正則化として知られます。重みを小さく保つことで、モデルの複雑さを制限し汎化性能を高めます。"
    },
    {
      "id": 10,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ディープラーニングのテクニック",
      "question": "ニューラルネットワークにおいて、入力画像の一部のピクセル値がわずかに変化しても、出力される特徴マップが変わらないようにする、位置不変性を獲得するための処理はどれか。",
      "options": [
        "プーリング",
        "畳み込み",
        "ゼロパディング",
        "全結合"
      ],
      "answer": 0,
      "explanation": "プーリング（特に最大プーリング）は、局所的な範囲内での最大値を取り出すことで、対象物体のわずかな位置ずれが特徴抽出の結果に影響しないようにする「位置不変性」を獲得するために行われます。"
    },
    {
      "id": 11,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理統計",
      "question": "探索アルゴリズムにおいて、出発点からのコストとゴールまでの推定コスト（ヒューリスティック関数）の和を最小化するように探索を進める手法はどれか。",
      "options": [
        "A*アルゴリズム",
        "山登り法",
        "双方向探索",
        "ダイクストラ法"
      ],
      "answer": 0,
      "explanation": "A*アルゴリズムは、ダイクストラ法を拡張した手法で、現在地までのコスト$g(n)$ とゴールまでの予測コスト $h(n)$ を組み合わせた $f(n) = g(n) + h(n)$ を評価値として、効率的に最短経路を探索します。"
    },
    {
      "id": 12,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "人工知能分野で議論される問題",
      "question": "1980年代に第5世代コンピュータプロジェクトが推進されていた日本において開発され、NHKのクイズ番組でも活用された「ロボットは東大に入れるか」プロジェクトに関連するAIを何と呼ぶか。",
      "options": [
        "東ロボくん",
        "ワトソン",
        "ディープブルー",
        "SHRDLU"
      ],
      "answer": 0,
      "explanation": "「ロボットは東大に入れるか（東ロボくん）」プロジェクトは、国立情報学研究所（NII）を中心に進められた日本の著名なAIプロジェクトで、入試問題という高度な知識処理の壁に挑戦しました。"
    },
    {
      "id": 13,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理統計",
      "question": "行列の演算において、元の行列の行と列を入れ替えたものを何と呼ぶか。",
      "options": [
        "転置行列",
        "逆行列",
        "対角行列",
        "単位行列"
      ],
      "answer": 0,
      "explanation": "転置行列は、元の行列の第 $i$ 行を第 $j$ 列に入れ替えた行列です。ディープラーニングの重み行列の計算や、誤差逆伝播法の数式などで頻出します。"
    },
    {
      "id": 14,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理統計",
      "question": "ある事象が起こる確率を $p$ としたとき、$p/(1-p)$ で表される値を何と呼ぶか。",
      "options": [
        "オッズ",
        "尤度",
        "回帰係数",
        "分散"
      ],
      "answer": 0,
      "explanation": "オッズ（Odds）は、事象が起こる確率と起こらない確率の比です。ロジスティック回帰分析において、対数オッズを線形モデルで予測する際に重要な役割を果たします。"
    },
    {
      "id": 15,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "人工知能分野で議論される問題",
      "question": "1960年代にマサチューセッツ工科大学でテリーウィノグラードが開発した、積み木の世界（ブロックワールド）をシミュレーションし、自然言語での指示を理解して行動したシステムはどれか。",
      "options": [
        "SHRDLU",
        "ELIZA",
        "MYCIN",
        "LISP"
      ],
      "answer": 0,
      "explanation": "SHRDLUは、限定された世界（積み木の世界）の中であれば、命令を解釈し、論理的に推論して、矛盾なく行動できることを示した画期的な自然言語理解システムです。"
    },
    {
      "id": 16,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "ディープラーニングのテクニック",
      "question": "ニューラルネットワークにおいて、学習が進むにつれて活性化関数の出力が0または1に飽和し、微分値（勾配）がほぼ0になって重みの更新が止まってしまう現象を何というか。",
      "options": [
        "勾配消失",
        "勾配爆発",
        "過学習",
        "局所解"
      ],
      "answer": 0,
      "explanation": "勾配消失問題は、多層ネットワークにおいて、活性化関数の微分が繰り返し掛け合わされることで、誤差の情報が入力層に向かうにつれて小さくなって消えてしまう現象です。ReLUの採用などで緩和されます。"
    },
    {
      "id": 17,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "ディープラーニングのテクニック",
      "question": "2014年に提唱された、2つのネットワーク（生成器と識別器）を「ナッシュ均衡」を目指して競わせることで、本物に近いデータを生成するモデルを何というか。",
      "options": [
        "GAN",
        "VAE",
        "拡散モデル",
        "RNN"
      ],
      "answer": 0,
      "explanation": "GAN（敵対的生成ネットワーク）は、偽物を作る生成器とそれを見破る識別器を競い合わせる（min-maxゲーム）ことで、極めて写実的な画像を生成することを可能にしました。"
    },
    {
      "id": 18,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "ディープラーニングのテクニック",
      "question": "Googleが開発したBERTにおいて採用されている事前学習タスクのうち、入力文の一部をマスクし、周囲の単語からその単語を予測させる手法を何というか。",
      "options": [
        "Masked Language Model",
        "Next Sentence Prediction",
        "Self-Attention",
        "Fine-tuning"
      ],
      "answer": 0,
      "explanation": "BERTは、Masked Language Model（MLM）というタスクを用いることで、単語の左右両方向のコンテキストを同時に考慮した、文脈に応じた強力な単語の分散表現を獲得しました。"
    },
    {
      "id": 19,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "ディープラーニングのテクニック",
      "question": "ニューラルネットワークの隠れ層の出力を、ミニバッチごとに平均0、分散1に揃えることで、共変量シフトを抑制し学習を高速化安定化させる手法はどれか。",
      "options": [
        "バッチ正規化",
        "レイヤー正規化",
        "重み減衰",
        "ドロップアウト"
      ],
      "answer": 0,
      "explanation": "バッチ正規化は、層ごとの入力分布の変化（内部共変量シフト）を抑えることで、大きな学習率の適用を可能にし、初期値に対する感度を下げるなど、極めて高い学習安定化効果を持ちます。"
    },
    {
      "id": 20,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "ディープラーニングのテクニック",
      "question": "データマイニングやAIプロジェクトの標準的なプロセスモデルであるCRISP-DMにおいて、最初のフェーズとして定義されているものはどれか。",
      "options": [
        "ビジネス理解",
        "データ理解",
        "モデリング",
        "データ準備"
      ],
      "answer": 0,
      "explanation": "CRISP-DM（Cross-Industry Standard Process for Data Mining）の第1段階は「ビジネス理解（Business Understanding）」であり、プロジェクトの目的、現状、目標、成功基準を明確にすることから始まります。"
    },
    {
      "id": 21,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "ディープラーニングのテクニック",
      "question": "教師あり学習の分類タスクにおいて、モデルが「正」と予測したデータのうち、実際に「正」であった割合を示す「適合率（Precision）」とトレードオフの関係にある指標はどれか。",
      "options": [
        "再現率",
        "正解率",
        "F値",
        "特異度"
      ],
      "answer": 0,
      "explanation": "適合率と再現率は、一般にトレードオフの関係にあります。適合率を高めようと（慎重に予測しようと）すると、本来拾えるはずの正解を見逃して再現率が下がる傾向があります。"
    },
    {
      "id": 22,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "機械学習モデルの汎化性能を評価する際、データを $k$ 個に分割し、そのうちの1つをテストデータ、残りの $k-1$ 個を学習データとして $k$ 回繰り返し評価を行う手法はどれか。",
      "options": [
        "k分割交差検証",
        "ホールドアウト法",
        "ブートストラップ法",
        "ランダムサンプリング"
      ],
      "answer": 0,
      "explanation": "k分割交差検証は、データを重複なく使い切ることで、データの分割の仕方に依存する評価の偏りを抑え、より安定した性能の見積もりを可能にします。"
    },
    {
      "id": 23,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "アンサンブル学習において、ブートストラップサンプリングによって作成した複数の決定木を独立に学習させ、それらの多数決や平均をとる手法は何か。",
      "options": [
        "ランダムフォレスト",
        "勾配ブースティング",
        "スタッキング",
        "アダブースト"
      ],
      "answer": 0,
      "explanation": "ランダムフォレストは、バギング（Bagging）の一種であり、データの重複を許した抽出（ブートストラップ）と、使用する特徴量のランダム選択を組み合わせることで、過学習に強い高精度な予測を実現します。"
    },
    {
      "id": 24,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "サポートベクターマシン（SVM）において、低次元では線形分離不可能なデータを高次元空間へ写像し、線形分離可能にするために導入される関数は何か。",
      "options": [
        "カーネル関数",
        "シグモイド関数",
        "ReLU関数",
        "損失関数"
      ],
      "answer": 0,
      "explanation": "カーネル法を用いることで、SVMは高次元空間での計算を明示的に行うことなく（「カーネルトリック」）、非線形な識別境界を効率的に学習することができます。"
    },
    {
      "id": 25,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習手法",
      "question": "教師なし学習において、データセット内の変数の相関関係をまとめ、情報の損失を最小限に抑えつつデータを低次元（主成分）に圧縮する手法はどれか。",
      "options": [
        "主成分分析",
        "k-means法",
        "階層的クラスタリング",
        "連関規則分析"
      ],
      "answer": 0,
      "explanation": "主成分分析 (Principal Component Analysis) は、データの分散が最大になる方向（主成分）を順に求めていく多変量解析手法で、可視化や前処理に多用されます。"
    },
    {
      "id": 26,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "ディープラーニングのテクニック",
      "question": "強化学習において、エージェントが現在置かれている状況を何と呼ぶか。",
      "options": [
        "状態",
        "報酬",
        "方策",
        "行動"
      ],
      "answer": 0,
      "explanation": "エージェントが直面している状況（盤面や環境のパラメータ等）を「状態（State）」と呼びます。強化学習は、ある状態における最適な行動を決定する方策を学習します。"
    },
    {
      "id": 27,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "ディープラーニングのテクニック",
      "question": "強化学習のエージェントが、過去の経験から得られた最も良いとされる行動を選ぶことを「利用（Exploitation）」と呼ぶのに対し、未知の行動を試してより良い情報を得ようとすることを何と呼ぶか。",
      "options": [
        "探索",
        "推論",
        "再学習",
        "汎化"
      ],
      "answer": 0,
      "explanation": "強化学習には「探索と利用のトレードオフ」があり、現在の知識を利用して高い報酬を得ることと、新しい行動を探索してさらに良い方策を見つけることのバランスが重要です。"
    },
    {
      "id": 28,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "ニューラルネットワークが過学習を起こし、未知のデータに対して精度が出なくなるのを防ぐために、ネットワークの一部を学習時にランダムに無効化する手法はどれか。",
      "options": [
        "ドロップアウト",
        "正規化",
        "早期終了",
        "プルーニング"
      ],
      "answer": 0,
      "explanation": "ドロップアウトは、学習のたびにランダムに一部のニューロンを除去して学習させることで、複数のネットワークをアンサンブル学習させるのと同様の効果を得て、過学習を強力に抑制します。"
    },
    {
      "id": 29,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIの応用分野",
      "question": "AIプロジェクトにおいて、本格的な開発に入る前に、技術的な実現可能性やビジネス価値を小規模で検証するプロセスを何と呼ぶか。",
      "options": [
        "PoC",
        "MVP",
        "R&D",
        "デプロイメント"
      ],
      "answer": 0,
      "explanation": "PoC（概念実証）は、不確実性の高いAIプロジェクトにおいて、データで実際に精度が出るか、課題解決に繋がるかを先行して確認する非常に重要なフェーズです。"
    },
    {
      "id": 30,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIの応用分野",
      "question": "学習時に使用したデータの傾向（分布）が、本番環境での運用中に変化してしまい、モデルの精度が低下する現象を何というか。",
      "options": [
        "データドリフト",
        "過学習",
        "勾配消失",
        "リーケージ"
      ],
      "answer": 0,
      "explanation": "データドリフトは、市場の変化やセンサーの故障などにより、モデルが学習した前提条件（データの分布）が変わってしまう問題です。継続的な監視と再学習が必要になります。"
    },
    {
      "id": 31,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "非常に大きなパラメータを持つ「教師モデル」の知識を、よりコンパクトな「生徒モデル」に継承させ、精度を維持しつつ軽量化を図る手法はどれか。",
      "options": [
        "蒸留",
        "プルーニング",
        "量子化",
        "ファインチューニング"
      ],
      "answer": 0,
      "explanation": "蒸留は、巨大なモデルの出力（ソフトターゲット）を小規模なモデルが模倣するように学習させることで、実用的な速度と精度を両立させる軽量化技術です。"
    },
    {
      "id": 32,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデル評価",
      "question": "ネットワークの不要な結合（重み）を削減し、モデルをスパースにすることで計算量とメモリ使用量を減らす手法であり、初期値の良いサブネットが存在するという「宝くじ仮説」に関連するものはどれか。",
      "options": [
        "プルーニング",
        "量子化",
        "蒸留",
        "データ拡張"
      ],
      "answer": 0,
      "explanation": "プルーニングは、精度に寄与しない重みを0にすることでモデルを軽量化します。宝くじ仮説（Lottery Ticket Hypothesis）は、ランダムに初期化された密なネットの中に、適切に訓練すれば元と同等の精度を出せる疎なネット（当たりくじ）が含まれているという主張です。"
    },
    {
      "id": 33,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "モデル評価",
      "question": "ディープラーニングのブラックボックス問題を解決するためのXAI（説明可能なAI）において、判断の根拠をヒートマップとして可視化する代表的な手法はどれか。",
      "options": [
        "Grad-CAM",
        "LIME",
        "SHAP",
        "ReLU"
      ],
      "answer": 0,
      "explanation": "Grad-CAMは、畳み込み層の勾配情報を利用して、モデルが画像のどの領域を重視して判定を行ったかを色分け（ヒートマップ）して表示する手法です。"
    },
    {
      "id": 34,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "検証手法",
      "question": "特定のデータだけでなく、モデルの種類に依存せず（モデルアグノスティック）、局所的なサンプリングによってモデルの判断を近似的に説明する手法はどれか。",
      "options": [
        "LIME",
        "Grad-CAM",
        "ニューラルネットワーク",
        "決定木"
      ],
      "answer": 0,
      "explanation": "LIME（Local Interpretable Model-agnostic Explanations）は、複雑なモデルを局所的に単純なモデル（線形回帰など）で近似することで、特定の予測理由を説明可能にする手法です。"
    },
    {
      "id": 35,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "学習の課題",
      "question": "協力ゲーム理論の概念を応用し、各特徴量が予測結果に対してどれだけ貢献したかを公平に算出する、数学的な根拠に基づいた説明手法はどれか。",
      "options": [
        "SHAP",
        "LIME",
        "Grad-CAM",
        "PCA"
      ],
      "answer": 0,
      "explanation": "SHAP（SHapley Additive exPlanations）は、シャープレイ値（Shapley value）を用いて各特徴量の寄与度を算出し、入力データと予測結果の結びつきを多角的に説明します。"
    },
    {
      "id": 36,
      "majorCategory": "機械学習の概要",
      "subCategory": "学習の課題",
      "question": "ディープラーニングモデルをスマートフォンなどのエッジデバイスで動作させる際、パラメータの数値を32bit浮動小数点から8bit整数などに変換して軽量化高速化を図る手法はどれか。",
      "options": [
        "量子化",
        "蒸留",
        "プルーニング",
        "正規化"
      ],
      "answer": 0,
      "explanation": "量子化は、データの表現精度（ビット数）を落とすことで、計算負荷とメモリ消費を大幅に削減する技術です。最近の推論チップはこの量子化された演算を高速に処理することに特化しています。"
    },
    {
      "id": 37,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "日本の個人情報保護法において、氏名や生年月日などとは別に、指紋データや顔認識データ、マイナンバーなどの「個人の身体的特徴をデジタル化したもの」を何と呼ぶか。",
      "options": [
        "個人識別符号",
        "要配慮個人情報",
        "匿名加工情報",
        "機密情報"
      ],
      "answer": 0,
      "explanation": "個人識別符号は、それ単体で特定の個人を識別できる特定の情報（指紋、DNA配列、顔認識データ等）を指し、個人情報保護法の対象となります。"
    },
    {
      "id": 38,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "個人情報保護法において、人種、信条、病歴、犯罪歴など、不当な差別や偏見が生じないよう取り扱いに特別な配慮が必要な情報を何というか。",
      "options": [
        "要配慮個人情報",
        "個人識別符号",
        "仮名加工情報",
        "限定提供データ"
      ],
      "answer": 0,
      "explanation": "要配慮個人情報は、本人の同意なく取得することが原則禁止されており、第三者提供の際もオプトアウト規定（事後拒否）による提供が認められない、厳格な管理が求められる情報です。"
    },
    {
      "id": 39,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "2022年施行の改正個人情報保護法で新設された、他の情報と照合しない限り特定個人を識別できないよう加工した情報を何というか。内部分析目的であれば利用目的の変更が柔軟に認められる。",
      "options": [
        "仮名加工情報",
        "匿名加工情報",
        "個人識別符号",
        "限定提供データ"
      ],
      "answer": 0,
      "explanation": "仮名加工情報は、元のデータと紐付けるための「連結テーブル」を保持しているため外部提供は原則禁止ですが、企業内部でのデータ利活用（AI学習など）を促進するために創設された枠組みです。"
    },
    {
      "id": 40,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "特定個人を識別できず、かつ復元もできないように適切に加工された情報を何というか。公表義務などの条件を満たせば、本人の同意なしで第三者提供（データの売買など）が可能となる。",
      "options": [
        "匿名加工情報",
        "仮名加工情報",
        "要配慮個人情報",
        "統計データ"
      ],
      "answer": 0,
      "explanation": "匿名加工情報は、復元不可能なレベルまで加工を施すことで、個人情報としての制約を受けずに外部への提供や販売が可能になるデータ形式です。"
    },
    {
      "id": 41,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "EUで施行されているGDPR（一般データ保護規則）において、データ主体が自身のデータを管理し、他のサービスへ容易に移転できる権利を何というか。",
      "options": [
        "データポータビリティ権",
        "忘れられる権利",
        "異議申立権",
        "処理制限権"
      ],
      "answer": 0,
      "explanation": "データポータビリティ権は、個人が自身のデータを構造化された形式で受け取り、別のサービスへ自由に移動させることを保障する、デジタル時代の重要な権利です。"
    },
    {
      "id": 42,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "GDPRにおいて、EU域内に拠点を持たない事業者であっても、EU域内の個人にサービスを提供したり、その行動を監視したりする場合に、この規則が適用されることを何というか。",
      "options": [
        "域外適用",
        "十分性認定",
        "相互承認",
        "標準契約条項"
      ],
      "answer": 0,
      "explanation": "GDPRの「域外適用」により、日本企業であってもEU居住者の個人データを取り扱う場合は、この規則を遵守する義務が生じます。"
    },
    {
      "id": 43,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "EU AI Act（欧州人工知能法）において、個人の社会的信用をスコアリングするAIや、公共の場所でのリアルタイム遠隔生体識別などは、どのリスクレベルに分類され、原則として禁止されているか。",
      "options": [
        "許容できないリスク",
        "高リスク",
        "限定的リスク",
        "最小限のリスク"
      ],
      "answer": 0,
      "explanation": "EU AI Actはリスクベースアプローチを採用しており、人の尊厳や基本的人権を脅かすようなAIの使用は「許容できないリスク」として禁止されています。"
    },
    {
      "id": 44,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "EU AI Actにおいて、採用、入試、与信管理、重要インフラの運用、自動運転などの分野で使用されるAIは、どのリスクレベルに分類され、厳格な義務が課されるか。",
      "options": [
        "高リスク",
        "許容できないリスク",
        "限定的リスク",
        "最小限のリスク"
      ],
      "answer": 0,
      "explanation": "「高リスク」に分類されたAIシステムには、リスク管理システムの構築、データのガバナンス、透明性と利用者への情報提供、人間の監視などの厳しい法的義務が課されます。"
    },
    {
      "id": 45,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "日本の著作権法第30条の4（情報解析のための利用）に関する記述として、最も適切なものはどれか。",
      "options": [
        "AIの学習目的であれば、原則として著作権者の許諾なく著作物を利用できる",
        "商用目的のAI学習には、必ず著作権者の個別許諾が必要である",
        "AIが生成した画像については、すべて著作権が発生しない",
        "いかなる場合でも、著作権者の利益を不当に害する利用も認められる"
      ],
      "answer": 0,
      "explanation": "著作権法第30条の4は、AIの学習などの「情報解析」目的であれば、著作物の種類を問わず複製等が可能であることを定めた、世界的に見ても柔軟な規定です。ただし「著作権者の利益を不当に害する場合」は除外されます。"
    },
    {
      "id": 46,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習のテクニック",
      "question": "自然言語処理において、単語の意味を多次元ベクトルで表現する手法のうち、単語全体を部分文字列（n-gramの文字集合）の集まりとして扱うことで、未知語（OOV）に対しても頑健な対応を可能にしたFacebook開発の手法はどれか。",
      "options": [
        "fastText",
        "word2vec",
        "GloVe",
        "ELMo"
      ],
      "answer": 0,
      "explanation": "fastTextは、単語をサブワード（文字単位のn-gram）に分解してベクトル化するため、学習データにない単語（タイポや活用形など）に対しても、その構成文字から意味を推測することができます。"
    },
    {
      "id": 47,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習のテクニック",
      "question": "2017年に発表された論文「Attention Is All You Need」で提案され、RNNやCNNを一切使わず、「Self-Attention」のみで並列処理を可能にした、現在の自然言語処理のパラダイムを変えたモデルはどれか。",
      "options": [
        "Transformer",
        "LSTM",
        "GRU",
        "ResNet"
      ],
      "answer": 0,
      "explanation": "Transformerは、再帰構造（RNN）を排除し、文章全体の単語間の関係を一度に計算できる自己注意機構（Self-Attention）を採用したことで、学習速度と性能を飛躍的に向上させました。"
    },
    {
      "id": 48,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "Transformerのエンコーダとデコーダのうち、デコーダ（Decoder）のみを積み重ねて構築され、次の単語を予測する自己回帰的な動作を得意とする生成系AIモデル（GPTシリーズなど）の基礎となっている構造はどれか。",
      "options": [
        "GPT",
        "BERT",
        "RoBERTa",
        "ALICE"
      ],
      "answer": 0,
      "explanation": "GPTは、Transformerのデコーダ部分を使用し、ある単語の次に出現する単語を予測するように事前学習される「自己回帰モデル（Autoregressive Model）」です。"
    },
    {
      "id": 49,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "Transformerのアーキテクチャでは、文章内の単語の順序や位置情報を考慮できないため、入力ベクトルに特定の波形の値を加算して「位置情報」を付与する仕組みを何というか。",
      "options": [
        "Positional Encoding",
        "Positional Embedding",
        "Self-Attention",
        "Skip Connection"
      ],
      "answer": 0,
      "explanation": "TransformerはRNNと異なり時系列的な構造を持たないため、単語の位置関係（前後関係）を認識するために、Positional Encodingという位置情報を表す固定値を加算します。"
    },
    {
      "id": 50,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "画像認識と自然言語処理を組み合わせたマルチモーダルモデルであり、4億組の画像とテキストのペアを用いて、画像と説明文が同じ意味空間で近くなるように学習されたOpenAIの開発したモデルはどれか。",
      "options": [
        "CLIP",
        "DALL-E",
        "Stable Diffusion",
        "Midjourney"
      ],
      "answer": 0,
      "explanation": "CLIP (Contrastive Language-Image Pre-training) は、画像とテキストを共通のベクトル空間に埋め込むことで、未知のカテゴリに対してもゼロショット（追加学習なし）で画像分類できるなど、極めて高い汎用性を示しました。"
    },
    {
      "id": 51,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "CNN応用",
      "question": "2019年にOpenAIが公開したGPT-2は、モデルのパラメータ数を15億にまで増やし、特定のタスクに向けた追加学習（ファインチューニング）を行わなくても、プロンプトだけで様々なタスクに対応できることを示しました。この手法を何というか。",
      "options": [
        "Zero-shot Learning",
        "Few-shot Learning",
        "Multitasking",
        "Pre-training"
      ],
      "answer": 0,
      "explanation": "Zero-shot Learningは、全く未知のクラスやタスクに対しても、学習済みモデルの知識だけで推論を行うことを指します。GPTシリーズはこの能力が非常に高いことが特徴です。"
    },
    {
      "id": 52,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "画像生成モデルにおいて、データにノイズを徐々に混ぜ、そのノイズを逆向きに取り除いていく過程を学習することで、高品質な画像を生成するStable Diffusionなどの基盤となっている技術はどれか。",
      "options": [
        "拡散モデル",
        "GAN",
        "VAE",
        "オートエンコーダ"
      ],
      "answer": 0,
      "explanation": "拡散モデルは、学習の安定性が高く、GANに比べて生成される画像の多様性に優れているため、現在の画像生成AI（Stable Diffusion, DALL-E 3等）の主流となっています。"
    },
    {
      "id": 53,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "LLM（大規模言語モデル）の人間による調整手法の一つで、生成された複数の回答を人間が評価ランク付けし、その報酬モデル（Reward Model）を使って強化学習（PPO等）を行うことで、回答の質を向上させる手法はどれか。",
      "options": [
        "RLHF",
        "In-context Learning",
        "Contrastive Learning",
        "Fine-tuning"
      ],
      "answer": 0,
      "explanation": "RLHF（Reinforcement Learning from Human Feedback - 人間のフィードバックによる強化学習）は、ChatGPTなどのモデルが、人間の意図に沿った安全で有用な対話ができるようにするために不可欠なプロセスです。"
    },
    {
      "id": 54,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "ディープラーニングの応用",
      "question": "画像処理タスクにおいて、医療用画像（細胞の輪郭抽出など）で特によく用いられる、エンコーダとデコーダをスキップ結合（Skip Connection）で接続し、精細な情報を詳細に復元可能なU字型のネットワーク構造を持つモデルはどれか。",
      "options": [
        "U-Net",
        "FCN",
        "SegNet",
        "DeepLab"
      ],
      "answer": 0,
      "explanation": "U-Netは、収縮パス（エンコーダ）と拡張パス（デコーダ）の対応する層を結合することで、物体の位置情報を正確に復元できるため、セグメンテーション（ピクセル単位の分類）に非常に優れています。"
    },
    {
      "id": 55,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "ディープラーニングの応用",
      "question": "セマンティックセグメンテーション（ピクセル単位の分類）において、単純な畳み込みよりも受容野（Receptive Field）を効果的に広げるために、フィルタの間に隙間を空けて計算を行う手法を何というか。",
      "options": [
        "Dilated Convolution",
        "Depthwise Separable Convolution",
        "Grouped Convolution",
        "Deconvolution"
      ],
      "answer": 0,
      "explanation": "Dilated Convolutionは、計算コストを抑えつつ、より広い範囲の情報を考慮して畳み込みを行うことができるため、画像解析や音声処理（WaveNet等）で広く採用されています。"
    },
    {
      "id": 56,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "深層学習のモデル",
      "question": "物体検出モデルのFaster R-CNNに、ピクセル単位の識別を行うマスク生成ブランチを追加し、物体検出とインスタンスセグメンテーション（個体識別）を同時に可能にしたモデルはどれか。",
      "options": [
        "Mask R-CNN",
        "YOLO",
        "SSD",
        "PSPNet"
      ],
      "answer": 0,
      "explanation": "Mask R-CNNは、物体のバウンディングボックスの特定だけでなく、その物体の正確な形状（マスク）まで抽出できるマルチタスクなセグメンテーションモデルです。"
    },
    {
      "id": 57,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "生成AIの手法",
      "question": "DeepMindが2016年に発表した、生の音声波形を直接生成するモデルであり、Dilated Convolutionを多用して広い受容野を持ち、それまでにない自然な合成音声を実現したものはどれか。",
      "options": [
        "WaveNet",
        "Tacotron",
        "MFCC",
        "CNN"
      ],
      "answer": 0,
      "explanation": "WaveNetは、一歩手前の波形から次の瞬間のサンプルの確率分布を予測する自己回帰モデルで、それまで主流だった連結型合成音声よりも遥かに人間の声に近い合成音を生成できます。"
    },
    {
      "id": 58,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "生成AIの手法",
      "question": "音声認識の学習において、入力（音声フレーム）と出力（文字）の長さが異なり、アライメント（対応関係）が不明なデータに対しても、動的計画法を用いて効率的に損失を計算できる手法はどれか。",
      "options": [
        "CTC",
        "Attention",
        "Self-Attention",
        "Beam Search"
      ],
      "answer": 0,
      "explanation": "CTCは、音声認識や手書き文字認識など、時系列の長さが一致しない系列間の変換において、空白（blank）記号を導入してアライメントの不確実性を吸収します。"
    },
    {
      "id": 59,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの応用分野",
      "question": "AI開発プロジェクトのPoC（概念実証）や研究開発段階において、成果物の完成を保証することが困難なため、仕事の完成ではなく、善管注意義務に基づいた役務の提供を目的として締結される契約形態はどれか。",
      "options": [
        "準委任契約",
        "請負契約",
        "売買契約",
        "雇用契約"
      ],
      "answer": 0,
      "explanation": "準委任契約は、不確実性の高いAI開発において、一定のスキルを持った開発者が善良な管理者として誠実に作業を行うことを約束する形態であり、成果の「完成義務」を負わないのが請負との大きな違いです。"
    },
    {
      "id": 60,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの応用分野",
      "question": "AIの開発委託契約において受託者が負う「善管注意義務」に関する説明として、最も適切なものはどれか。",
      "options": [
        "専門家として客観的に期待される注意を払って業務を遂行する義務",
        "仕事の完成を100%保証する義務",
        "開発したAIの精度が低下した際に無償で永久に修正する義務",
        "委託者の指示に無条件に従う義務"
      ],
      "answer": 0,
      "explanation": "善管注意義務（善良な管理者の注意義務）は、委託された事務の内容について、その道の専門家として通常期待されるレベルの注意を尽くす義務を指します。"
    },
    {
      "id": 61,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習の課題",
      "question": "AIプロジェクトにおいて、本来予測時には利用不可能な「未来の情報」が学習データに混入し、開発時には見かけ上高い精度が出るが、本番環境では使い物にならなくなる現象を何というか。",
      "options": [
        "データリーケージ",
        "オーバーフィッティング",
        "アンダーフィッティング",
        "共変量シフト"
      ],
      "answer": 0,
      "explanation": "データリーケージは、テストデータに含まれるべき正解の手がかりが訓練データに漏れ出してしまう問題で、不正検知モデルの構築などで時系列の扱いを誤ると発生しやすいため注意が必要です。"
    },
    {
      "id": 62,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIの応用分野",
      "question": "AIプロジェクトの進行中に、目標精度が達成できなかったり、新たな課題が見つかってPoC（概念実証）を何度も繰り返してしまい、次のステップへ進めなくなる状態を何と呼ぶか。",
      "options": [
        "PoC死",
        "オーバーサンプリング",
        "デッドロック",
        "アジャイル開発"
      ],
      "answer": 0,
      "explanation": "PoC死とは、検証を目的としたPoCが本来の目的を見失い、継続的な試作のみに終始してしまい、最終的な実用化（本番化）に至らない現象を指すビジネス用語です。"
    },
    {
      "id": 63,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIの応用分野",
      "question": "機械学習モデルの開発から本番運用、監視、品質管理（再学習）までのライフサイクルを自動化効率化し、開発チームと運用チームが密に連携する手法や文化を何というか。",
      "options": [
        "MLOps",
        "DevOps",
        "DataOps",
        "Model Management"
      ],
      "answer": 0,
      "explanation": "MLOpsは、DevOpsの考え方を機械学習に適用したもので、コードだけでなくデータやモデルのバージョン管理、データの変化（ドリフト）に応じた継続的学習などを目指します。"
    },
    {
      "id": 64,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIの応用分野",
      "question": "AIモデルの学習において必要不可欠な「データにラベル（正解）を付与する作業」を何と呼ぶか。",
      "options": [
        "アノテーション",
        "ラベリング",
        "スクレイピング",
        "クレンジング"
      ],
      "answer": 0,
      "explanation": "アノテーションは、画像の中のどこに何が映っているか、テキストがどのような感情を含んでいるかなどをタグ付けする作業で、AIの精度はこの品質に大きく依存します。"
    },
    {
      "id": 65,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIの応用分野",
      "question": "データの品質を管理するための指標の一つで、AIが判断を下した後に人間の専門家などがその結果を検証し、学習データの質を定常的に保つ仕組みに関連する概念はどれか。",
      "options": [
        "Human-in-the-Loop",
        "Black Box",
        "End-to-End",
        "Deep Learning"
      ],
      "answer": 0,
      "explanation": "Human-in-the-Loop (HITL) は、AIの予測が不確かな場合に人間が介入したり、定期的なフィードバックをループに組み込んだりすることで、モデルの精度と信頼性を高める設計思想です。"
    },
    {
      "id": 66,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "2023年のG7広島サミットにおいて合意された、生成AIに関する国際的な指針や開発者向けの行動規範を策定する枠組みを何というか。",
      "options": [
        "広島AIプロセス",
        "アジロマ原則",
        "ダボス会議",
        "OECD AI原則"
      ],
      "answer": 0,
      "explanation": "広島AIプロセスは、生成AIの急速な普及に伴うリスクに対応するため、信頼できるAIの実現に向けた国際的なルール作りを目指す重要な取り組みです。"
    },
    {
      "id": 67,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "AIシステムが特定の個人やグループに対して不当な不利益を与える「アルゴリズムバイアス」の発生原因として、不適切なものはどれか。",
      "options": [
        "モデルのパラメータ数が多すぎて計算が複雑になること",
        "学習データ自体に過去の人間の偏見が含まれていること",
        "特定の属性のデータが極端に少ないサンプリングの偏り",
        "予測結果の評価指標が、全体の正解率のみに偏っていること"
      ],
      "answer": 0,
      "explanation": "アルゴリズムバイアスは主にデータの質や収集方法、評価指標の設計に起因します。パラメータ数が多いこと（モデルの複雑さ）自体が直接的な差別の原因になるわけではありません。"
    },
    {
      "id": 68,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "AI倫理において、「AIがいかなる判断を行ったか」が利用者にも説明可能であるべきという原則を何というか。",
      "options": [
        "透明性説明可能性",
        "人間中心の原則",
        "公平性の原則",
        "セキュリティの原則"
      ],
      "answer": 0,
      "explanation": "透明性は、AIがブラックボックス化することを防ぎ、なぜその判断に至ったかを人間が理解検証できるようにすることで、信頼性を確保するための基本原則です。"
    },
    {
      "id": 69,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "AI倫理の設計思想の一つである「プライバシーバイデザイン（Privacy by Design）」に関する説明として、最も適切なものはどれか。",
      "options": [
        "システムを構築した後ではなく、設計段階からプライバシー保護を組み込むこと",
        "ユーザーが自分の個人情報を自由に売買できる仕組みを作ること",
        "すべてのデータを匿名化して個人を特定不可能にすることのみを指す",
        "個人情報を最大限に活用してAIの精度を極限まで高めること"
      ],
      "answer": 0,
      "explanation": "プライバシーバイデザインは、Ann Cavoukian氏が提唱した概念で、事後対応ではなく「デフォルトでプライバシーが守られる」ように設計の初期段階から技術的組織的対策を組み込むアプローチです。"
    },
    {
      "id": 70,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "AIの倫理的課題",
      "question": "2019年に採択されたOECD（経済協力開発機構）のAI原則において、AIシステムの開発運用に関わる者が負うべき責任を指す概念はどれか。",
      "options": [
        "アカウンタビリティ",
        "レジリエンス",
        "サステナビリティ",
        "トレーサビリティ"
      ],
      "answer": 0,
      "explanation": "アカウンタビリティ（説明責任）は、AIがもたらした結果に対して、開発者や運用者が責任を持ち、必要に応じてその経緯を説明する義務があるという原則です。"
    },
    {
      "id": 71,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIセキュリティ",
      "question": "AIセキュリティにおける攻撃手法のうち、学習データに悪意あるサンプルを混入させることで、モデルに特定の条件で誤った判断をさせるバックドア（罠）を仕掛ける手法を何というか。",
      "options": [
        "データ汚染",
        "敵対的攻撃",
        "モデル抽出攻撃",
        "メンバーシップ推論攻撃"
      ],
      "answer": 0,
      "explanation": "データ汚染（ポイズニング）は、学習段階での介入であり、特定のトリガーを認識した時だけ攻撃者の意図通りに動作するような不正なモデルを作成させる攻撃です。"
    },
    {
      "id": 72,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIセキュリティ",
      "question": "画像認識モデルなどの入力に、人間には知覚できない極めて微小なノイズを加えることで、AIを意図的に誤分類させる「敵対的サンプル（Adversarial Example）」を用いた攻撃を何というか。",
      "options": [
        "敵対的攻撃",
        "データ汚染",
        "モデル抽出攻撃",
        "プロンプトインジェクション"
      ],
      "answer": 0,
      "explanation": "敵対的攻撃は、ディープラーニングモデルの脆弱性を突いた推論時の攻撃であり、FGSMやPGDといった手法でノイズ（摂動）が生成されます。"
    },
    {
      "id": 73,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIセキュリティ",
      "question": "ディープラーニングを用いた偽の動画や音声「ディープフェイク」の悪用に対する技術的対策として、生成されたコンテンツに人間には見えない特定の情報を埋め込み、由来を識別可能にする技術はどれか。",
      "options": [
        "電子透かし",
        "ブロックチェーン",
        "デジタル署名",
        "暗号化"
      ],
      "answer": 0,
      "explanation": "電子透かしは、画像や動画の品質を損なわずに固有の識別情報を埋め込む技術で、生成AIによる偽情報の拡散防止やコンテンツの真実性の証明に期待されています。"
    },
    {
      "id": 74,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "倫理的課題",
      "question": "AIの判断における公平性を評価する際に用いられる概念で、複数のグループ（例：男女）の間で、陽性（合格、採用など）と判定される割合が統計的に等しい状態を指すのはどれか。",
      "options": [
        "集団公平性",
        "個人公平性",
        "機会均等",
        "予測的パリティ"
      ],
      "answer": 0,
      "explanation": "集団公平性は、性別や人種などの保護属性によって判定結果に統計的な差がないことを重視する公平性の指標です。"
    },
    {
      "id": 75,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIセキュリティ",
      "question": "AIの安全性を確保するための手法の一つで、敵対的サンプル（Adversarial Example）をあえて学習データに含めて訓練することで、ノイズ攻撃に対する耐性を高める手法を何というか。",
      "options": [
        "敵対的学習",
        "データ拡張",
        "蒸留",
        "プルーニング"
      ],
      "answer": 0,
      "explanation": "敵対的学習は、攻撃者が作成しそうなノイズ入りの画像を学習時に見せておくことで、モデルの堅牢性（堅牢な判断能力）を向上させる防御策です。"
    },
    {
      "id": 76,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "モデルの解釈性",
      "question": "AIモデルの解釈性手法であるLIMEにおいて、特定の予測を説明するために利用される手法はどれか。",
      "options": [
        "対象のデータの周辺をサンプリングし、局所的に線形モデルで近似する",
        "ネットワーク全体の勾配を計算し、全結合層の重みを可視化する",
        "すべての学習データを再学習し、影響力の大きいデータを特定する",
        "モデルのハイパーパラメータをランダムに変更して出力を比較する"
      ],
      "answer": 0,
      "explanation": "LIME（Local Interpretable Model-agnostic Explanations）は、「モデルの中身を問わず（アグノスティック）」、説明したいデータの近傍でサンプルを生成し、単純なモデルでその振る舞いを真似させることで説明を行います。"
    },
    {
      "id": 77,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "モデルの解釈性",
      "question": "ディープラーニングにおいて、入力データの微小な変化が出力に与える影響（勾配）を可視化することで、モデルがどの画素に注目しているかを示す基本的な手法を何というか。",
      "options": [
        "サリエンシーマップ",
        "Grad-CAM",
        "LIME",
        "SHAP"
      ],
      "answer": 0,
      "explanation": "サリエンシーマップは、出力値を入力画像で微分した勾配を可視化したもので、物体の輪郭などが強調される傾向があります。可視化手法の最も基本的なものの一つです。"
    },
    {
      "id": 78,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "モデル評価",
      "question": "データ収集時に、特定のクラスのデータのみが大量に含まれ、他のクラスのデータが極端に少ない場合に発生する問題はどれか。",
      "options": [
        "不均衡データ  問題",
        "マルチコ",
        "オーバーフィッティング",
        "次元の呪い"
      ],
      "answer": 0,
      "explanation": "不均衡データの問題は、AIが多数派のクラスばかりを予測するようになり、少数派（例えば稀な病気の発見など）の精度が著しく低下することです。サンプリング調整などの対策が必要です。"
    },
    {
      "id": 79,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "AIセキュリティ",
      "question": "生成AIなどのコンテンツの真正性を確保するため、データの作成から編集、公開に至るまでの履歴（プロバンス）を記録証明しようとする国際的な技術標準（C2PAなど）の取り組みに関連する概念はどれか。",
      "options": [
        "コンテンツの来歴",
        "著作権フリー",
        "電子署名",
        "ブロックチェーン専用"
      ],
      "answer": 0,
      "explanation": "Content Provenance（コンテンツの来歴）は、その画像や動画がいつ、誰によって、どのAIを使って作られたかという情報を追跡可能にすることで、偽情報対策や信頼性確保を目指すものです。"
    },
    {
      "id": 80,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "デジタルトランスフォーメーション",
      "question": "AIプロジェクトにおいて、自社のリソースだけでなく、他社、大学、自治体などの外部の技術やアイデアを柔軟に取り入れて、革新的な価値を創出する手法を何というか。",
      "options": [
        "オープンイノベーション",
        "アウトソーシング",
        "BPR",
        "PoC"
      ],
      "answer": 0,
      "explanation": "オープンイノベーションは、組織の境界を超えて知識や技術を循環させることで、自社だけでは困難なスピードや規模でのイノベーションを目指すアプローチです。"
    },
    {
      "id": 81,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "教師あり学習の回帰タスクにおいて、モデルの予測値と真の値の差の二乗の平均をとる、最も標準的な損失関数はどれか。",
      "options": [
        "平均二乗誤差",
        "交差エントロピー誤差",
        "平均絶対誤差",
        "ヒンジ損失"
      ],
      "answer": 0,
      "explanation": "平均二乗誤差（Mean Squared Error）は、大きな誤差に対してより大きなペナルティを与える特性があり、回帰問題のモデル評価や学習の指標として広く用いられます。"
    },
    {
      "id": 82,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "決定木を学習させる際、分割後の子ノードの「不純度」が最も低くなるように分割を決定する。この「不純度」を測る代表的な指標はどれか。",
      "options": [
        "ジニ係数",
        "相関係数",
        "決定係数",
        "標準偏差"
      ],
      "answer": 0,
      "explanation": "ジニ係数（Gini Impurity）は、ノード内のデータの混ざり具合を表す指標です。値が小さいほどクラスが純粋（一種類にまとまっている）であることを示し、決定木の分割基準として一般的です。"
    },
    {
      "id": 83,
      "majorCategory": "機械学習の概要",
      "subCategory": "モデル評価",
      "question": "ロジスティック回帰において、特徴量の重み $w$ が $0$ になるように誘導し、特徴量選択の効果を持たせるために損失関数に加えられる制約はどれか。",
      "options": [
        "L1正則化",
        "L2正則化",
        "弾性ネット",
        "ドロップアウト"
      ],
      "answer": 0,
      "explanation": "L1正則化は、重みの絶対値の和をペナルティ項として加えることで、不要な特徴量の重みを正確に $0$ にする性質（スパース性）があり、変数選択としても機能します。"
    },
    {
      "id": 84,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "社会実装に向けて",
      "question": "ディープニューラルネットワークにおいて、重みの初期値が適切でないと、層を深くするにつれて信号が極端に大きくなったり小さくなったりする。この問題を解決するために提案された初期化手法のうち、ReLU関数と相性が良いとされるものはどれか。",
      "options": [
        "Heの初期値",
        "Xavierの初期値",
        "ガウス初期化",
        "ゼロ初期化"
      ],
      "answer": 0,
      "explanation": "Heの初期値は、ReLUを使用するネットワークの各層の出力の分散を一定に保つように設計されており、勾配消失や勾配爆発を防ぐ効果があります。"
    },
    {
      "id": 85,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "社会実装",
      "question": "勾配降下法において、過去の勾配の移動平均を利用して「慣性（モーメント）」を持たせることで、振動を抑えつつ平坦な領域でも効率よく学習を進める手法を何というか。",
      "options": [
        "Momentum",
        "AdaGrad",
        "RMSProp",
        "SGD"
      ],
      "answer": 0,
      "explanation": "Momentumは、物理的な運動量（慣性）の概念を導入することで、局所的な急勾配に振り回されすぎず、全体的な勾配の方向に加速して収束を早める手法です。"
    },
    {
      "id": 86,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "管理・運用",
      "question": "ディープラーニングモデルのパラメータ更新において、学習率をパラメータごとに動的に調整し、過去の勾配の二乗和を利用して収束を安定化させる手法のうち、勾配の二乗和が累積して学習率が極端に小さくなってしまう欠点を指数移動平均の導入で改善したものはどれか。",
      "options": [
        "RMSProp",
        "AdaGrad",
        "SGD",
        "Adam"
      ],
      "answer": 0,
      "explanation": "RMSPropは、AdaGradの「学習が進むにつれて学習率が0（減衰しすぎ）になってしまう」問題を、直近の勾配を重視する指数移動平均（移動平均）を導入することで解決した手法です。"
    },
    {
      "id": 87,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "管理・運用",
      "question": "ディープラーニングにおいて、入力データのわずかな変動（ノイズ）に対してモデルの出力が大きく変動しないようにする、関数の滑らかさを保証するための制約を何というか。",
      "options": [
        "リプシッツ連続性",
        "線形性",
        "直交性",
        "スパース性"
      ],
      "answer": 0,
      "explanation": "リプシッツ連続性は、関数の変化の度合いが一定の定数（リプシッツ定数）以下であることを保証する性質です。GAN（特にWGAN）などの学習を安定させるための制約条件として採用されます。"
    },
    {
      "id": 88,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "データ処理",
      "question": "画像の中から特定の物体を検出し、その物体の種類を分類する「物体検出」において、画像全体から一度に特徴を抽出して直接バウンディングボックスとクラスを予測する、高速な1段階（One-stage）手法の代表格はどれか。",
      "options": [
        "YOLO",
        "R-CNN",
        "Fast R-CNN",
        "Faster R-CNN"
      ],
      "answer": 0,
      "explanation": "YOLOは、画像をグリッドに分割して各セルで直接予測を行うことで、リアルタイムに近い非常に高速な物体検出を可能にした画期的なモデルです。"
    },
    {
      "id": 89,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "数理・統計の基礎",
      "question": "2014年に発表されたVGG16において、モデル全体のパラメータの大部分を占めているのはどの層か。",
      "options": [
        "全結合層",
        "畳み込み層",
        "プーリング層",
        "入力層"
      ],
      "answer": 0,
      "explanation": "VGG16のような初期の深いモデルでは、畳み込み層で特徴を抽出した後、最後の全結合層（Fully Connected Layer）が大規模なパラメータ（数百MB）を保持しており、モデル軽量化の主な対象となりました。"
    },
    {
      "id": 90,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "数理・統計の基礎",
      "question": "CNN（畳み込みニューラルネットワーク）において、1x1のフィルタを用いた畳み込み（1x1 Convolution）を行う主な目的はどれか。",
      "options": [
        "チャンネル方向の次元削減",
        "空間解像度の拡大",
        "プーリングの代替",
        "過学習の抑制"
      ],
      "answer": 0,
      "explanation": "1x1畳み込みは、画像のサイズ（高さ幅）を変えずに、チャンネル数（奥行き）だけを調整（削減）することができ、InceptionモジュールやResNetのボトルネック構造で計算量削減のために多用されます。"
    },
    {
      "id": 91,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "数理・統計の基礎",
      "question": "2017年に提唱されたMobileNetにおいて採用され、畳み込み演算を「チャンネルごとの畳み込み（Depthwise）」と「1x1の畳み込み（Pointwise）」に分解することで、計算量を大幅に削減した手法を何というか。",
      "options": [
        "Depthwise Separable Convolution",
        "Dilated Convolution",
        "Transposed Convolution",
        "Deconvolution"
      ],
      "answer": 0,
      "explanation": "Depthwise Separable Convolution（深度別分離畳み込み）は、通常の畳み込みに比べて精度低下を抑えつつ計算コストを数分の一から十分の一程度に削減できるため、モバイル端末向けモデルの核心技術となっています。"
    },
    {
      "id": 92,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "数理・統計の基礎",
      "question": "RNN（再帰型ニューラルネットワーク）の一種であり、LSTMよりも構造をシンプルに（ゲート数を2つに）減らしつつ、長期依存性の学習能力を維持したモデルはどれか。",
      "options": [
        "GRU",
        "Simple RNN",
        "Bi-RNN",
        "Echo State Network"
      ],
      "answer": 0,
      "explanation": "GRUは、「リセットゲート」と「更新ゲート」の2つのゲートのみを持ち、LSTMよりもパラメータが少ないため計算効率が良く、データセットが比較的小さい場合に有効な選択肢となります。"
    },
    {
      "id": 93,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "基本統計量",
      "question": "自然言語処理における単語の意味表現（Word Embedding）において、単語を「周辺に出現する単語」から予測するCBOWに対し、ある単語から「その周辺に出現する単語」を予測するように学習するword2vecの手法を何というか。",
      "options": [
        "Skip-gram",
        "fastText",
        "GloVe",
        "BERT"
      ],
      "answer": 0,
      "explanation": "Skip-gramは、CBOWに比べて計算コストは高いものの、出現頻度の低い単語に対しても高品質なベクトル（分散表現）を獲得しやすいという特徴があります。"
    },
    {
      "id": 94,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "基本統計量",
      "question": "Transformerの自己注意機構（Self-Attention）において、注目する単語以外の情報が将来の情報を含まないように、デコーダ側で行われる処理を何というか。",
      "options": [
        "Masking",
        "Padding",
        "Positional Encoding",
        "Softmax"
      ],
      "answer": 0,
      "explanation": "Transformerのデコーダでは、文章生成時に未来の単語をカンニングしないように、まだ生成されていない単語の注意の重みをゼロにする「マスキング」という処理が不可欠です。"
    },
    {
      "id": 95,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "基本統計量",
      "question": "画像生成モデルの一種であるVAE（変分オートエンコーダ）において、潜在変数を「平均」と「分散」を持つ正規分布として学習させ、そこからサンプリングを行う際、勾配を逆伝播できるようにするために用いられる手法を何というか。",
      "options": [
        "Reparameterization Trick",
        "Backpropagation",
        "Monte Carlo Method",
        "Stochastic Gradient Descent"
      ],
      "answer": 0,
      "explanation": "Reparameterization Trick（再パラメータ化トリック）は、サンプリングという確率的な（微不可能な）操作を、「固定された平均分散」と「外部のノイズ」に分離することで、誤差逆伝播法を可能にする重要なテクニックです。"
    },
    {
      "id": 96,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "推測統計",
      "question": "ディープラーニングにおける「表現学習（Representation Learning）」の目的として、最も適切なものはどれか。",
      "options": [
        "データの中から、予測や分類に有効な特徴を自動的に抽出すること",
        "人間が定義した数万個のルールを高速に処理すること",
        "データの重複を一切排除してメモリ消費を極限まで抑えること",
        "ニューラルネットワークのパラメータをすべて固定して学習を停止させること"
      ],
      "answer": 0,
      "explanation": "ディープラーニングの最大の特徴は、従来は人間が手作業で設計（特徴量エンジニアリング）していた「特徴量」を、データから自動的に獲得（表現学習）できる点にあります。"
    },
    {
      "id": 97,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "距離尺度",
      "question": "物体検出において、まず「物体がありそうな領域」を提案（Region Proposal）し、その後に各領域を分類する2段階（Two-stage）のアプローチをとる代表的なモデルはどれか。",
      "options": [
        "Faster R-CNN",
        "YOLO",
        "SSD",
        "Transformer"
      ],
      "answer": 0,
      "explanation": "Faster R-CNNは、Region Proposal Network (RPN) を導入することで領域提案もニューラルネットワーク化し、高い精度と（R-CNNと比較して）実用的な速度を実現しました。"
    },
    {
      "id": 98,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "距離尺度",
      "question": "画像の中から特定の物体をピクセル単位で塗り分ける「セマンティックセグメンテーション」において、画像を縮小して特徴を抽出するエンコーダと、元の画像サイズに戻す（Upsampling）デコーダを組み合わせたFCNなどの構造が基本となります。この際、Upsamplingで失われがちな詳細情報を補うために用いられる技術はどれか。",
      "options": [
        "スキップ結合",
        "バッチ正規化",
        "ドロップアウト",
        "プーリング"
      ],
      "answer": 0,
      "explanation": "セグメンテーション（FCN, U-Net等）では、層を深くする過程で失われた細部の物体の境界情報を復元するため、浅い層の特徴マップを深い層に直接供給するスキップ結合が多用されます。"
    },
    {
      "id": 99,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "距離尺度",
      "question": "GAN（敵対的生成ネットワーク）において、生成器（Generator）が多様性を失い、特定の（同じような）画像ばかりを出力し続けてしまう、学習が停滞する現象を何というか。",
      "options": [
        "モード崩壊",
        "勾配消失",
        "オーバーフィッティング",
        "データリーケージ"
      ],
      "answer": 0,
      "explanation": "モード崩壊は、生成器が識別器を出し抜きやすい特定のサンプルに固執してしまう現象で、GANの学習を不安定にする大きな要因の一つです。WGANなどの導入により対策が図られています。"
    },
    {
      "id": 100,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "類似度",
      "question": "動画認識タスクにおいて、画像の3次元（高さ幅時間軸）に対して畳み込みを行う手法はどれか。",
      "options": [
        "C3D",
        "RNN",
        "CNN",
        "LSTM"
      ],
      "answer": 0,
      "explanation": "C3Dは、通常の2次元畳み込みに時間軸（フレームの流れ）を加え、3次元のフィルタ（カーネル）を用いることで、動画内の動きや時間的な特徴を捉える手法です。"
    },
    {
      "id": 101,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "アノテーション",
      "question": "深層強化学習において、深層ニューラルネットワークとQ学習（Q-learning）を組み合わせ、Atari社のレトロゲームで人間を上回る性能を示した、深層強化学習ブームの先駆けとなったモデルはどれか。",
      "options": [
        "DQN",
        "AlphaGo",
        "A3C",
        "SARSA"
      ],
      "answer": 0,
      "explanation": "DQNは、膨大な状態空間を持つビデオゲームにおいて、過去の経験をメモリに蓄えてランダムにサンプリングする「Experience Replay」や、教師信号となるQ関数を一時的に固定する「Target Network」といった工夫で学習を安定させ、歴史的な成果を挙げました。"
    },
    {
      "id": 102,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "数理・統計の基礎",
      "question": "Googleが開発したAlphaGo（アルファ碁）が、世界トップ棋士を破った際に採用されていた手法の組み合わせとして正しいものはどれか。",
      "options": [
        "ポリシー網＋バリュー網＋モンテカルロ木探索",
        "DQNによるエンドツーエンド学習",
        "LSTMによる盤面情報の時系列予測",
        "単純なルールベースによる力まかせ探索"
      ],
      "answer": 0,
      "explanation": "AlphaGoは、ディープラーニングによる盤面の形勢判断（バリュー網）および候補手の絞り込み（ポリシー網）と、伝統的な手法であるモンテカルロ木探索を融合させることで、未知の局面を効率的に探索することを可能にしました。"
    },
    {
      "id": 103,
      "majorCategory": "ディープラーニングの応用例",
      "subCategory": "ロボティクス",
      "question": "2017年に発表された「AlphaGo Zero」が、それまでのAlphaGoと決定的に異なっていた点はどれか。",
      "options": [
        "人間の棋譜を一切使わず、自己対戦のみで学習したこと",
        "ニューラルネットワークの使用をやめ、純粋なモンテカルロ木探索のみにしたこと",
        "盤面全体を画像として認識するのをやめ、点数化された特徴量のみを使用したこと",
        "インターネット上のあらゆる囲碁ニュースを学習データに加えたこと"
      ],
      "answer": 0,
      "explanation": "AlphaGo Zeroは、人間の知識（棋譜）に頼ることなく、強化学習による自己対戦（セルフプレイ）を繰り返すことで、人間の常識に囚われない独創的かつ最強の手を自ら編み出しました。"
    },
    {
      "id": 104,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "モデル軽量化",
      "question": "ある領域（ドメイン）で学習済みのモデルの重みを、別の関連するタスクの初期値として利用し、少量のデータで効率的に学習を進める手法を何というか。",
      "options": [
        "転移学習",
        "多タスク学習",
        "能動学習",
        "蒸留"
      ],
      "answer": 0,
      "explanation": "転移学習は、ImageNetなどの大規模データで得られた「画像の汎用的な特徴（エッジや模様など）」を、医療画像診断などの専門的なタスクに使い回すことで、ゼロから学習するよりも遥かに高い精度と収束速度を叩き出します。"
    },
    {
      "id": 105,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "行列分解",
      "question": "転移学習の一種で、事前学習済みモデルの重みを固定（Freeze）せず、新しいタスクのデータを用いてモデル全体の重みを微調整するプロセスを何というか。",
      "options": [
        "ファインチューニング",
        "事前学習",
        "蒸留",
        "量子化"
      ],
      "answer": 0,
      "explanation": "ファインチューニングは、事前学習で得られた知識を活かしつつ、特定のターゲットドメイン（例えばアニメ画像認識など）に特化したモデルに「微調整」する作業です。"
    },
    {
      "id": 106,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "ディープラーニングモデルにおいて、入力データに僅かな変更（人間には検知できない程度のノイズ）を加え、意図的にモデルの判断を誤らせる攻撃手法を何というか。",
      "options": [
        "敵対的攻撃",
        "データ汚染",
        "モデル抽出攻撃",
        "メンバーシップ推論攻撃"
      ],
      "answer": 0,
      "explanation": "敵対的攻撃は、自動運転の道路標識認識を誤らせるなど、現実社会でのAI利用における大きなセキュリティ上の懸念事項となっています。"
    },
    {
      "id": 107,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "確率変数 $X$ の値と、その平均（期待値） $\\mu$ との差の二乗の平均をとり、データの「ばらつき」の度合いを数値化したものを何と呼ぶか。",
      "options": [
        "分散",
        "標準偏差",
        "期待値",
        "共分散"
      ],
      "answer": 0,
      "explanation": "分散は、データの散らばり具合を定量的に示す基本的な指標です。ディープラーニングにおいては、情報の伝播をスムーズにするために、各層の出力の分散を調節する「バッチ正規化」などの技術が重要になります。"
    },
    {
      "id": 108,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "プライバシー",
      "question": "二つの変数の関係において、一方の値が大きくなるともう一方の値も大きくなる傾向があるとき、その関係性を何と呼ぶか。",
      "options": [
        "正の相関",
        "負の相関",
        "無相関",
        "因果関係"
      ],
      "answer": 0,
      "explanation": "相関関係は二つの変数が連動していることを示しますが、それが直接的な原因と結果（因果関係）であるとは限らないことに注意が必要です（擬似相関）。"
    },
    {
      "id": 109,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "ベイズの定理",
      "question": "ベイズの定理において、新しいデータ（証拠）が得られた後に、ある事象が起こる確率を更新したものを何と呼ぶか。",
      "options": [
        "事後確率",
        "事前確率",
        "尤度",
        "周辺確率"
      ],
      "answer": 0,
      "explanation": "ベイズの定理は、限られた情報を基に推論を行い、新しい情報を得るたびにその推論の精度（確率）を高めていくデータサイエンスの強力なツールです。"
    },
    {
      "id": 110,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "モデルの解釈性",
      "question": "回帰分析において、目的変数（予測したい値）に対してどれだけ説明変数（予測の手がかりとなる値）が寄与しているか、つまりモデルの当てはまりの良さ（説明力）を示す 0 から 1 までの指標を何と呼ぶか。",
      "options": [
        "決定係数 ($R^2$)",
        "相関係数",
        "p値",
        "標準誤差"
      ],
      "answer": 0,
      "explanation": "決定係数は、データの変動のうち何パーセントがモデルによって説明できているかを示す指標で、回帰モデルの評価において最も多用されます。"
    },
    {
      "id": 111,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "検定",
      "question": "AIをビジネスに導入する際、単に作業を自動化するだけでなく、組織のあり方や業務プロセスそのものを根本的に見直し、再設計することを何と呼ぶか。",
      "options": [
        "BPR",
        "DX",
        "RPA",
        "OJT"
      ],
      "answer": 0,
      "explanation": "BPRは、AI導入を機に「今までのやり方」をゼロベースで見直し、飛躍的な成果（コスト、品質、スピード等）を追求する経営手法です。"
    },
    {
      "id": 112,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "時系列解析",
      "question": "AIプロジェクトの体制において、ビジネス課題を定義し、AIの導入によって得られるROI（投資対効果）を評価管理する役割を担うべきなのはどの部門か。",
      "options": [
        "ビジネス部門",
        "ITシステム部門",
        "法務コンプライアンス部門",
        "研究開発部門"
      ],
      "answer": 0,
      "explanation": "AIプロジェクトの成否は「何のために使うか」という出口戦略に依存するため、現場の課題を熟知したビジネス部門の主体的な関与が不可欠です。"
    },
    {
      "id": 113,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "データ前処理・分析",
      "question": "個人情報保護法における「連結可能匿名化」と「連結不可能匿名化」の違いのうち、2022年4月施行の改正法で「内部分析目的」として定義された仮名加工情報に該当するのはどれか。",
      "options": [
        "元の個人情報と紐付けるための連結テーブルを保持しており、復元可能な状態",
        "特定の個人を識別できず、かつ復元もできないように適切に加工された状態",
        "単に名前を伏せ字にしただけで、住所や生年月日はそのままの状態",
        "Webサイトから収集しただけで、加工を一切行っていない状態"
      ],
      "answer": 0,
      "explanation": "「仮名加工情報」は、他の情報と照合しなければ個人を識別できない情報であり、社内でのデータ利活用（分析やAI学習）を容易にするために創設されました。"
    },
    {
      "id": 114,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "データ前処理・分析",
      "question": "他人の著作物をAIの学習データとして使用する行為について、日本の著作権法第30条の4に基づいた現在の解釈として正しいものはどれか。",
      "options": [
        "情報解析を目的とするならば、原則として著作権者の許諾なく利用可能",
        "商用目的のAI学習には、理由を問わず著作権者の個別の許諾が必要となる",
        "インターネット上に公開されている画像であれば、学習以外の目的でも自由に使用できる",
        "著作権法第30条の4は、日本国内の著作物のみに適用され、海外の著作物には適用されない"
      ],
      "answer": 0,
      "explanation": "日本の著作権法第30条の4は「柔軟な権利制限規定」として知られ、著作物に表現された思想又は感情を自ら享受することを目的としない「情報解析」であれば、原則として利用できるとしています。"
    },
    {
      "id": 115,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "学習手法",
      "question": "AI生成物の著作権について、現在の日本の法解釈における原則的な考え方はどれか。",
      "options": [
        "人間が創造的な寄与を行っていない「AIが勝手に作ったもの」には著作権は発生しない",
        "AIが生成したものは、すべて作成者の著作権として認められる",
        "AIが生成したものは、そのAIを開発した企業の著作物となる",
        "AI生成物は、学習に使用されたデータの著作者全員の共有著作物となる"
      ],
      "answer": 0,
      "explanation": "著作権法は「思想又は感情を創作的に表現したもの」を保護対象としているため、人間が創作に関与していないAI生成物は、原則として著作物とはみなされません。"
    },
    {
      "id": 116,
      "majorCategory": "人工知能をめぐる動向",
      "subCategory": "学習手法",
      "question": "AIが生成した画像において、既存の著作物との「類似性」と「（　）」の両方が認められる場合、著作権を侵害していると判断される可能性がある。（　）に入る適切な用語を選べ。",
      "options": [
        "依拠性",
        "新規性",
        "進歩性",
        "有用性"
      ],
      "answer": 0,
      "explanation": "著作権侵害が成立するためには、既存の著作物と似ていること（類似性）だけでなく、その著作物を基にして作られたこと（依拠性）が必要です。AIの場合、学習データにその著作物が含まれていたかが重要な論点になります。"
    },
    {
      "id": 117,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "特許法",
      "question": "特許法において、AIが自律的に行った発明の「発明者」としての資格について、現在の日本の制度における一般的な扱いはどれか。",
      "options": [
        "発明者は「自然人」に限られ、AI自体は発明者にはなれない",
        "AIが発明したものであれば、そのAIの開発者が自動的に発明者となる",
        "AIそのものが発明者として特許庁に登録されることが認められている",
        "AIが生成した発明には、いかなる場合も特許権が発生しない"
      ],
      "answer": 0,
      "explanation": "現行の日本の特許法体系では、発明者は人間であることを前提としており、AI自身を発明者として認めるための法整備や議論が国際的に進められています。"
    },
    {
      "id": 118,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "不正競争防止法",
      "question": "不正競争防止法において保護される「営業秘密」として認められるための3つの要件に含まれないものはどれか。",
      "options": [
        "進歩性",
        "秘密管理性",
        "有用性",
        "非公知性"
      ],
      "answer": 0,
      "explanation": "営業秘密として保護されるには、「秘密として管理されていること（秘密管理性）」、「事業活動に有用であること（有用性）」、「公然と知られていないこと（非公知性）」の3要件を満たす必要があります。「進歩性」は特許の要件です。"
    },
    {
      "id": 119,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "不正競争防止法",
      "question": "2019年の改正不正競争防止法で導入された概念で、IDやパスワード等で管理され、特定の者に提供される相当量蓄積された情報（例：気象データ、走行データ等）を何と呼ぶか。",
      "options": [
        "限定提供データ",
        "営業秘密",
        "ビッグデータ",
        "要配慮個人情報"
      ],
      "answer": 0,
      "explanation": "限定提供データは、秘密としての管理（秘密管理性）までは求められないものの、ID/PW等でアクセス制限されたビジネス価値のあるデータを、不正な取得や使用から守るための枠組みです。"
    },
    {
      "id": 120,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "評価",
      "question": "AIプロジェクトの推進体制において、現場（ビジネス部門）のニーズを汲み取り、データサイエンティストと連携してAIの活用方法を企画設計する人材を何と呼ぶか。",
      "options": [
        "AIプロデューサー / AIプランナー",
        "データサイエンティスト",
        "MLエンジニア",
        "ドメインエキスパート"
      ],
      "answer": 0,
      "explanation": "AIプロデューサー（プランナー）は、ビジネスと技術の橋渡しを行い、AIを「どのようにビジネス価値に変えるか」という設計図を描く重要な役割を担います。"
    },
    {
      "id": 121,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "法規制・権利",
      "question": "AIプロジェクトにおいて、PoC（概念実証）を実施した環境では高い精度が得られていたが、本番環境に導入した途端に精度が大幅に低下してしまう原因として、不適切なものはどれか。",
      "options": [
        "本番環境で使用したGPUの性能がPoC時よりも向上したこと",
        "本番環境で実際に発生するデータのノイズが、PoC用のデータには含まれていなかったこと",
        "PoCではデータクレンジング後のきれいなデータのみを使用していたこと",
        "ユーザーの行動変化により、入力データの分布がPoC時と大きく変わってしまったこと"
      ],
      "answer": 0,
      "explanation": "ハードウェア（GPU）の性能向上は処理速度を上げますが、推論の精度そのものを低下させる直接的な原因にはなりません。精度の低下は、主にデータの質の差異や分布の変化（ドリフト）に起因します。"
    },
    {
      "id": 122,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "管理・運用",
      "question": "機械学習モデルのライフサイクル管理において、モデルの性能を定常的に監視し、あらかじめ設定した閾値を下回った場合に自動的に再学習を開始するような「継続的学習」の仕組みが含まれる手法はどれか。",
      "options": [
        "MLOps",
        "アジャイル開発",
        "データサイエンス",
        "EDA"
      ],
      "answer": 0,
      "explanation": "MLOpsは、機械学習モデルの「鮮度」を保つために、自動化された監視再学習パイプラインを構築し、本番環境での性能劣化に迅速に対応することを目指します。"
    },
    {
      "id": 123,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "運用・管理",
      "question": "企業において、AIやデータなどのデジタル技術を活用し、単なる業務効率化にとどまらず、ビジネスモデルや組織、企業文化そのものを変革し、競争優位性を確立する取り組みを何と呼ぶか。",
      "options": [
        "DX",
        "BPR",
        "RPA",
        "IT化"
      ],
      "answer": 0,
      "explanation": "DXは単なるデジタルツールの導入ではなく、データやデジタル技術を駆使して、製品、サービス、さらには企業文化や組織そのものを変革することを指します。"
    },
    {
      "id": 124,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "法規制・権利",
      "question": "AIプロジェクトを推進する際に、自社の強みと外部リソース（スタートアップの技術、大学の知見等）を組み合わせてイノベーションを加速させる手法を何というか。",
      "options": [
        "オープンイノベーション",
        "垂直統合",
        "M&A",
        "アウトソーシング"
      ],
      "answer": 0,
      "explanation": "オープンイノベーションは、外部の知識や技術を積極的に自社の技術と組み合わせることで、内部開発だけに頼るよりも迅速かつ効果的に新しい価値を生み出す手法です。"
    },
    {
      "id": 125,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "ライフサイクル管理",
      "question": "AIプロジェクトの課題定義フェーズにおいて、解決したいビジネス課題を数値として評価するために設定する重要な指標を何というか。",
      "options": [
        "KPI",
        "ROI",
        "PoC",
        "MVP"
      ],
      "answer": 0,
      "explanation": "KPIは、プロジェクトの成功（または目標への進捗）を客観的に測定するための重要な評価指標です。AIプロジェクトでは、ビジネス上の効果とAIの精度（RMSEやRecall等）の両面でKPIを設定することが重要です。"
    },
    {
      "id": 126,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "学習手法",
      "question": "大規模言語モデル（LLM）において、ファインチューニングを行わずに、プロンプト内でいくつか具体例（質問と回答のペア）を提示することで、モデルに未知のタスクを実行させる手法はどれか。",
      "options": [
        "Few-shot Learning",
        "Zero-shot Learning",
        "Multimodal Learning",
        "Transfer Learning"
      ],
      "answer": 0,
      "explanation": "Few-shot Learningは、モデルにわずかな例示を与えるだけで、そのパターンを理解してタスクを実行させる力（In-context Learning）を活用した手法です。"
    },
    {
      "id": 127,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "2013年にGoogleによって発表されたword2vecにおいて、周辺の単語の並びから中心の単語を推測するように学習する手法はどれか。",
      "options": [
        "CBOW",
        "Skip-gram",
        "GloVe",
        "RNN"
      ],
      "answer": 0,
      "explanation": "CBOW(Continuous Bag-of-Words)は中心単語を周辺文脈から予測するのに対し、Skip-gramは中心単語から周辺単語を予測します。CBOWの方が計算が速い傾向があります。"
    },
    {
      "id": 128,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "ディープラーニングにおける「アテンション（Attention）」メカニズムの中でも、自分自身の系列内の単語同士の関連性を計算する仕組みを何というか。",
      "options": [
        "Self-Attention",
        "Cross-Attention",
        "Soft Attention",
        "Hard Attention"
      ],
      "answer": 0,
      "explanation": "Self-Attentionは、Transformerの核心技術であり、文中の各単語が「他のどの単語と強く結びついているか」を計算することで、文脈を高度に理解することを可能にします。"
    },
    {
      "id": 129,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "ニューラルネットワークの隠れ層において、入力値が正であればそのまま出力し、0以下であれば0を出力する、勾配消失を防ぐ効果が高い活性化関数はどれか。",
      "options": [
        "ReLU",
        "シグモイド関数",
        "tanh関数",
        "ステップ関数"
      ],
      "answer": 0,
      "explanation": "ReLU（Rectified Linear Unit）は、計算が単純で、かつ正の領域で勾配が減衰しないため、深層ネットワークの学習を劇的に効率化させました。"
    },
    {
      "id": 130,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "学習データに対する誤差は非常に小さいが、テストデータ（未知のデータ）に対する誤差が大きくなってしまう、モデルが必要以上に複雑になりすぎた状態を何というか。",
      "options": [
        "過学習",
        "学習不足",
        "勾配消失",
        "モード崩壊"
      ],
      "answer": 0,
      "explanation": "過学習は、モデルが訓練データのノイズや偶然のパターンまで学習してしまい、新しいデータに対する応用力が失われた状態を指します。"
    },
    {
      "id": 131,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "畳み込みニューラルネットワーク（CNN）において、フィルタが入力画像の上をスライドする際の間隔を何と呼ぶか。",
      "options": [
        "ストライド",
        "パディング",
        "チャンネル",
        "プーリング"
      ],
      "answer": 0,
      "explanation": "ストライドを大きく設定すると、出力される特徴マップのサイズが小さくなり、計算量を削減することができます。"
    },
    {
      "id": 132,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "2015年にResNetで提案され、入力を層の出力にそのまま加算することで、100層を超えるような超多層ネットワークでも勾配消失を防ぎ、学習を可能にした仕組みはどれか。",
      "options": [
        "スキップ結合",
        "バッチ正規化",
        "ドロップアウト",
        "アテンション"
      ],
      "answer": 0,
      "explanation": "スキップ結合は、ネットワークの一部をバイパス（ショートカット）させることで、誤差の情報が直接深い層まで伝わるようにし、最適化を容易にしました。"
    },
    {
      "id": 133,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "AIセキュリティ",
      "question": "ディープラーニングにおいて、学習率などの「人間があらかじめ設定しなければならないパラメータ」を何と呼ぶか。",
      "options": [
        "ハイパーパラメータ",
        "学習パラメータ",
        "入力パラメータ",
        "出力パラメータ"
      ],
      "answer": 0,
      "explanation": "ハイパーパラメータには、学習率、バッチサイズ、層の数、ニューロン数などがあり、これらを適切に調整（チューニング）することがモデルの性能向上に不可欠です。"
    },
    {
      "id": 134,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "ニューラルネットワークが解いている最適化問題において、全体の中で最も誤差が小さい「最適解（グローバルミニマム）」ではなく、その周辺だけで誤差が小さくなっている点に陥ってしまう問題を何というか。",
      "options": [
        "局所解  問題",
        "勾配消失問題",
        "過学習問題",
        "次元の呪い"
      ],
      "answer": 0,
      "explanation": "局所解の問題は、初期値や学習率の設定によっては、本当の最適解に辿り着けずに途中で学習が止まってしまう現象を指します。最近のSGDやAdamなどの最適化手法は、この問題を回避しやすく設計されています。"
    },
    {
      "id": 135,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "画像認識、音声認識、自然言語処理などの異なる種類のデータを組み合わせて処理理解するモデルを何と呼ぶか。",
      "options": [
        "マルチモーダルモデル",
        "マルチタスクモデル",
        "マルチコアモデル",
        "マルチリンガルモデル"
      ],
      "answer": 0,
      "explanation": "マルチモーダルAIは、例えば「写真（視覚）」と「説明文（言語）」を統合して理解することで、より高度で人間らしい認識能力を実現します（CLIPなどが有名です）。"
    },
    {
      "id": 136,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "自然言語処理において、大量のテキストから得られた単語の分散表現を用いて、「王 － 男 ＋ 女 ＝ 女王」のように意味の足し引きができる性質を何というか。",
      "options": [
        "加法構成性",
        "分散表現",
        "アテンション",
        "再帰性"
      ],
      "answer": 0,
      "explanation": "word2vecなどの単語埋め込み手法では、単語の意味がベクトル空間上の「方向」と「距離」として表現されるため、ベクトルの演算によって意味の類推を行うことができます。"
    },
    {
      "id": 137,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "ディープラーニングにおいて、学習データの数が極端に少ない場合に、左右反転や回転、色の変化などを加えて強引にデータ数を増やすテクニックを何というか。",
      "options": [
        "データ拡張",
        "オーバサンプリング",
        "転移学習",
        "正規化"
      ],
      "answer": 0,
      "explanation": "データ拡張は、特に画像認識において、モデルが画像の些細な変化に惑わされないようにし、汎化性能（未知のデータへの対応力）を高めるために非常に有効です。"
    },
    {
      "id": 138,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "ディープラーニングの学習において、勾配情報の更新間隔を示す「バッチサイズ」を大きくすることの一般的な影響はどれか。",
      "options": [
        "1エポックあたりの計算が並列化しやすくなり、高速化するが、メモリ消費量が増える",
        "学習が非常に不安定になり、勾配爆発が起こりやすくなる",
        "常に過学習を抑制する効果があり、正則化と全く同じ働きをする",
        "ネットワークの層を自動的に増やす効果がある"
      ],
      "answer": 0,
      "explanation": "大きなバッチサイズはGPUの並列演算能力を活かしやすい一方、メモリを多く消費し、また「般化性能がわずかに低下する」という研究結果（鋭い極小値への収束）もあります。"
    },
    {
      "id": 139,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "AIモデルの推論において、すべてのデータをクラウド上のサーバーに送るのではなく、ユーザーの手元（スマートフォンやカメラデバイス等）で直接処理を行う方式を何と呼ぶか。",
      "options": [
        "エッジAI",
        "フォグコンピューティング",
        "クラウドAI",
        "中央集権型AI"
      ],
      "answer": 0,
      "explanation": "エッジAIは、通信遅延（レイテンシ）を抑え、プライバシー情報を外部に出さないメリットがあるため、自動運転や監視カメラなどで急速に普及しています。"
    },
    {
      "id": 140,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "ディープラーニングのモデルを特定の業務に適用した際、期待される精度が出ない場合の対策として、モデルの改良以外で最も重要とされるアプローチはどれか。",
      "options": [
        "データの質と量を見直し、必要に応じてアノテーションをやり直す",
        "より高性能なGPUを導入する",
        "活性化関数をすべて最新のものに変更する",
        "社内のすべてのPCにAIをインストールする"
      ],
      "answer": 0,
      "explanation": "AIの精度は「データの質」に依存します。ラベルの誤りを修正したり、偏りをなくすためにデータを追加収集したりする「データ中心のAI（Data-centric AI）」の考え方が重要視されています。"
    },
    {
      "id": 141,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "学習手法",
      "question": "統計的仮説検定において、検定結果の有意性を判断するために用いられる、帰無仮説が正しいとした場合に観察されたデータ（またはそれ以上に極端なデータ）が得られる確率を何と呼ぶか。",
      "options": [
        "p値",
        "有意水準",
        "信頼区間",
        "検定統計量"
      ],
      "answer": 0,
      "explanation": "p値は、観察された結果が偶然によって生じた可能性を示す指標です。一般にp値が有意水準（例えば0.05）を下回れば、帰無仮説を棄却し「統計的に有意な差がある」と判断します。"
    },
    {
      "id": 142,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "生成AIの手法",
      "question": "平均 $\\mu$、標準偏差 $\\sigma$ の正規分布に従う確率変数 $X$ を、$Z = (X - \\mu) / \\sigma$ と変換することで得られる、平均0、分散1の分布を何というか。",
      "options": [
        "標準正規分布",
        "対数正規分布",
        "カイ二項分布",
        "t分布"
      ],
      "answer": 0,
      "explanation": "標準正規分布（Z分布）への変換（標準化）を行うことで、異なるスケールのデータを比較したり、特定のデータの偏差値的な位置づけを調べることが可能になります。"
    },
    {
      "id": 143,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "生成AI",
      "question": "統計的な推定において、標本から得られた情報に基づき、母集団のパラメータ（平均など）が含まれる確率が一定以上（例えば95%）である範囲を求めることを何というか。",
      "options": [
        "区間推定",
        "点推定",
        "仮説検定",
        "最尤推定"
      ],
      "answer": 0,
      "explanation": "正規分布などの理論的分布に基づき、「真の値はこの範囲にあるはずだ」という信頼区間を算出するのが区間推定です。"
    },
    {
      "id": 144,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "生成AI",
      "question": "二つの変数が独立であるかどうか、あるいはデータの分布が想定される理論分布に適合しているかどうかを判定するために多用される統計的検定手法はどれか。",
      "options": [
        "カイ二乗検定",
        "t検定",
        "F検定",
        "ウェルチの検定"
      ],
      "answer": 0,
      "explanation": "カイ二乗検定は、カテゴリーデータの相関分析などで非常によく用いられる手法です。"
    },
    {
      "id": 145,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "評価",
      "question": "回帰分析後の残差分析などにおいて、予測誤差（残差）が正規分布に従っているかどうかを確認するために用いられる、プロット上の点が直線に並ぶかどうかを見るグラフは何というか。",
      "options": [
        "Q-Qプロット",
        "ヒストグラム",
        "散布図",
        "箱ひげ図"
      ],
      "answer": 0,
      "explanation": "Q-Qプロット（quantile-quantile plot）は、データの分布と理論分布を比較するための視覚的ツールで、回帰モデルの前提条件のチェックに役立ちます。"
    },
    {
      "id": 146,
      "majorCategory": "AIに必要な数理・統計知識",
      "subCategory": "数理・統計の基礎",
      "question": "ディープラーニングモデルにおいて、学習が進むにつれて重みの値が指数関数的に増大し、計算不能（NaN）になってしまう現象を何というか。",
      "options": [
        "勾配爆発",
        "勾配消失",
        "鞍点",
        "過学習"
      ],
      "answer": 0,
      "explanation": "勾配爆発は、重みの更新量が大きくなりすぎることで発生します。勾配クリッピング（Gradient Clipping）などの対策が必要です。"
    },
    {
      "id": 147,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "最適化",
      "question": "2014年に提唱されたGANの目的関数において、生成器（Generator）が最小化しようとする一方で識別器（Discriminator）が最大化しようとするゲーム的な目的関数は何と呼ばれる関数の形式か。",
      "options": [
        "min-maxゲーム",
        "ロジスティック損失",
        "ヒンジ損失",
        "平均二乗誤差"
      ],
      "answer": 0,
      "explanation": "GANは2つのネットワークが互いの利益を相反する形で競い合う「ゼロサムゲーム」の構造をとっており、ナッシュ均衡への到達を目指します。"
    },
    {
      "id": 148,
      "majorCategory": "ディープラーニングの要素技術",
      "subCategory": "時系列",
      "question": "RNN（再帰型ニューラルネットワーク）において、過去の情報を長期にわたって保持するために、「セル状態」という情報の通り道と、それを制御する「ゲート」を導入した構造はどれか。",
      "options": [
        "LSTM",
        "GRU",
        "Simple RNN",
        "CNN"
      ],
      "answer": 0,
      "explanation": "LSTMは、不要な情報を忘れる「忘却ゲート」、新しい情報を追加する「入力ゲート」、出力を決める「出力ゲート」により、長期的な依存関係を学習できます。"
    },
    {
      "id": 149,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "ディープラーニングの学習において、特定の訓練データに過度に依存するのを避けるため、複数の独立した重みセット（アンサンブル）を用意する代わりに、一つのネットワーク内でランダムにニューロンを間引く手法はどれか。",
      "options": [
        "ドロップアウト",
        "バッチ正規化",
        "早期終了",
        "L2正則化"
      ],
      "answer": 0,
      "explanation": "ドロップアウトは、学習のたびにランダムに一部の接続を断つことで、膨大な数の小さなサブネットワークのアンサンブル学習を行っているのと等価な効果を発揮し、過学習を強力に抑えます。"
    },
    {
      "id": 150,
      "majorCategory": "ディープラーニングの概要",
      "subCategory": "学習手法",
      "question": "ニューラルネットワークにおいて、入力と出力が等しくなるように学習を行う教师なし学習アルゴリズムであり、中間層で情報の圧縮（特徴抽出）を行うものはどれか。",
      "options": [
        "オートエンコーダ",
        "GAN",
        "DQN",
        "BERT"
      ],
      "answer": 0,
      "explanation": "オートエンコーダは、入力を次元圧縮して潜在表現を得る「エンコード」と、そこから元の入力を復元する「デコード」を学習することで、データの効率的な表現を自律的に獲得します。"
    },
    {
      "id": 151,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "管理・運用",
      "question": "ディープラーニングモデルをWebサービスとして公開し、ユーザーからのリクエストに対してリアルタイムに推論結果を返す形態を何というか。",
      "options": [
        "オンライン推論",
        "バッチ推論",
        "エッジ推論",
        "ストリーム処理"
      ],
      "answer": 0,
      "explanation": "オンライン推論は、APIなどを通じて一つ一つのデータに対して即座に応答を返す方式で、検索エンジンやチャットボットなどで利用されます。"
    },
    {
      "id": 152,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "管理・運用",
      "question": "AIモデルの運用において、入力データの傾向は変わっていないが、正解ラベルの定義（ビジネス上の判断基準など）が変化することでモデルの精度が低下する現象を何というか。",
      "options": [
        "コンセプトドリフト",
        "データドリフト",
        "過学習",
        "勾配消失"
      ],
      "answer": 0,
      "explanation": "コンセプトドリフトは、例えば「以前は正常と判断していた行動が、社会情勢の変化で異常と見なされるようになった」など、ターゲットとなる概念そのものが変化してしまう問題を指します。"
    },
    {
      "id": 153,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "管理・運用",
      "question": "AIプロジェクトにおいて、実データの代わりに、シミュレーターやCGを用いて人工的に生成された学習データを何と呼ぶか。",
      "options": [
        "シンセティックデータ",
        "オープンデータ",
        "ビッグデータ",
        "時系列データ"
      ],
      "answer": 0,
      "explanation": "シンセティックデータは、プライバシーの懸念がある情報や、発生頻度の低い稀なケース（事故シーンなど）をAIに学習させるために非常に有効な手段です。"
    },
    {
      "id": 154,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "管理・運用",
      "question": "AIの判断結果が人間に与える影響の大きさを考慮し、特にリスクの高い分野において、AIの判断に必ず人間が関与監督する仕組みを何というか。",
      "options": [
        "Human-in-the-Loop",
        "Black Box",
        "End-to-End",
        "Decentralized AI"
      ],
      "answer": 0,
      "explanation": "Human-in-the-Loopは、特に生命や自由に関わるような重要な意思決定において、AIを完全に自律させるのではなく、最終的な責任を人間が負うための設計思想です。"
    },
    {
      "id": 155,
      "majorCategory": "AIの社会実装に向けて",
      "subCategory": "倫理的法的社会的課題",
      "question": "AIの普及によって生じる倫理的法的社会的課題の総称をアルファベット4文字で何というか。",
      "options": [
        "ELSI",
        "GDPR",
        "XAI",
        "MLOps"
      ],
      "answer": 0,
      "explanation": "ELSI（Ethical, Legal and Social Implications）は、新しい科学技術を社会に導入する際に多角的に検討すべき課題を指し、AI開発においても極めて重視されています。"
    },
    {
      "id": 156,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "AIによって生成された画像などをSNS等にアップロードする際、他人の著作物と酷似している場合に問われる可能性がある責任はどれか。",
      "options": [
        "著作権侵害",
        "特許権侵害",
        "不正競争防止法違反",
        "意匠権侵害"
      ],
      "answer": 0,
      "explanation": "AI生成物であっても、既存の著作物との「類似性」と「依拠性」が認められれば、著作権侵害となり得ます。利用者は生成された内容が既知の作品に似ていないか注意を払う必要があります。"
    },
    {
      "id": 157,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "AI開発における契約段階で、学習データとして提供した自社のノウハウが、AIの学習を通じて競合他社に利用（流出）されないように定めるべき条項はどれか。",
      "options": [
        "秘密保持および利用目的制限",
        "瑕疵担保責任",
        "善管注意義務",
        "損害賠償制限"
      ],
      "answer": 0,
      "explanation": "提供した生データだけでなく、そこから学習された「モデル」や「重み」に自社の知財がどのように反映されるかを、契約で明確に定義することが重要です。"
    },
    {
      "id": 158,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "AIシステムの開発委託において、完成したソフトウェアの不具合（契約不適合）に対して受託者が責任を負うべき期間や範囲を定める責任を何というか。",
      "options": [
        "契約不適合責任",
        "善管注意義務",
        "製造物責任",
        "不法行為責任"
      ],
      "answer": 0,
      "explanation": "2020年の民法改正により「瑕疵担保責任」から名称が変わりました。AIは100%の精度を保証できないため、その責任範囲をどこまで認めるかが契約上の重要な論点になります。"
    },
    {
      "id": 159,
      "majorCategory": "AIに関する法律と契約",
      "subCategory": "法規制・権利",
      "question": "生成AIが学習データに含まれる個人情報を出力してしまった場合、関連する法規制のうち、主にどの法律の違反となる可能性があるか。",
      "options": [
        "個人情報保護法",
        "著作権法",
        "特許法",
        "不正競争防止法"
      ],
      "answer": 0,
      "explanation": "AIの出力結果に特定の個人のプライバシーや個人情報が含まれており、それが本人の同意なく拡散されることは、個人情報保護法上のリスクとなります。"
    },
    {
      "id": 160,
      "majorCategory": "人工知能とは",
      "subCategory": "全体",
      "question": "AIが人間の知能を遥かに凌駕し、人類の歴史が根本から変わってしまう転換点を何と呼ぶか。",
      "options": [
        "シンギュラリティ",
        "チューリングテスト",
        "フレーム問題",
        "シンボルグラウンディング問題"
      ],
      "answer": 0,
      "explanation": "シンギュラリティは、レイカーツワイル氏らによって提唱された概念で、AIが自らより優れたAIを開発し始めることで、指数関数的な進化が起こるとされています。"
    }
  ]
}